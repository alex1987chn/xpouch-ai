"""
ä¸“å®¶èŠ‚ç‚¹ï¼ˆåŠ¨æ€ç‰ˆæœ¬ï¼‰

ä½¿ç”¨æ•°æ®åº“åŠ è½½çš„ Promptï¼Œä¸å†ä¾èµ–ç¡¬ç¼–ç å¸¸é‡
"""
import os
from typing import Dict, Any
from langchain_core.messages import SystemMessage, HumanMessage
from datetime import datetime

from agents.expert_loader import get_expert_config_cached
from agents.experts import EXPERT_DESCRIPTIONS
from agents.model_fallback import get_effective_model, get_default_model


async def run_expert_node(
    expert_key: str,
    state: Dict[str, Any],
    llm
) -> Dict[str, Any]:
    """
    é€šç”¨ä¸“å®¶èŠ‚ç‚¹ï¼šæ ¹æ® expert_key ä»æ•°æ®åº“åŠ è½½é…ç½®

    Args:
        expert_key: ä¸“å®¶ç±»å‹æ ‡è¯†ï¼ˆå¦‚ 'coder', 'search'ï¼‰
        state: å®Œæ•´çš„ AgentState
        llm: LLM å®ä¾‹

    Returns:
        Dict: æ›´æ–°åçš„ AgentStateï¼ˆåŒ…å« output_resultï¼‰
    """
    # ä»æ•°æ®åº“/ç¼“å­˜åŠ è½½ä¸“å®¶é…ç½®
    expert_config = get_expert_config_cached(expert_key)

    if not expert_config:
        # é™çº§ï¼šä½¿ç”¨ç¡¬ç¼–ç  Promptï¼ˆå¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼‰
        from agents.experts import EXPERT_PROMPTS
        # ğŸ‘ˆ ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç çš„ gpt-4o
        default_model = get_default_model()
        expert_config = {
            "expert_key": expert_key,
            "name": EXPERT_DESCRIPTIONS.get(expert_key, expert_key),
            "system_prompt": EXPERT_PROMPTS.get(expert_key, ""),
            "model": default_model,
            "temperature": 0.5
        }
        print(f"[ExpertNode] Using fallback config for '{expert_key}': model={default_model}")

    system_prompt = expert_config["system_prompt"]
    # ğŸ‘ˆ åº”ç”¨æ¨¡å‹å…œåº•æœºåˆ¶
    model = get_effective_model(expert_config.get("model"))
    temperature = expert_config["temperature"]

    print(f"[ExpertNode] Running {expert_key} with model={model}, temp={temperature}")

    # è·å–å½“å‰ä»»åŠ¡
    task_list = state.get("task_list", [])
    current_index = state.get("current_task_index", 0)

    if current_index >= len(task_list):
        return {"error": "æ²¡æœ‰å¾…æ‰§è¡Œçš„ä»»åŠ¡"}

    current_task = task_list[current_index]
    description = current_task.get("description", "")
    input_data = current_task.get("input_data", {})

    started_at = datetime.now()

    try:
        # ä½¿ç”¨é…ç½®çš„æ¨¡å‹å’Œæ¸©åº¦å‚æ•°
        llm_with_config = llm.bind(
            model=model,
            temperature=temperature
        )

        response = await llm_with_config.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"ä»»åŠ¡æè¿°: {description}\n\nè¾“å…¥å‚æ•°:\n{format_input_data(input_data)}")
        ])

        completed_at = datetime.now()
        duration_ms = int((completed_at - started_at).total_seconds() * 1000)

        print(f"[{expert_key.upper()}] ä¸“å®¶å®Œæˆ (è€—æ—¶: {duration_ms/1000:.2f}s)")

        result = {
            "output_result": response.content,
            "status": "completed",
            "started_at": started_at.isoformat(),
            "completed_at": completed_at.isoformat(),
            "duration_ms": duration_ms
        }

        # æ ¹æ®ä¸“å®¶ç±»å‹ç¡®å®š artifact ç±»å‹
        artifact_type_map = {
            "coder": "code",
            "writer": "markdown",
            "search": "search",
            "planner": "markdown",
            "researcher": "markdown",
            "analyzer": "markdown",
            "image_analyzer": "text",
        }
        artifact_type = artifact_type_map.get(expert_key, "text")

        # æ·»åŠ  artifact
        result["artifact"] = {
            "type": artifact_type,
            "title": f"{expert_config['name']}ç»“æœ",
            "content": response.content,
            "source": f"{expert_key}_expert"
        }

        return result

    except Exception as e:
        print(f"[{expert_key.upper()}] ä¸“å®¶å¤±è´¥: {e}")
        return {
            "output_result": f"{expert_config['name']}å¤±è´¥: {str(e)}",
            "status": "failed",
            "error": str(e),
            "started_at": started_at.isoformat(),
            "completed_at": datetime.now().isoformat()
        }


def format_input_data(input_data: Dict) -> str:
    """æ ¼å¼åŒ–è¾“å…¥æ•°æ®ä¸ºæ–‡æœ¬"""
    if not input_data:
        return "ï¼ˆæ— é¢å¤–å‚æ•°ï¼‰"

    lines = []
    for key, value in input_data.items():
        if isinstance(value, (list, dict)):
            lines.append(f"- {key}: {value}")
        else:
            lines.append(f"- {key}: {value}")

    return "\n".join(lines)
