"""
Aggregator èŠ‚ç‚¹ - ç»“æœèšåˆå™¨

æ•´åˆå¤šä¸ªä¸“å®¶çš„è¾“å‡ºç»“æœï¼Œç”Ÿæˆè‡ªç„¶è¯­è¨€çš„æœ€ç»ˆå›å¤
v3.2 æ›´æ–°ï¼šä½¿ç”¨ç‹¬ç«‹æ•°æ®åº“ä¼šè¯ï¼Œé¿å… MemorySaver åºåˆ—åŒ–é—®é¢˜
"""
from typing import Dict, Any, List
import uuid
from langchain_core.messages import SystemMessage, HumanMessage
from sqlmodel import Session

from langchain_core.runnables import RunnableConfig

from agents.state import AgentState
from utils.llm_factory import get_aggregator_llm
from utils.event_generator import (
    event_message_delta, event_message_done, sse_event_to_string
)
from agents.services.task_manager import complete_task_session, save_aggregator_message
from database import engine


async def aggregator_node(state: AgentState, config: RunnableConfig = None) -> Dict[str, Any]:
    """
    èšåˆå™¨èŠ‚ç‚¹
    v3.1 æ›´æ–°ï¼šè°ƒç”¨ LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€æ€»ç»“ï¼Œæ”¯æŒæµå¼è¾“å‡º
    v3.2 æ›´æ–°ï¼šä½¿ç”¨ç‹¬ç«‹æ•°æ®åº“ä¼šè¯ï¼Œé¿å… MemorySaver åºåˆ—åŒ–é—®é¢˜
    v3.3 æ›´æ–°ï¼šä½¿ç”¨äº‹ä»¶é©±åŠ¨æµå¼è¾“å‡ºï¼Œé€šè¿‡ event_queue å®æ—¶æ¨é€ message.delta äº‹ä»¶
    """
    expert_results = state["expert_results"]
    strategy = state["strategy"]
    task_list = state.get("task_list", [])  # âœ… è·å– task_list ä»¥ä¾¿è¿”å›

    # è·å– task_session_id å’Œå…¶ä»–çŠ¶æ€
    task_session_id = state.get("task_session_id")
    event_queue = state.get("event_queue", [])
    # v3.0: è·å–å‰ç«¯ä¼ é€’çš„ message_idï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    message_id = state.get("message_id", str(uuid.uuid4()))
    thread_id = state.get("thread_id")  # ğŸ”¥ ç”¨äºä¿å­˜æ¶ˆæ¯åˆ°æ­£ç¡®çº¿ç¨‹

    if not expert_results:
        return {
            "task_list": state.get("task_list", []),  # âœ… æ·»åŠ  task_list
            "final_response": "æœªç”Ÿæˆä»»ä½•æ‰§è¡Œç»“æœã€‚",
            "event_queue": event_queue
        }

    print(f"[AGG] æ­£åœ¨èšåˆ {len(expert_results)} ä¸ªç»“æœï¼Œè°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“...")

    # v3.1: æ„å»º Aggregator çš„ Prompt
    aggregator_prompt = _build_aggregator_prompt(expert_results, strategy)
    
    # v3.1: è·å– Aggregator LLMï¼ˆå¸¦å…œåº•é€»è¾‘ï¼‰
    aggregator_llm = get_aggregator_llm()
    
    # v3.1: æµå¼ç”Ÿæˆæ€»ç»“
    final_response_chunks = []
    
    try:
        # ä½¿ç”¨æµå¼è¾“å‡º
        async for chunk in aggregator_llm.astream([
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ¥å‘Šæ’°å†™ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å¤šä¸ªä¸“å®¶çš„åˆ†æç»“æœæ•´åˆæˆä¸€ä»½è¿è´¯ã€ä¸“ä¸šçš„æœ€ç»ˆæŠ¥å‘Šã€‚ä¸è¦ç®€å•ç½—åˆ—ï¼Œè¦ç”¨è‡ªç„¶æµç•…çš„è¯­è¨€è¿›è¡Œæ€»ç»“ã€‚"),
            HumanMessage(content=aggregator_prompt)
        ]):
            content = chunk.content if hasattr(chunk, 'content') else str(chunk)
            if content:
                final_response_chunks.append(content)
                
                # å‘é€ message.delta äº‹ä»¶ï¼ˆå®æ—¶æµå¼ï¼‰
                delta_event = event_message_delta(
                    message_id=message_id,
                    content=content,
                    is_final=False
                )
                event_str = sse_event_to_string(delta_event)
                event_queue.append({"type": "sse", "event": event_str})
        
        final_response = "".join(final_response_chunks)
        
    except Exception as e:
        print(f"[AGG] LLM æ€»ç»“å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•æ‹¼æ¥: {e}")
        # å…œåº•ï¼šä½¿ç”¨ç®€å•æ‹¼æ¥
        final_response = _build_markdown_response(expert_results, strategy)
        
        # å‘é€ç®€å•æ‹¼æ¥çš„ç»“æœ
        chunk_size = 100
        for i in range(0, len(final_response), chunk_size):
            chunk = final_response[i:i + chunk_size]
            is_final = (i + chunk_size) >= len(final_response)
            delta_event = event_message_delta(
                message_id=message_id,
                content=chunk,
                is_final=is_final
            )
            event_str = sse_event_to_string(delta_event)
            event_queue.append({"type": "sse", "event": event_str})
    
    # å‘é€ message.done äº‹ä»¶
    done_event = event_message_done(
        message_id=message_id,
        full_content=final_response
    )
    event_queue.append({"type": "sse", "event": sse_event_to_string(done_event)})
    
    # v3.2: æ›´æ–°ä»»åŠ¡ä¼šè¯çŠ¶æ€å¹¶æŒä¹…åŒ–èšåˆæ¶ˆæ¯ (é€šè¿‡ TaskManager)
    # ğŸ”¥ ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯ï¼ˆé¿å… MemorySaver åºåˆ—åŒ–é—®é¢˜ï¼‰
    if task_session_id:
        try:
            with Session(engine) as db_session:
                # æ ‡è®°ä»»åŠ¡ä¼šè¯ä¸ºå·²å®Œæˆ
                complete_task_session(db_session, task_session_id, final_response)

                # æŒä¹…åŒ–èšåˆæ¶ˆæ¯åˆ°æ•°æ®åº“
                if thread_id:
                    save_aggregator_message(db_session, thread_id, final_response)
        except Exception as e:
            print(f"[AGG] ä¿å­˜ä»»åŠ¡ä¼šè¯å¤±è´¥: {e}")
    
    print(f"[AGG] èšåˆå®Œæˆï¼Œå›å¤é•¿åº¦: {len(final_response)}")

    # âœ… è¿”å› task_list ä»¥ç¡®ä¿ chat.py èƒ½æ”¶é›†åˆ°æ‰€æœ‰ä»»åŠ¡çŠ¶æ€
    return {
        "task_list": task_list,  # âœ… æ·»åŠ  task_list
        "final_response": final_response,
        "event_queue": event_queue
    }


def _build_aggregator_prompt(expert_results: List[Dict[str, Any]], strategy: str) -> str:
    """
    æ„å»º Aggregator çš„ Promptï¼Œå°†å¤šä¸ªä¸“å®¶ç»“æœè½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æ€»ç»“çš„è¾“å…¥
    
    Args:
        expert_results: ä¸“å®¶æ‰§è¡Œç»“æœåˆ—è¡¨
        strategy: æ‰§è¡Œç­–ç•¥æ¦‚è¿°
        
    Returns:
        str: ä¾› LLM æ€»ç»“çš„ Prompt
    """
    lines = [
        f"æ‰§è¡Œç­–ç•¥: {strategy}",
        "",
        "å„ä¸“å®¶åˆ†æç»“æœå¦‚ä¸‹ï¼š",
        ""
    ]
    
    for i, res in enumerate(expert_results, 1):
        lines.append(f"ã€ä¸“å®¶ {i}: {res['expert_type'].upper()}ã€‘")
        lines.append(f"ä»»åŠ¡æè¿°: {res['description']}")
        lines.append(f"åˆ†æç»“æœ:\n{res['output']}")
        lines.append("")
    
    lines.extend([
        "---",
        "",
        "è¯·åŸºäºä»¥ä¸Šå„ä¸“å®¶çš„åˆ†æç»“æœï¼Œæ’°å†™ä¸€ä»½è¿è´¯ã€ä¸“ä¸šçš„æœ€ç»ˆæ€»ç»“æŠ¥å‘Šã€‚è¦æ±‚ï¼š",
        "1. ç”¨è‡ªç„¶æµç•…çš„è¯­è¨€æ•´åˆæ‰€æœ‰ä¸“å®¶çš„è§‚ç‚¹ï¼Œä¸è¦ç®€å•ç½—åˆ—",
        "2. çªå‡ºå…³é”®å‘ç°å’Œæ ¸å¿ƒç»“è®º",
        "3. ä¿æŒé€»è¾‘æ¸…æ™°ï¼Œç»“æ„å®Œæ•´",
        "4. å¦‚æœä¸“å®¶ç»“æœä¹‹é—´æœ‰ä¾èµ–å…³ç³»ï¼Œè¯·ä½“ç°è¿™ç§å…³è”",
        ""
    ])
    
    return "\n".join(lines)


def _build_markdown_response(expert_results: List[Dict[str, Any]], strategy: str) -> str:
    """
    æ„å»º Markdown æ ¼å¼çš„ç®€å•å›å¤ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
    """
    lines = [f"# æ‰§è¡ŒæŠ¥å‘Š\n**ç­–ç•¥**: {strategy}\n---"]
    for i, res in enumerate(expert_results, 1):
        lines.append(f"## {i}. {res['expert_type'].upper()}: {res['description']}")
        lines.append(f"{res['output']}\n")
    return "\n".join(lines)
