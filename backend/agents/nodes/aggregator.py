"""
Aggregator èŠ‚ç‚¹ - ç»“æœèšåˆå™¨

æ•´åˆå¤šä¸ªä¸“å®¶çš„è¾“å‡ºç»“æœï¼Œç”Ÿæˆè‡ªç„¶è¯­è¨€çš„æœ€ç»ˆå›å¤
v3.2 æ›´æ–°ï¼šä½¿ç”¨ç‹¬ç«‹æ•°æ®åº“ä¼šè¯ï¼Œé¿å… MemorySaver åºåˆ—åŒ–é—®é¢˜
v3.5 æ›´æ–°ï¼šå®ç°ä¸‰å±‚å…œåº•æç¤ºè¯ä½“ç³» (DB -> Cache -> Constants)
"""
from typing import Dict, Any, List
import uuid
from langchain_core.messages import SystemMessage, HumanMessage
from sqlmodel import Session

from langchain_core.runnables import RunnableConfig

from agents.state import AgentState
from utils.llm_factory import get_aggregator_llm
from utils.event_generator import (
    event_message_delta, event_message_done, sse_event_to_string
)
from agents.services.task_manager import complete_task_session, save_aggregator_message
from agents.services.expert_manager import get_expert_config_cached
from database import engine
from constants import AGGREGATOR_SYSTEM_PROMPT
from utils.logger import logger


async def aggregator_node(state: AgentState, config: RunnableConfig = None) -> Dict[str, Any]:
    """
    èšåˆå™¨èŠ‚ç‚¹
    v3.1 æ›´æ–°ï¼šè°ƒç”¨ LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€æ€»ç»“ï¼Œæ”¯æŒæµå¼è¾“å‡º
    v3.2 æ›´æ–°ï¼šä½¿ç”¨ç‹¬ç«‹æ•°æ®åº“ä¼šè¯ï¼Œé¿å… MemorySaver åºåˆ—åŒ–é—®é¢˜
    v3.3 æ›´æ–°ï¼šä½¿ç”¨äº‹ä»¶é©±åŠ¨æµå¼è¾“å‡ºï¼Œé€šè¿‡ event_queue å®æ—¶æ¨é€ message.delta äº‹ä»¶
    v3.5 æ›´æ–°ï¼šå®ç°ä¸‰å±‚å…œåº•æç¤ºè¯ä½“ç³» (DB -> Cache -> Constants)
    """
    expert_results = state["expert_results"]
    strategy = state["strategy"]
    task_list = state.get("task_list", [])  # âœ… è·å– task_list ä»¥ä¾¿è¿”å›

    # è·å– task_session_id å’Œå…¶ä»–çŠ¶æ€
    task_session_id = state.get("task_session_id")
    event_queue = state.get("event_queue", [])
    # v3.0: è·å–å‰ç«¯ä¼ é€’çš„ message_idï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    message_id = state.get("message_id", str(uuid.uuid4()))
    thread_id = state.get("thread_id")  # ğŸ”¥ ç”¨äºä¿å­˜æ¶ˆæ¯åˆ°æ­£ç¡®çº¿ç¨‹

    if not expert_results:
        return {
            "task_list": state.get("task_list", []),  # âœ… æ·»åŠ  task_list
            "final_response": "æœªç”Ÿæˆä»»ä½•æ‰§è¡Œç»“æœã€‚",
            "event_queue": event_queue
        }

    logger.info(f"[AGG] æ­£åœ¨èšåˆ {len(expert_results)} ä¸ªç»“æœï¼Œè°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“...")

    # v3.5: æ„å»º Aggregator çš„ Promptï¼ˆä¸“å®¶æˆæœæ‘˜è¦ï¼‰
    aggregator_input = _build_aggregator_input(expert_results, strategy)
    
    # v3.5: ä¸‰å±‚å…œåº•åŠ è½½ System Prompt (L1: DB -> L2: Cache -> L3: Constants)
    system_prompt = _load_aggregator_system_prompt(aggregator_input)
    logger.info(f"[AGG] System Prompt é•¿åº¦: {len(system_prompt)} å­—ç¬¦")
    
    # v3.1: è·å– Aggregator LLMï¼ˆå¸¦å…œåº•é€»è¾‘ï¼‰
    aggregator_llm = get_aggregator_llm()
    
    # v3.1: æµå¼ç”Ÿæˆæ€»ç»“
    final_response_chunks = []
    
    try:
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ  metadata æ ‡è®°ä¸º aggregator èŠ‚ç‚¹
        # transform_langgraph_event ä¼šè¯†åˆ«å¹¶å…è®¸ aggregator èŠ‚ç‚¹çš„ message.delta
        # è¿™æ ·é€šè¿‡ LangGraph çš„ on_chat_model_stream äº‹ä»¶å‘é€ï¼Œé¿å…ä¸ event_queue é‡å¤
        aggregator_config = RunnableConfig(
            tags=["aggregator"],
            metadata={"node_type": "aggregator"}
        )
        
        # ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆé€šè¿‡ LangGraph çš„ on_chat_model_stream äº‹ä»¶å‘é€ message.deltaï¼‰
        async for chunk in aggregator_llm.astream(
            [
                SystemMessage(content=system_prompt),
                HumanMessage(content=aggregator_input)
            ],
            config=aggregator_config
        ):
            content = chunk.content if hasattr(chunk, 'content') else str(chunk)
            if content:
                final_response_chunks.append(content)
                # ğŸ”¥ ç§»é™¤ï¼šä¸å†é€šè¿‡ event_queue å‘é€ message.delta
                # è®© transform_langgraph_event ç»Ÿä¸€å¤„ç†ï¼Œé¿å…é‡å¤
        
        final_response = "".join(final_response_chunks)
        
    except Exception as e:
        logger.warning(f"[AGG] LLM æ€»ç»“å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•æ‹¼æ¥: {e}")
        # å…œåº•ï¼šä½¿ç”¨ç®€å•æ‹¼æ¥
        final_response = _build_markdown_response(expert_results, strategy)
        
        # ğŸ”¥ å…œåº•æƒ…å†µï¼šé€šè¿‡ event_queue å‘é€ï¼ˆå› ä¸ºæ²¡æœ‰ LLM è°ƒç”¨ï¼‰
        chunk_size = 100
        for i in range(0, len(final_response), chunk_size):
            chunk = final_response[i:i + chunk_size]
            delta_event = event_message_delta(
                message_id=message_id,
                content=chunk,
                is_final=False
            )
            event_str = sse_event_to_string(delta_event)
            event_queue.append({"type": "sse", "event": event_str})
    
    # å‘é€ message.done äº‹ä»¶
    done_event = event_message_done(
        message_id=message_id,
        full_content=final_response
    )
    event_queue.append({"type": "sse", "event": sse_event_to_string(done_event)})
    
    # v3.2: æ›´æ–°ä»»åŠ¡ä¼šè¯çŠ¶æ€å¹¶æŒä¹…åŒ–èšåˆæ¶ˆæ¯ (é€šè¿‡ TaskManager)
    # ğŸ”¥ ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯ï¼ˆé¿å… MemorySaver åºåˆ—åŒ–é—®é¢˜ï¼‰
    if task_session_id:
        try:
            with Session(engine) as db_session:
                # æ ‡è®°ä»»åŠ¡ä¼šè¯ä¸ºå·²å®Œæˆ
                complete_task_session(db_session, task_session_id, final_response)

                # æŒä¹…åŒ–èšåˆæ¶ˆæ¯åˆ°æ•°æ®åº“
                if thread_id:
                    save_aggregator_message(db_session, thread_id, final_response)
        except Exception as e:
            logger.warning(f"[AGG] ä¿å­˜ä»»åŠ¡ä¼šè¯å¤±è´¥: {e}")
    
    logger.info(f"[AGG] èšåˆå®Œæˆï¼Œå›å¤é•¿åº¦: {len(final_response)}")

    # âœ… è¿”å› task_list ä»¥ç¡®ä¿ chat.py èƒ½æ”¶é›†åˆ°æ‰€æœ‰ä»»åŠ¡çŠ¶æ€
    return {
        "task_list": task_list,  # âœ… æ·»åŠ  task_list
        "final_response": final_response,
        "event_queue": event_queue
    }


def _load_aggregator_system_prompt(input_data: str) -> str:
    """
    v3.5: ä¸‰å±‚å…œåº•åŠ è½½ Aggregator System Prompt
    
    L1: SystemExpert æ•°æ®åº“è¡¨
    L2: å†…å­˜ç¼“å­˜
    L3: constants.AGGREGATOR_SYSTEM_PROMPT (é™æ€å…œåº•)
    
    Args:
        input_data: è¦æ³¨å…¥åˆ° {input} å ä½ç¬¦çš„æ•°æ®
        
    Returns:
        str: å¤„ç†åçš„ System Prompt
    """
    system_prompt = None
    
    # L1/L2: å°è¯•ä»æ•°æ®åº“/ç¼“å­˜åŠ è½½
    try:
        config = get_expert_config_cached("aggregator")
        if config and config.get("system_prompt"):
            system_prompt = config["system_prompt"]
            logger.info("[AGG] ä»æ•°æ®åº“/ç¼“å­˜åŠ è½½ System Prompt")
    except Exception as e:
        logger.warning(f"[AGG] ä»æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
    
    # L3: å…œåº•åˆ°é™æ€å¸¸é‡
    if not system_prompt:
        system_prompt = AGGREGATOR_SYSTEM_PROMPT
        logger.info("[AGG] ä½¿ç”¨é™æ€å¸¸é‡ System Prompt (L3å…œåº•)")
    
    # æ³¨å…¥ {input} å ä½ç¬¦
    if "{input}" in system_prompt:
        system_prompt = system_prompt.replace("{input}", input_data)
        logger.info("[AGG] å·²æ³¨å…¥ {input} å ä½ç¬¦")
    
    return system_prompt


def _build_aggregator_input(expert_results: List[Dict[str, Any]], strategy: str) -> str:
    """
    v3.5: æ„å»º Aggregator çš„è¾“å…¥æ•°æ®ï¼ˆæ³¨å…¥åˆ° System Prompt çš„ {input} å ä½ç¬¦ï¼‰
    
    å°†å¤šä¸ªä¸“å®¶ç»“æœæ ¼å¼åŒ–ä¸ºç»“æ„åŒ–æ–‡æœ¬ï¼Œä¾› Aggregator æ•´åˆã€‚
    
    Args:
        expert_results: ä¸“å®¶æ‰§è¡Œç»“æœåˆ—è¡¨
        strategy: æ‰§è¡Œç­–ç•¥æ¦‚è¿°
        
    Returns:
        str: ä¾›æ³¨å…¥çš„è¾“å…¥æ–‡æœ¬
    """
    lines = [
        f"ã€æ‰§è¡Œç­–ç•¥ã€‘: {strategy}",
        "",
        f"ã€ä¸“å®¶æˆæœæ±‡æ€»ã€‘: å…± {len(expert_results)} ä½ä¸“å®¶å‚ä¸åˆ†æ",
        ""
    ]
    
    for i, res in enumerate(expert_results, 1):
        lines.append(f"--- ä¸“å®¶ {i}: {res['expert_type'].upper()} ---")
        lines.append(f"ä»»åŠ¡: {res['description']}")
        lines.append(f"æˆæœ:\n{res['output']}")
        lines.append("")
    
    return "\n".join(lines)


def _build_markdown_response(expert_results: List[Dict[str, Any]], strategy: str) -> str:
    """
    æ„å»º Markdown æ ¼å¼çš„ç®€å•å›å¤ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰
    """
    lines = [f"# æ‰§è¡ŒæŠ¥å‘Š\n**ç­–ç•¥**: {strategy}\n---"]
    for i, res in enumerate(expert_results, 1):
        lines.append(f"## {i}. {res['expert_type'].upper()}: {res['description']}")
        lines.append(f"{res['output']}\n")
    return "\n".join(lines)
