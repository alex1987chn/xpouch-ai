"""
Router èŠ‚ç‚¹ - æ„å›¾è¯†åˆ«

è´Ÿè´£å°†ç”¨æˆ·è¾“å…¥åˆ†ç±»ä¸º simple æˆ– complex æ¨¡å¼
é›†æˆé•¿æœŸè®°å¿†æ£€ç´¢ï¼Œæä¾›ä¸ªæ€§åŒ–è·¯ç”±å†³ç­–
v3.5 æ›´æ–°ï¼šä½¿ç”¨æ•°æ®åº“é…ç½® + å ä½ç¬¦åŠ¨æ€å¡«å……
v3.6 æ›´æ–°ï¼šä½¿ç”¨ prompt_utils.inject_current_time æ›¿ä»£å†…è”å®ç°
"""
from datetime import datetime
from typing import Dict, Any, Literal
from langchain_core.messages import SystemMessage
from langchain_core.runnables import RunnableConfig
from pydantic import BaseModel, Field

from agents.state import AgentState
from constants import ROUTER_SYSTEM_PROMPT, DEFAULT_ASSISTANT_PROMPT
from services.memory_manager import memory_manager  # ğŸ”¥ å¯¼å…¥è®°å¿†ç®¡ç†å™¨
from utils.event_generator import event_router_start, event_router_decision, sse_event_to_string
from agents.services.expert_manager import get_expert_config_cached
from utils.prompt_utils import inject_current_time  # v3.6: æå–åˆ°å·¥å…·å‡½æ•°


class RoutingDecision(BaseModel):
    """v2.7 ç½‘å…³å†³ç­–ç»“æ„ï¼ˆRouteråªè´Ÿè´£åˆ†ç±»ï¼‰"""
    decision_type: Literal["simple", "complex"] = Field(description="å†³ç­–ç±»å‹")


async def router_node(state: AgentState, config: RunnableConfig = None) -> Dict[str, Any]:
    """
    [ç½‘å…³] åªè´Ÿè´£åˆ†ç±»ï¼Œä¸è´Ÿè´£å›ç­”

    æ ¹æ®ç”¨æˆ·è¾“å…¥åˆ¤æ–­åº”è¯¥ä½¿ç”¨ simple æ¨¡å¼ï¼ˆç›´æ¥å›å¤ï¼‰
    è¿˜æ˜¯ complex æ¨¡å¼ï¼ˆå¤šä¸“å®¶åä½œï¼‰

    P1 ä¼˜åŒ–: ç»Ÿä¸€ Node ç­¾åï¼Œæ·»åŠ  config å‚æ•°
    
    ğŸ”¥ æ–°å¢ï¼šæ£€ç´¢é•¿æœŸè®°å¿†ï¼Œæä¾›ä¸ªæ€§åŒ–å†³ç­–
    ğŸ”¥ ä¿®å¤ï¼šæ¯æ¬¡ç”¨æˆ·æ–°è¾“å…¥éƒ½é‡æ–°åˆ¤æ–­ï¼Œä¸å—å†å² task_list å½±å“
    ğŸ”¥ Phase 3: å‘é€ router.start å’Œ router.decision SSE äº‹ä»¶
    """
    messages = state["messages"]
    last_message = messages[-1]
    user_query = last_message.content if hasattr(last_message, 'content') else str(last_message)

    # v3.1 ä¿®å¤ï¼šç§»é™¤æ–­ç‚¹æ¢å¤æ£€æŸ¥ï¼Œæ¯æ¬¡ç”¨æˆ·æ–°è¾“å…¥éƒ½é‡æ–°åˆ¤æ–­
    # ä¹‹å‰çš„é€»è¾‘ä¼šå¯¼è‡´ Complex æ¨¡å¼ç»“æŸåï¼Œæ–°æ¶ˆæ¯ä»è¢«åˆ¤å®šä¸º Complex
    # å¦‚æœéœ€è¦æ–­ç‚¹æ¢å¤ï¼Œåº”è¯¥ç”±å‰ç«¯æ˜¾å¼ä¼ é€’æ¢å¤ä¿¡å·ï¼Œè€Œä¸æ˜¯è‡ªåŠ¨åˆ¤æ–­

    # ğŸ”¥ ä» state è·å– user_idï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
    # åç»­å¯ä»¥ä»è¯·æ±‚ header æˆ–ä¸Šä¸‹æ–‡ä¼ é€’ user_id
    user_id = state.get("user_id", "default_user")

    print(f"--- [Router] æ­£åœ¨æ€è€ƒ: {user_query[:100]}... ---")

    # ğŸ”¥ Phase 3: åˆå§‹åŒ–äº‹ä»¶é˜Ÿåˆ—ï¼Œå‘é€ router.start äº‹ä»¶
    event_queue = state.get("event_queue", [])
    start_event = event_router_start(query=user_query[:200])  # é™åˆ¶é•¿åº¦
    event_queue.append({"type": "sse", "event": sse_event_to_string(start_event)})
    print(f"[Router] å·²å‘é€ router.start äº‹ä»¶")

    # 1. ğŸ”¥ æ£€ç´¢é•¿æœŸè®°å¿†ï¼ˆå¼‚æ­¥ï¼‰
    try:
        relevant_memories = await memory_manager.search_relevant_memories(user_id, user_query, limit=3)
    except Exception as e:
        print(f"[Router] è®°å¿†æ£€ç´¢å¤±è´¥: {e}")
        relevant_memories = ""

    # 2. ğŸ”¥ v3.5: åŠ è½½ System Promptï¼ˆDB -> Cache -> Constants å…œåº•ï¼‰
    system_prompt = _load_router_system_prompt()
    
    # 3. ğŸ”¥ v3.5: å¡«å……å ä½ç¬¦
    system_prompt = _fill_router_placeholders(
        system_prompt=system_prompt,
        user_query=user_query,
        relevant_memories=relevant_memories
    )
    print(f"[Router] System Prompt å·²åŠ è½½å¹¶å¡«å……å ä½ç¬¦")

    try:
        # ğŸ”¥ v3.7: ä½¿ç”¨ with_structured_output æ›¿ä»£ PydanticOutputParser
        # æ›´ç°ä»£ã€ç±»å‹å®‰å…¨ï¼Œåˆ©ç”¨æ¨¡å‹åŸç”Ÿ JSON æ¨¡å¼
        from agents.graph import get_router_llm_lazy
        llm_structured = get_router_llm_lazy().with_structured_output(RoutingDecision)
        decision = await llm_structured.ainvoke(
            [
                SystemMessage(content=system_prompt),
                *messages  # ç”¨æˆ·çš„è¾“å…¥åœ¨è¿™é‡Œ
            ],
            config={"tags": ["router"], "metadata": {"node_type": "router"}}
        )
        print(f"[Router] å†³ç­–ç»“æœ: {decision.decision_type if hasattr(decision, 'decision_type') else decision}")

        # ğŸ”¥ Phase 3: å‘é€ router.decision äº‹ä»¶
        decision_event = event_router_decision(
            decision=decision.decision_type,
            reason=f"Based on query complexity analysis"
        )
        event_queue.append({"type": "sse", "event": sse_event_to_string(decision_event)})
        print(f"[Router] å·²å‘é€ router.decision äº‹ä»¶: {decision.decision_type}")

        return {
            "router_decision": decision.decision_type,
            "event_queue": event_queue  # è¿”å›äº‹ä»¶é˜Ÿåˆ—
        }
    except Exception as e:
        print(f"[ROUTER ERROR] {e}")

        # ğŸ”¥ Phase 3: é”™è¯¯æ—¶ä¹Ÿå‘é€ decision äº‹ä»¶ï¼ˆfallback åˆ° complexï¼‰
        decision_event = event_router_decision(
            decision="complex",
            reason=f"Router error, fallback to complex mode: {str(e)}"
        )
        event_queue.append({"type": "sse", "event": sse_event_to_string(decision_event)})
        print(f"[Router] é”™è¯¯ï¼Œå·²å‘é€ fallback router.decision äº‹ä»¶")

        return {
            "router_decision": "complex",
            "event_queue": event_queue
        }


def _load_router_system_prompt() -> str:
    """
    v3.5: ä¸‰å±‚å…œåº•åŠ è½½ Router System Prompt
    
    L1: SystemExpert æ•°æ®åº“è¡¨
    L2: å†…å­˜ç¼“å­˜
    L3: constants.ROUTER_SYSTEM_PROMPT (é™æ€å…œåº•)
    """
    # L1/L2: å°è¯•ä»æ•°æ®åº“/ç¼“å­˜åŠ è½½
    try:
        config = get_expert_config_cached("router")
        if config and config.get("system_prompt"):
            print("[Router] ä»æ•°æ®åº“/ç¼“å­˜åŠ è½½ System Prompt")
            return config["system_prompt"]
    except Exception as e:
        print(f"[Router] ä»æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
    
    # L3: å…œåº•åˆ°é™æ€å¸¸é‡
    print("[Router] ä½¿ç”¨é™æ€å¸¸é‡ System Prompt (L3å…œåº•)")
    return ROUTER_SYSTEM_PROMPT


def _fill_router_placeholders(
    system_prompt: str,
    user_query: str,
    relevant_memories: str
) -> str:
    """
    v3.5: å¡«å…… Router System Prompt ä¸­çš„å ä½ç¬¦
    
    å ä½ç¬¦:
    - {user_query}: ç”¨æˆ·æŸ¥è¯¢
    - {current_time}: å½“å‰æ—¶é—´
    - {relevant_memories}: ç›¸å…³è®°å¿†
    """
    # å‡†å¤‡æ—¶é—´ä¿¡æ¯
    now = datetime.now()
    weekdays = ["æ˜ŸæœŸä¸€", "æ˜ŸæœŸäºŒ", "æ˜ŸæœŸä¸‰", "æ˜ŸæœŸå››", "æ˜ŸæœŸäº”", "æ˜ŸæœŸå…­", "æ˜ŸæœŸæ—¥"]
    weekday_str = weekdays[now.weekday()]
    time_str = now.strftime(f"%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S {weekday_str}")
    
    # æ„å»ºå ä½ç¬¦æ˜ å°„
    placeholder_map = {
        "user_query": user_query,
        "current_time": time_str,
        "relevant_memories": relevant_memories if relevant_memories else "ï¼ˆæš‚æ— è®°å¿†ï¼‰"
    }
    
    # æ›¿æ¢æ‰€æœ‰æ”¯æŒçš„å ä½ç¬¦
    for placeholder, value in placeholder_map.items():
        placeholder_pattern = f"{{{placeholder}}}"
        if placeholder_pattern in system_prompt:
            system_prompt = system_prompt.replace(placeholder_pattern, value)
            print(f"[Router] å·²æ³¨å…¥å ä½ç¬¦: {{{placeholder}}}")
    
    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªå¡«å……çš„å ä½ç¬¦ï¼ˆè­¦å‘Šä½†ä¸ä¸­æ–­ï¼‰
    import re
    remaining_placeholders = re.findall(r'\{([a-zA-Z_][a-zA-Z0-9_]*)\}', system_prompt)
    if remaining_placeholders:
        print(f"[Router] è­¦å‘Š: ä»¥ä¸‹å ä½ç¬¦æœªå¡«å……: {remaining_placeholders}")
    
    return system_prompt


async def direct_reply_node(state: AgentState, config: RunnableConfig = None) -> Dict[str, Any]:
    """
    [ç›´è¿èŠ‚ç‚¹] è´Ÿè´£ Simple æ¨¡å¼ä¸‹çš„æµå¼å›å¤
    
    ç›´æ¥è°ƒç”¨ LLM ç”Ÿæˆå›å¤ï¼Œä¸ç»è¿‡å¤æ‚çš„å¤šä¸“å®¶æµç¨‹
    
    P1 ä¼˜åŒ–: ç»Ÿä¸€ Node ç­¾åï¼Œæ·»åŠ  config å‚æ•°
    
    ğŸ”¥ æ–°å¢ï¼šé›†æˆé•¿æœŸè®°å¿†ï¼Œæä¾›ä¸ªæ€§åŒ–å›å¤
    """
    print(f"[DIRECT_REPLY] èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ")
    messages = state["messages"]
    last_message = messages[-1]
    user_query = last_message.content if hasattr(last_message, 'content') else str(last_message)

    # ğŸ”¥ ä» state è·å– user_id
    user_id = state.get("user_id", "default_user")

    # 1. ğŸ”¥ æ£€ç´¢é•¿æœŸè®°å¿†ï¼ˆå¼‚æ­¥ï¼‰
    try:
        relevant_memories = await memory_manager.search_relevant_memories(user_id, user_query, limit=5)
    except Exception as e:
        print(f"[DirectReply] è®°å¿†æ£€ç´¢å¤±è´¥: {e}")
        relevant_memories = ""

    # 2. ğŸ”¥ æ„å»º System Promptï¼ˆæ³¨å…¥è®°å¿†å’Œæ—¶é—´ï¼‰
    system_prompt = DEFAULT_ASSISTANT_PROMPT
    if relevant_memories:
        print(f"[DirectReply] æ¿€æ´»è®°å¿†:\n{relevant_memories}")
        system_prompt += f"""

ã€å…³äºè¯¥ç”¨æˆ·çš„å·²çŸ¥ä¿¡æ¯ã€‘:
{relevant_memories}
(è¯·åœ¨å›ç­”æ—¶è‡ªç„¶åœ°åˆ©ç”¨è¿™äº›ä¿¡æ¯ï¼Œæä¾›æ›´ä¸ªæ€§åŒ–çš„å›å¤)"""

    # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ³¨å…¥å½“å‰æ—¶é—´
    system_prompt = inject_current_time(system_prompt)
    print(f"[DirectReply] å·²æ³¨å…¥å½“å‰æ—¶é—´åˆ° System Prompt")

    # ä½¿ç”¨æµå¼é…ç½®ï¼Œæ·»åŠ  metadata ä¾¿äºè¿½è¸ª
    config = {"tags": ["direct_reply"], "metadata": {"node_type": "direct_reply"}}
    
    # Simple æ¨¡å¼ä½¿ç”¨ MiniMaxï¼ˆå“åº”æœ€å¿«ï¼‰
    from agents.graph import get_simple_llm_lazy
    response = await get_simple_llm_lazy().ainvoke(
        [
            SystemMessage(content=system_prompt),
            *messages  # ç”¨æˆ·çš„å†å²æ¶ˆæ¯ä¸Šä¸‹æ–‡
        ],
        config=config
    )

    print(f"[DIRECT_REPLY] èŠ‚ç‚¹å®Œæˆï¼Œå›å¤é•¿åº¦: {len(response.content)}")

    # ç›´æ¥è¿”å› response å¯¹è±¡ï¼ˆä¿ç•™å®Œæ•´å…ƒæ•°æ®ï¼‰ï¼Œå¹¶æ·»åŠ  final_response å­—æ®µ
    return {
        "messages": [response],
        "final_response": response.content
    }
