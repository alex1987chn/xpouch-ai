"""
é€šç”¨ä¸“å®¶æ‰§è¡ŒèŠ‚ç‚¹

ç”¨äºå¤„ç†åŠ¨æ€åˆ›å»ºçš„è‡ªå®šä¹‰ä¸“å®¶ï¼Œæ ¹æ® state["current_task"]["expert_type"]
ä»æ•°æ®åº“åŠ è½½ä¸“å®¶é…ç½®å¹¶æ‰§è¡Œã€‚
"""
import os
import re
import asyncio  # ğŸ”¥ æ–°å¢ï¼šç”¨äºå¼‚æ­¥ä¿å­˜ä¸“å®¶æ‰§è¡Œç»“æœ
from typing import Dict, Any, Optional
from datetime import datetime
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.runnables import RunnableConfig

from agents.state import AgentState
from agents.services.expert_manager import get_expert_config_cached
from utils.llm_factory import get_effective_model, get_expert_llm
from providers_config import get_model_config


async def generic_worker_node(state: Dict[str, Any], llm=None) -> Dict[str, Any]:
    """
    é€šç”¨ä¸“å®¶æ‰§è¡ŒèŠ‚ç‚¹
    
    æ ¹æ® state["current_task"]["expert_type"] ä»æ•°æ®åº“åŠ è½½ä¸“å®¶é…ç½®å¹¶æ‰§è¡Œã€‚
    ç”¨äºå¤„ç†åŠ¨æ€åˆ›å»ºçš„è‡ªå®šä¹‰ä¸“å®¶ã€‚
    
    Args:
        state: AgentStateï¼ŒåŒ…å« task_list, current_task_index ç­‰
        llm: å¯é€‰çš„ LLM å®ä¾‹ï¼Œå¦‚æœä¸æä¾›åˆ™æ ¹æ®ä¸“å®¶é…ç½®åˆ›å»º
    
    Returns:
        Dict: æ‰§è¡Œç»“æœï¼ŒåŒ…å« output_result, status, artifact ç­‰
    """
    # è·å–å½“å‰ä»»åŠ¡
    task_list = state.get("task_list", [])
    current_index = state.get("current_task_index", 0)
    
    if current_index >= len(task_list):
        return {
            "output_result": "æ²¡æœ‰å¾…æ‰§è¡Œçš„ä»»åŠ¡",
            "status": "failed",
            "error": "Task index out of range",
            "started_at": datetime.now().isoformat(),
            "completed_at": datetime.now().isoformat()
        }
    
    current_task = task_list[current_index]
    expert_type = current_task.get("expert_type", "")
    description = current_task.get("description", "")
    input_data = current_task.get("input_data", {})
    
    if not expert_type:
        return {
            "output_result": "ä»»åŠ¡ç¼ºå°‘ expert_type å­—æ®µ",
            "status": "failed",
            "error": "Missing expert_type in task",
            "started_at": datetime.now().isoformat(),
            "completed_at": datetime.now().isoformat()
        }
    
    # ä»ç¼“å­˜åŠ è½½ä¸“å®¶é…ç½®
    expert_config = get_expert_config_cached(expert_type)
    
    # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œå¯èƒ½æ˜¯è‡ªå®šä¹‰ä¸“å®¶ï¼Œå°è¯•ç›´æ¥æŸ¥æ•°æ®åº“
    if not expert_config:
        print(f"[GenericWorker] ç¼“å­˜ä¸­æœªæ‰¾åˆ° '{expert_type}'ï¼Œå°è¯•ä»æ•°æ®åº“åŠ è½½...")
        from database import engine
        from sqlmodel import Session
        from agents.services.expert_manager import get_expert_config
        
        with Session(engine) as session:
            expert_config = get_expert_config(expert_type, session)
            if expert_config:
                print(f"[GenericWorker] ä»æ•°æ®åº“åŠ è½½ '{expert_type}' æˆåŠŸ")
    
    if not expert_config:
        return {
            "output_result": f"ä¸“å®¶ '{expert_type}' æœªæ‰¾åˆ°",
            "status": "failed",
            "error": f"Expert '{expert_type}' not found in database",
            "started_at": datetime.now().isoformat(),
            "completed_at": datetime.now().isoformat()
        }
    
    started_at = datetime.now()

    # âœ… å‘é€ task.started äº‹ä»¶ï¼ˆä¸“å®¶å¼€å§‹æ‰§è¡Œï¼‰
    from utils.event_generator import event_task_started, sse_event_to_string
    task_id = current_task.get("id", str(current_index))
    started_event = event_task_started(
        task_id=task_id,
        expert_type=expert_type,
        description=description
    )
    # å°† started äº‹ä»¶æ”¾å…¥ state çš„ event_queueï¼Œè®© dispatcher æˆ–å…¶ä»–èŠ‚ç‚¹å¤„ç†
    initial_event_queue = state.get("event_queue", [])
    initial_event_queue.append({"type": "sse", "event": sse_event_to_string(started_event)})
    print(f"[GenericWorker] å·²ç”Ÿæˆ task.started äº‹ä»¶: {expert_type}")

    try:
        # è·å–ä¸“å®¶é…ç½®å‚æ•°
        system_prompt = expert_config["system_prompt"]
        expert_name = expert_config.get("name", expert_type)
        
        # åº”ç”¨æ¨¡å‹å…œåº•æœºåˆ¶
        configured_model = expert_config.get("model")
        effective_model = get_effective_model(configured_model)
        
        # è·å–æ¨¡å‹é…ç½®ä»¥ç¡®å®šå®é™…çš„ API æ¨¡å‹åç§°å’Œæ¸©åº¦
        model_config = get_model_config(effective_model)
        if model_config:
            actual_model = model_config.get("model", effective_model)
            temperature = model_config.get("temperature", expert_config.get("temperature", 0.7))
        else:
            actual_model = effective_model
            temperature = expert_config.get("temperature", 0.7)
        
        print(f"[GenericWorker] Running '{expert_type}' ({expert_name}) with model={actual_model}, temp={temperature}")
        
        # å¦‚æœæ²¡æœ‰æä¾› LLM å®ä¾‹ï¼Œæ ¹æ®é…ç½®åˆ›å»º
        if llm is None:
            # æ ¹æ®æ¨¡å‹é…ç½®è·å– provider
            if model_config:
                provider = model_config.get("provider")
                llm = get_expert_llm(provider=provider, model=actual_model, temperature=temperature)
            else:
                llm = get_expert_llm(model=actual_model, temperature=temperature)
        
        # ç»‘å®šæ¨¡å‹å’Œæ¸©åº¦å‚æ•°
        llm_with_config = llm.bind(
            model=actual_model,
            temperature=temperature
        )
        
        # ä½¿ç”¨ RunnableConfig æ·»åŠ æ ‡ç­¾ï¼Œä¾¿äºæµå¼è¾“å‡ºè¿‡æ»¤
        response = await llm_with_config.ainvoke(
            [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"ä»»åŠ¡æè¿°: {description}\n\nè¾“å…¥å‚æ•°:\n{_format_input_data(input_data)}")
            ],
            config=RunnableConfig(
                tags=["expert", expert_type, "generic_worker"],
                metadata={"node_type": "expert", "expert_type": expert_type}
            )
        )
        
        completed_at = datetime.now()
        duration_ms = int((completed_at - started_at).total_seconds() * 1000)
        
        print(f"[GenericWorker] '{expert_type}' completed (è€—æ—¶: {duration_ms/1000:.2f}s)")

        # æ£€æµ‹ artifact ç±»å‹
        artifact_type = _detect_artifact_type(response.content, expert_type)

        # âœ… v3.2 ä¿®å¤ï¼šå¢åŠ  current_task_index ä»¥æ”¯æŒå¾ªç¯
        # Generic Worker æ‰§è¡Œå®Œä»»åŠ¡åï¼Œéœ€è¦é€’å¢ index æ‰èƒ½æ‰§è¡Œä¸‹ä¸€ä¸ªä»»åŠ¡
        next_index = current_index + 1

        # âœ… æ›´æ–°ä»»åŠ¡åˆ—è¡¨ä¸­çš„ä»»åŠ¡çŠ¶æ€
        task_list[current_index]["output_result"] = {"content": response.content}
        task_list[current_index]["status"] = "completed"
        task_list[current_index]["completed_at"] = completed_at.isoformat()

        # âœ… æ·»åŠ åˆ° expert_resultsï¼ˆç”¨äºåç»­ä»»åŠ¡ä¾èµ–å’Œæœ€ç»ˆèšåˆï¼‰
        expert_result = {
            "task_id": current_task.get("id", str(current_index)),
            "expert_type": expert_type,
            "description": description,
            "output": response.content,
            "status": "completed",
            "duration_ms": duration_ms
        }

        # è·å–ç°æœ‰çš„ expert_results å¹¶è¿½åŠ æ–°ç»“æœ
        expert_results = state.get("expert_results", [])
        expert_results = expert_results + [expert_result]

        # âœ… æ„å»º artifact å¯¹è±¡ï¼ˆç¬¦åˆ ArtifactCreate æ¨¡å‹ï¼‰
        artifact = {
            "type": artifact_type,
            "title": f"{expert_name}ç»“æœ",
            "content": response.content,
            "language": None,  # å¯é€‰å­—æ®µï¼ŒPydantic æ¨¡å‹éœ€è¦
            "sort_order": 0    # é»˜è®¤æ’åº
        }

        # âœ… å¼‚æ­¥ä¿å­˜ä¸“å®¶æ‰§è¡Œç»“æœåˆ°æ•°æ®åº“ï¼ˆP0 ä¼˜åŒ–ï¼šä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        # ğŸ”¥ ä¿®å¤ï¼šä¸ä¼ é€’ db_sessionï¼Œåœ¨ async_save_expert_result ä¸­åˆ›å»ºç‹¬ç«‹çš„ Session
        if task_id:
            try:
                from utils.async_task_queue import async_save_expert_result
                # ä½¿ç”¨åå°çº¿ç¨‹å¼‚æ­¥ä¿å­˜ï¼Œä¸é˜»å¡ LLM å“åº”è¿”å›
                asyncio.create_task(async_save_expert_result(
                    task_id=task_id,
                    expert_type=expert_type,
                    output_result=response.content,
                    artifact_data=artifact,
                    duration_ms=duration_ms
                ))
                print(f"[GenericWorker] âœ… ä¸“å®¶æ‰§è¡Œç»“æœå·²æäº¤å¼‚æ­¥ä¿å­˜: {expert_type}")
            except Exception as save_err:
                print(f"[GenericWorker] âš ï¸ å¼‚æ­¥ä¿å­˜æäº¤å¤±è´¥ï¼ˆä¸å½±å“æµç¨‹ï¼‰: {save_err}")
        else:
            print(f"[GenericWorker] âš ï¸ è·³è¿‡ä¿å­˜: task_id={task_id}")

        # âœ… ç”Ÿæˆäº‹ä»¶é˜Ÿåˆ—ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºä¸“å®¶å’Œ artifactï¼‰
        from utils.event_generator import (
            event_task_completed, event_artifact_generated, sse_event_to_string
        )
        from uuid import uuid4

        event_queue = []
        task_id = current_task.get("id", str(current_index))

        # 1. å‘é€ task.completed äº‹ä»¶ï¼ˆä¸“å®¶æ‰§è¡Œå®Œæˆï¼‰
        task_completed_event = event_task_completed(
            task_id=task_id,
            expert_type=expert_type,
            description=description,
            output=response.content[:500] + "..." if len(response.content) > 500 else response.content,
            duration_ms=duration_ms,
            artifact_count=1
        )
        event_queue.append({"type": "sse", "event": sse_event_to_string(task_completed_event)})
        print(f"[GenericWorker] å·²ç”Ÿæˆ task.completed äº‹ä»¶: {expert_type}")

        # 2. å‘é€ artifact.generated äº‹ä»¶ï¼ˆç”Ÿæˆäº§ç‰©ï¼‰
        artifact_event = event_artifact_generated(
            task_id=task_id,
            expert_type=expert_type,
            artifact_id=str(uuid4()),
            artifact_type=artifact_type,
            content=response.content,
            title=f"{expert_name}ç»“æœ"
        )
        event_queue.append({"type": "sse", "event": sse_event_to_string(artifact_event)})
        print(f"[GenericWorker] å·²ç”Ÿæˆ artifact.generated äº‹ä»¶: {artifact_type}")

        # âœ… åˆå¹¶ started äº‹ä»¶å’Œ completed äº‹ä»¶
        full_event_queue = initial_event_queue + event_queue

        return {
            "task_list": task_list,
            "expert_results": expert_results,
            "current_task_index": next_index,  # âœ… å¢åŠ  index
            "output_result": response.content,
            "status": "completed",
            "started_at": started_at.isoformat(),
            "completed_at": completed_at.isoformat(),
            "duration_ms": duration_ms,
            "artifact": artifact,
            "event_queue": full_event_queue,  # âœ… æ·»åŠ å®Œæ•´äº‹ä»¶é˜Ÿåˆ—ï¼ˆåŒ…å« started å’Œ completedï¼‰
            # âœ… æ·»åŠ  __expert_info ç”¨äº chat.py è¯†åˆ«å’Œæ”¶é›† artifacts
            "__expert_info": {
                "expert_type": expert_type,
                "expert_name": expert_name,
                "task_id": task_id,
                "status": "completed"
            }
        }
        
    except Exception as e:
        print(f"[GenericWorker] '{expert_type}' failed: {e}")

        # âœ… å¤±è´¥æ—¶ä¹Ÿè¦å¢åŠ  indexï¼Œå¦åˆ™ä¼šå¡æ­»å¾ªç¯
        next_index = current_index + 1

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        task_list[current_index]["status"] = "failed"

        # è·å–ç°æœ‰çš„ expert_results å¹¶æ·»åŠ å¤±è´¥è®°å½•
        expert_results = state.get("expert_results", [])
        task_id = current_task.get("id", str(current_index))
        expert_result = {
            "task_id": task_id,
            "expert_type": expert_type,
            "description": description,
            "output": f"ä¸“å®¶æ‰§è¡Œå¤±è´¥: {str(e)}",
            "status": "failed",
            "error": str(e),
            "duration_ms": 0
        }
        expert_results = expert_results + [expert_result]

        # âœ… ç”Ÿæˆ task.failed äº‹ä»¶
        from utils.event_generator import event_task_failed, sse_event_to_string

        event_queue = []
        failed_event = event_task_failed(
            task_id=task_id,
            expert_type=expert_type,
            description=description,
            error=str(e)
        )
        event_queue.append({"type": "sse", "event": sse_event_to_string(failed_event)})
        print(f"[GenericWorker] å·²ç”Ÿæˆ task.failed äº‹ä»¶: {expert_type}")

        # âœ… åˆå¹¶ started äº‹ä»¶å’Œ failed äº‹ä»¶
        full_event_queue = initial_event_queue + event_queue

        return {
            "task_list": task_list,
            "expert_results": expert_results,
            "current_task_index": next_index,  # âœ… å³ä½¿å¤±è´¥ä¹Ÿå¢åŠ  index
            "output_result": f"ä¸“å®¶æ‰§è¡Œå¤±è´¥: {str(e)}",
            "status": "failed",
            "error": str(e),
            "started_at": started_at.isoformat(),
            "completed_at": datetime.now().isoformat(),
            "event_queue": full_event_queue,  # âœ… æ·»åŠ å®Œæ•´äº‹ä»¶é˜Ÿåˆ—ï¼ˆåŒ…å« started å’Œ failedï¼‰
            # âœ… æ·»åŠ  __expert_info ç”¨äºæ ‡è¯†å¤±è´¥çš„ä¸“å®¶
            "__expert_info": {
                "expert_type": expert_type,
                "expert_name": expert_config.get("name", expert_type) if expert_config else expert_type,
                "task_id": task_id,
                "status": "failed",
                "error": str(e)
            }
        }


def _format_input_data(data: Dict) -> str:
    """æ ¼å¼åŒ–è¾“å…¥æ•°æ®ä¸ºæ–‡æœ¬"""
    if not data:
        return "ï¼ˆæ— é¢å¤–å‚æ•°ï¼‰"
    
    lines = []
    for key, value in data.items():
        if isinstance(value, (list, dict)):
            lines.append(f"- {key}: {value}")
        else:
            lines.append(f"- {key}: {value}")
    
    return "\n".join(lines)


def _detect_artifact_type(content: str, expert_key: str) -> str:
    """
    æ£€æµ‹ artifact ç±»å‹
    
    ç®€åŒ–ç‰ˆï¼Œé»˜è®¤è¿”å› "text"ï¼Œä½†ä¼šå°è¯•æ£€æµ‹ HTML å’Œ Markdown å†…å®¹ã€‚
    """
    content_lower = content.lower().strip()
    
    # 1. HTML æ£€æµ‹
    if (content_lower.startswith("<!doctype html") or
        content_lower.startswith("<html") or
        ("<html" in content_lower and "</html>" in content_lower)):
        return "html"
    
    # æ£€æµ‹ HTML ä»£ç å—
    html_code_block = re.search(r'```html\n([\s\S]*?)```', content, re.IGNORECASE)
    if html_code_block:
        return "html"
    
    # 2. Markdown æ£€æµ‹
    has_markdown = any(marker in content for marker in ['# ', '## ', '### ', '> ', '- ', '* '])
    has_code_block = '```' in content
    
    if has_markdown or has_code_block:
        return "markdown"
    
    # 3. é»˜è®¤è¿”å› text
    return "text"
