"""
XPouch AI æ™ºèƒ½è·¯ç”±å·¥ä½œæµ (v2.7 æ¶æ„)
é›†æˆæ„å›¾è¯†åˆ« (Router) -> ä»»åŠ¡è§„åˆ’ (Planner) -> ä¸“å®¶æ‰§è¡Œ (Experts)
"""
from typing import TypedDict, Annotated, List, Dict, Any, Literal
from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import os
from dotenv import load_dotenv
import pathlib
from pydantic import BaseModel, Field
from uuid import uuid4
from datetime import datetime

# å¯¼å…¥æ•°æ®æ¨¡å‹
import sys
sys.path.append(str(pathlib.Path(__file__).parent.parent))
from models import ExpertType, TaskStatus, SubTask
from config import init_langchain_tracing, get_langsmith_config
from utils.json_parser import parse_llm_json
from utils.exceptions import AppError
# å°†åŸæœ‰çš„ COMMANDER_SYSTEM_PROMPT ä½œä¸ºè§„åˆ’å™¨ (Planner) çš„æç¤ºè¯
from constants import COMMANDER_SYSTEM_PROMPT as PLANNER_SYSTEM_PROMPT 
from agents.dynamic_experts import DYNAMIC_EXPERT_FUNCTIONS, initialize_expert_cache
from agents.expert_loader import get_expert_config_cached

# ============================================================================
# 0. è®¾ç½®ä¸é…ç½®
# ============================================================================
env_path = pathlib.Path(__file__).parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
base_url = os.getenv("OPENAI_BASE_URL") or os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
model_name = os.getenv("MODEL_NAME", "deepseek-chat")

# LangSmith é“¾è·¯è¿½è¸ª
langsmith_config = get_langsmith_config()
if langsmith_config["enabled"]:
    init_langchain_tracing(langsmith_config)

# åˆå§‹åŒ– LLM
# å»ºè®®ï¼šå¦‚æœå¯èƒ½ï¼ŒRouter å¯ä»¥ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆå¦‚ gpt-4o-miniï¼‰ï¼Œè¿™é‡Œæš‚æ—¶å¤ç”¨ä¸»é…ç½®
llm = ChatOpenAI(
    model=model_name,
    temperature=0.3, # Router éœ€è¦æ›´ç¡®å®šçš„è¾“å‡ºï¼Œç¨å¾®é™ä½æ¸©åº¦
    api_key=api_key,
    base_url=base_url,
    streaming=True
)

# ============================================================================
# 1. ç»“æ„å®šä¹‰ä¸æç¤ºè¯ (æ–°çš„ Router é€»è¾‘)
# ============================================================================

ROUTER_SYSTEM_PROMPT = """
ä½ æ˜¯ XPouch AI çš„ä¸­å¤®è·¯ç”±æŒ‡æŒ¥å®˜ï¼ˆRouterï¼‰ã€‚ä½ çš„å”¯ä¸€èŒè´£æ˜¯åˆ†æç”¨æˆ·çš„æ„å›¾å¹¶è¿›è¡Œåˆ†ç±»ã€‚

ã€åˆ†ç±»è§„åˆ™ - é‡è¦ã€‘

1. **ç®€å•/ç›´æ¥å›å¤ (Simple / Direct Reply)** - ä»…é™ä»¥ä¸‹æƒ…å†µï¼š
   - é—®å€™è¯­ï¼ˆ"ä½ å¥½", "Hi", "åœ¨å—", "æ—©ä¸Šå¥½"ï¼‰
   - æå…¶åŸºç¡€çš„å¸¸è¯†é—®é¢˜ï¼ˆ"æ³•å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ", "1+1ç­‰äºå‡ "ï¼‰
   - ç®€å•çš„ç¡®è®¤ï¼ˆ"å¥½çš„", "æ˜ç™½", "è°¢è°¢", "ok"ï¼‰
   - é—²èŠï¼ˆ"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·", "è®²ä¸ªç¬‘è¯"ï¼‰
   -> åŠ¨ä½œï¼šä½ è‡ªå·±ç›´æ¥ç”Ÿæˆå›å¤å†…å®¹ã€‚

2. **å¤æ‚/æ™ºèƒ½ä½“ä»»åŠ¡ (Complex / Agent Task)** - ä»¥ä¸‹æƒ…å†µ**å¿…é¡»**é€‰æ‹© complexï¼š
   - **ç¼–å†™ä»£ç ã€è°ƒè¯• Bugã€ä»£ç å®¡æŸ¥ã€ä»£ç è§£é‡Š**ï¼ˆä»»ä½•ä¸ä»£ç ç›¸å…³çš„ï¼‰
   - **ç½‘ç»œæœç´¢ã€ä¿¡æ¯æ£€ç´¢ã€æ·±åº¦ç ”ç©¶ã€æ•°æ®åˆ†æ**
   - **ç”Ÿæˆæ–‡ä»¶ã€æ–‡æ¡£ã€è¡¨æ ¼ã€æŠ¥å‘Šã€PPT å†…å®¹**
   - **å¤šæ­¥éª¤ä»»åŠ¡ã€éœ€è¦åˆ†è§£çš„é—®é¢˜**
   - **æ¶‰åŠå¤šä¸ªé¢†åŸŸçš„å¤æ‚é—®é¢˜**
   - **ä»»ä½•éœ€è¦è°ƒç”¨å·¥å…·ã€æœç´¢ç½‘é¡µã€æˆ–ä¸“ä¸šä¸“å®¶å¤„ç†çš„è¯·æ±‚**
   - **ç”¨æˆ·æ˜ç¡®è¦æ±‚"æœç´¢"ã€"æŸ¥è¯¢"ã€"åˆ†æ"ã€"æ¯”è¾ƒ"ã€"æ€»ç»“"ç­‰**

ã€åˆ¤æ–­åŸåˆ™ã€‘
- **å®å¯ complexï¼Œä¸è¦ simple** - å¦‚æœä¸ç¡®å®šï¼Œé€‰æ‹© complexï¼Œè®© Planner æ¥å¤„ç†
- **ä»£ç ç›¸å…³ä»»åŠ¡ä¸€å¾‹ complex** - å³ä½¿æ˜¯"Hello World"ä¹Ÿèµ° complex æ¨¡å¼
- **éœ€è¦å®æ—¶ä¿¡æ¯çš„ä»»åŠ¡ä¸€å¾‹ complex** - å¦‚ä»·æ ¼ã€å¤©æ°”ã€æ–°é—»ç­‰

ã€è¾“å‡ºæ ¼å¼ã€‘
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š
{format_instructions}

ã€ç¤ºä¾‹ã€‘
ç”¨æˆ·ï¼š"ä½ å¥½" -> simple
ç”¨æˆ·ï¼š"å¸®æˆ‘å†™ä¸ª Python çˆ¬è™«" -> complex
ç”¨æˆ·ï¼š"è§£é‡Šè¿™æ®µä»£ç " -> complex  
ç”¨æˆ·ï¼š"æœç´¢æœ€æ–°çš„ AI æ–°é—»" -> complex
ç”¨æˆ·ï¼š"å¸®æˆ‘è§„åˆ’ä¸€ä¸ªé¡¹ç›®" -> complex
ç”¨æˆ·ï¼š"å·´é»å¤©æ°”æ€ä¹ˆæ ·" -> complex (éœ€è¦å®æ—¶ä¿¡æ¯)
"""

class RoutingDecision(BaseModel):
    """è·¯ç”±å™¨çš„å†³ç­–è¾“å‡ºç»“æ„"""
    intent: Literal["simple", "complex"] = Field(
        ..., 
        description="ç”¨æˆ·æ„å›¾ï¼š'simple' è¡¨ç¤ºç®€å•é—²èŠï¼Œ'complex' è¡¨ç¤ºéœ€è¦ä¸“å®¶å¤„ç†çš„ä»»åŠ¡ã€‚"
    )
    direct_response: str = Field(
        default="", 
        description="å¦‚æœ intent æ˜¯ 'simple'ï¼Œè¯·åœ¨æ­¤å¤„å¡«å†™ç›´æ¥å›å¤çš„å†…å®¹ã€‚å¦‚æœæ˜¯ 'complex'ï¼Œå¿…é¡»ç•™ç©ºã€‚"
    )
    thought: str = Field(description="ç®€çŸ­çš„æ€è€ƒè¿‡ç¨‹ï¼Œè§£é‡Šä¸ºä»€ä¹ˆåšå‡ºè¿™ä¸ªåˆ†ç±»ã€‚")

# --- ä¿ç•™åŸæœ‰çš„è§„åˆ’å™¨ç»“æ„ (åŸ CommanderOutput) ---

class SubTaskOutput(BaseModel):
    """å•ä¸ªå­ä»»åŠ¡ç»“æ„ (Planner ä½¿ç”¨)"""
    expert_type: ExpertType = Field(description="æ‰§è¡Œæ­¤ä»»åŠ¡çš„ä¸“å®¶ç±»å‹")
    description: str = Field(description="ä»»åŠ¡æè¿°")
    input_data: Dict[str, Any] = Field(default={}, description="è¾“å…¥å‚æ•°")
    priority: int = Field(default=0, description="ä¼˜å…ˆçº§ (0=æœ€é«˜)")

class PlannerOutput(BaseModel):
    """è§„åˆ’å™¨è¾“å‡º - å­ä»»åŠ¡åˆ—è¡¨ (åŸ CommanderOutput)"""
    tasks: List[SubTaskOutput] = Field(description="å­ä»»åŠ¡åˆ—è¡¨")
    strategy: str = Field(description="æ‰§è¡Œç­–ç•¥æ¦‚è¿°")
    estimated_steps: int = Field(description="é¢„è®¡æ­¥éª¤æ•°")

# ============================================================================
# 2. çŠ¶æ€å®šä¹‰
# ============================================================================

class AgentState(TypedDict):
    """è¶…æ™ºèƒ½ä½“çš„å…¨å±€çŠ¶æ€"""
    messages: Annotated[List[BaseMessage], add_messages]
    task_list: List[Dict[str, Any]]
    current_task_index: int
    strategy: str
    expert_results: List[Dict[str, Any]]
    final_response: str
    # æ–°å¢ï¼šè®°å½•è·¯ç”±å†³ç­–ä¿¡æ¯
    router_decision: str 

# ============================================================================
# 3. èŠ‚ç‚¹å®ç°
# ============================================================================

# --- æ–°å¢ï¼šRouter èŠ‚ç‚¹ (å‰å°æ¥å¾…) ---
async def router_node(state: AgentState) -> Dict[str, Any]:
    """
    [å®ˆé—¨äºº] å¯¹æ„å›¾è¿›è¡Œåˆ†ç±»ï¼šSimple vs Complex
    """
    messages = state["messages"]
    last_message = messages[-1].content if messages else ""
    
    # 0. æ£€æŸ¥"ç›´æ¥ä¸“å®¶æ¨¡å¼" (Direct Mode)
    # å¦‚æœçŠ¶æ€ä¸­å·²ç»é¢„ç½®äº† task_listï¼Œè¯´æ˜æ˜¯ç³»ç»Ÿæ¢å¤æˆ– API æŒ‡å®šä»»åŠ¡ï¼Œç›´æ¥è·³è¿‡æ„å›¾æ£€æŸ¥
    if state.get("task_list") and len(state.get("task_list", [])) > 0:
        print(f"[ROUTER] æ£€æµ‹åˆ°ç°æœ‰ä»»åŠ¡åˆ—è¡¨ï¼Œè·³è¿‡æ„å›¾æ£€æŸ¥ -> Complex")
        return {"router_decision": "complex"}

    print(f"[ROUTER] åˆ†æç”¨æˆ·è¾“å…¥: '{last_message[:100]}...' " if len(str(last_message)) > 100 else f"[ROUTER] åˆ†æç”¨æˆ·è¾“å…¥: '{last_message}'")

    # 1. è°ƒç”¨ LLM è¿›è¡Œåˆ†ç±»
    # ä½¿ç”¨é€šç”¨çš„ PydanticOutputParserï¼ˆå…¼å®¹ DeepSeek/OpenAIï¼‰
    from langchain_core.output_parsers import PydanticOutputParser

    parser = PydanticOutputParser(pydantic_object=RoutingDecision)

    # æ„å»º promptï¼ˆåŒ…å«æ ¼å¼åŒ–æŒ‡ä»¤ï¼‰
    prompt = ROUTER_SYSTEM_PROMPT.format(format_instructions=parser.get_format_instructions())

    try:
        # è°ƒç”¨ LLM
        response = await llm.ainvoke([
            SystemMessage(content=prompt),
            *messages
        ])
        print(f"[ROUTER] LLM åŸå§‹å“åº”: {response.content[:200]}..." if len(response.content) > 200 else f"[ROUTER] LLM åŸå§‹å“åº”: {response.content}")
        # è§£æè¾“å‡º
        decision = parser.parse(response.content)
    except Exception as e:
        print(f"[ROUTER] è§£æé”™è¯¯ï¼Œå›é€€åˆ° Complex æ¨¡å¼: {e}")
        print(f"[ROUTER] é”™è¯¯è¯¦æƒ…: {str(e)}")
        # å®‰å…¨å›é€€ï¼šå¦‚æœæœ‰é—®é¢˜ï¼Œé»˜è®¤å½“ä½œå¤æ‚ä»»åŠ¡å¤„ç†
        decision = RoutingDecision(intent="complex", thought="Fallback due to parse error", direct_response="")

    print(f"[ROUTER] å†³ç­–: {decision.intent.upper()} | æ€è€ƒ: {decision.thought}")

    if decision.intent == "simple":
        # ç®€å•æ¨¡å¼ï¼šç›´æ¥ç”Ÿæˆå›å¤å¹¶å†™å…¥ messages å’Œ final_response
        # å‰ç«¯æ”¶åˆ°è¿™ä¸ªæ¶ˆæ¯åï¼Œä¼šä½œä¸ºæ™®é€šå¯¹è¯æ˜¾ç¤ºï¼Œä¸ä¼šè§¦å‘å¤æ‚ UI
        return {
            "router_decision": "simple",
            "messages": [AIMessage(content=decision.direct_response)],
            "final_response": decision.direct_response
        }
    else:
        # å¤æ‚æ¨¡å¼ï¼šé€ä¼ ç»™ Planner
        return {
            "router_decision": "complex"
        }

# --- ä¿®æ”¹ï¼šPlanner èŠ‚ç‚¹ (åŸ Commander) ---
async def planner_node(state: AgentState) -> Dict[str, Any]:
    """
    [æ¶æ„å¸ˆ] å°†å¤æ‚æŸ¥è¯¢æ‹†è§£ä¸ºå­ä»»åŠ¡ã€‚
    ä»…å½“ Router å†³å®š intent="complex" æ—¶è§¦å‘ã€‚
    """
    messages = state["messages"]
    last_message = messages[-1]
    user_query = last_message.content if isinstance(last_message, HumanMessage) else str(last_message.content)
    
    # åŠ è½½é…ç½® (æ•°æ®åº“æˆ–å›é€€)
    # æ³¨æ„ï¼šä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬ä»ç„¶è¯»å– key="commander" çš„é…ç½®
    commander_config = get_expert_config_cached("commander") 
    
    if not commander_config:
        system_prompt = PLANNER_SYSTEM_PROMPT
        model = model_name  # ğŸ‘ˆ ä½¿ç”¨ä¸ Router ç›¸åŒçš„æ¨¡å‹ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        temperature = 0.5
        print(f"[PLANNER] ä½¿ç”¨é»˜è®¤å›é€€é…ç½®: model={model}")
    else:
        system_prompt = commander_config["system_prompt"]
        model = commander_config["model"]
        temperature = commander_config["temperature"]
        print(f"[PLANNER] åŠ è½½æ•°æ®åº“é…ç½®: model={model}")
    
    # æ‰§è¡Œ LLM è¿›è¡Œè§„åˆ’
    try:
        llm_with_config = llm.bind(model=model, temperature=temperature)
        
        response = await llm_with_config.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"ç”¨æˆ·æŸ¥è¯¢: {user_query}\n\nè¯·å°†æ­¤æŸ¥è¯¢æ‹†è§£ä¸ºå­ä»»åŠ¡åˆ—è¡¨ã€‚")
        ])

        # è§£æ JSON
        planner_response = parse_llm_json(
            response.content,
            PlannerOutput, # ä½¿ç”¨æ–°çš„ Pydantic æ¨¡å‹å
            strict=False,
            clean_markdown=True
        )

        # è½¬æ¢ä¸ºå†…éƒ¨å­—å…¸æ ¼å¼
        task_list = [
            {
                "id": str(uuid4()),
                "expert_type": task.expert_type,
                "description": task.description,
                "input_data": task.input_data,
                "priority": task.priority,
                "status": "pending",
                "output_result": None,
                "started_at": None,
                "completed_at": None,
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }
            for task in planner_response.tasks
        ]

        print(f"[PLANNER] ç”Ÿæˆäº† {len(task_list)} ä¸ªä»»åŠ¡ã€‚ç­–ç•¥: {planner_response.strategy}")

        return {
            "task_list": task_list,
            "strategy": planner_response.strategy,
            "current_task_index": 0,
            "expert_results": [],
            # å‰ç«¯ç”¨äº UI æ¸²æŸ“çš„å…ƒæ•°æ®
            "__task_plan": {
                "task_count": len(task_list),
                "strategy": planner_response.strategy,
                "estimated_steps": planner_response.estimated_steps,
                "tasks": task_list
            }
        }

    except Exception as e:
        print(f"[ERROR] Planner è§„åˆ’å¤±è´¥: {e}")
        return {
            "task_list": [],
            "strategy": f"Error: {str(e)}",
            "current_task_index": 0
        }

# --- åŸæœ‰ï¼šExpert Dispatcher èŠ‚ç‚¹ (é€»è¾‘ä¸å˜) ---
async def expert_dispatcher_node(state: AgentState) -> Dict[str, Any]:
    task_list = state["task_list"]
    current_index = state["current_task_index"]

    if current_index >= len(task_list):
        return {"expert_results": state["expert_results"]}

    current_task = task_list[current_index]
    expert_type = current_task["expert_type"]
    description = current_task["description"]

    print(f"[EXEC] æ‰§è¡Œä»»åŠ¡ [{current_index + 1}/{len(task_list)}] - {expert_type}: {description}")

    try:
        expert_func = DYNAMIC_EXPERT_FUNCTIONS.get(expert_type)
        if not expert_func:
            raise ValueError(f"æœªçŸ¥çš„ä¸“å®¶ç±»å‹: {expert_type}")

        result = await expert_func(state, llm)

        if "error" in result:
             raise AppError(message=result["error"], code="EXPERT_EXECUTION_ERROR")

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        current_task["output_result"] = {"content": result.get("output_result", "")}
        current_task["status"] = result.get("status", "completed")
        current_task["completed_at"] = result.get("completed_at")
        
        # æ·»åŠ åˆ°ç»“æœé›†
        updated_results = state["expert_results"] + [{
            "task_id": current_task["id"],
            "expert_type": expert_type,
            "description": description,
            "output": result.get("output_result", ""),
            "status": result.get("status", "unknown"),
            "duration_ms": result.get("duration_ms", 0)
        }]

        duration = result.get('duration_ms', 0) / 1000
        print(f"   [OK] è€—æ—¶ {duration:.2f}s")

        return_dict = {
            "task_list": task_list,
            "expert_results": updated_results,
            "current_task_index": current_index + 1,
            "__expert_info": { # ç”¨äºå‰ç«¯ SSE äº‹ä»¶
                "expert_type": expert_type,
                "description": description,
                "status": "completed",
                "output": result.get("output_result", ""),
            }
        }
        if "artifact" in result:
            return_dict["artifact"] = result["artifact"]

        return return_dict

    except Exception as e:
        print(f"   [ERROR] ä¸“å®¶æ‰§è¡Œå¤±è´¥: {e}")
        current_task["status"] = "failed"
        return {
            "task_list": task_list,
            "current_task_index": current_index + 1,
            "__expert_info": {
                "expert_type": expert_type,
                "description": description,
                "status": "failed",
                "error": str(e)
            }
        }

# --- åŸæœ‰ï¼šAggregator èŠ‚ç‚¹ (é€»è¾‘ä¸å˜) ---
async def aggregator_node(state: AgentState) -> Dict[str, Any]:
    expert_results = state["expert_results"]
    strategy = state["strategy"]

    if not expert_results:
        return {"final_response": "æœªç”Ÿæˆä»»ä½•æ‰§è¡Œç»“æœã€‚"}

    print(f"[AGG] æ­£åœ¨èšåˆ {len(expert_results)} ä¸ªç»“æœ...")
    final_response = _build_markdown_response(expert_results, strategy)
    return {"final_response": final_response}

def _build_markdown_response(expert_results: List[Dict[str, Any]], strategy: str) -> str:
    # ç®€å•çš„ Markdown æ„å»ºé€»è¾‘
    lines = [f"# æ‰§è¡ŒæŠ¥å‘Š\n**ç­–ç•¥**: {strategy}\n---"]
    for i, res in enumerate(expert_results, 1):
        lines.append(f"## {i}. {res['expert_type'].upper()}: {res['description']}")
        lines.append(f"{res['output']}\n")
    return "\n".join(lines)

# ============================================================================
# 4. æ¡ä»¶è·¯ç”±é€»è¾‘ (Edges)
# ============================================================================

def route_router(state: AgentState) -> str:
    """å†³å®š Router ä¹‹åçš„å»å‘"""
    decision = state.get("router_decision", "complex")
    
    if decision == "simple":
        print("[PATH] ç®€å•æ„å›¾ -> END (ç›´æ¥ç»“æŸ)")
        return END
    else:
        print("[PATH] å¤æ‚æ„å›¾ -> Planner (è¿›å…¥è§„åˆ’)")
        # å†æ¬¡æ£€æŸ¥ï¼šå¦‚æœæ˜¯ç›´æ¥æ¨¡å¼ï¼ˆå·²æœ‰ä»»åŠ¡ï¼‰ï¼Œç›´æ¥å»æ‰§è¡Œï¼Œä¸ç”¨è§„åˆ’
        if state.get("task_list") and len(state.get("task_list", [])) > 0:
             return "expert_dispatcher"
        return "planner"

def route_dispatcher(state: AgentState) -> str:
    """å†³å®š åˆ†å‘å™¨ ä¹‹åçš„å»å‘ï¼ˆå¾ªç¯æˆ–èšåˆï¼‰"""
    if state["current_task_index"] >= len(state["task_list"]):
        return "aggregator"
    return "expert_dispatcher"

# ============================================================================
# 5. æ„å»ºå·¥ä½œæµå›¾
# ============================================================================

def create_smart_router_workflow() -> StateGraph:
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("router", router_node)
    workflow.add_node("planner", planner_node)
    workflow.add_node("expert_dispatcher", expert_dispatcher_node)
    workflow.add_node("aggregator", aggregator_node)

    # è®¾ç½®å…¥å£ï¼šç°åœ¨å…¥å£æ˜¯ Routerï¼
    workflow.set_entry_point("router")

    # æ·»åŠ è¿çº¿
    
    # 1. Router -> (END | Planner | Dispatcher)
    workflow.add_conditional_edges(
        "router",
        route_router,
        {
            END: END,
            "planner": "planner",
            "expert_dispatcher": "expert_dispatcher"
        }
    )

    # 2. Planner -> Dispatcher (è§„åˆ’å®Œå¿…ç„¶æ‰§è¡Œ)
    workflow.add_edge("planner", "expert_dispatcher")

    # 3. Dispatcher -> (Loop | Aggregator)
    workflow.add_conditional_edges(
        "expert_dispatcher",
        route_dispatcher,
        {
            "expert_dispatcher": "expert_dispatcher",
            "aggregator": "aggregator"
        }
    )

    # 4. Aggregator -> END
    workflow.add_edge("aggregator", END)

    return workflow.compile()

# å¯¼å‡ºç¼–è¯‘åçš„å›¾
commander_graph = create_smart_router_workflow()

# ============================================================================
# æµ‹è¯•å°è£…å‡½æ•°
# ============================================================================

async def execute_commander_workflow(user_query: str) -> Dict[str, Any]:
    print(f"--- [START] æŸ¥è¯¢: {user_query} ---")
    initial_state: AgentState = {
        "messages": [HumanMessage(content=user_query)],
        "task_list": [],
        "current_task_index": 0,
        "strategy": "",
        "expert_results": [],
        "final_response": ""
    }
    final_state = await commander_graph.ainvoke(initial_state)
    print("--- [DONE] ---")
    return final_state

if __name__ == "__main__":
    import asyncio
    async def test():
        # æµ‹è¯• 1: ç®€å•é—²èŠ
        print("\n=== æµ‹è¯• 1: ç®€å•æ¨¡å¼ ===")
        await execute_commander_workflow("ä½ å¥½ï¼Œåœ¨å—ï¼Ÿ")
        
        # æµ‹è¯• 2: å¤æ‚ä»»åŠ¡
        print("\n=== æµ‹è¯• 2: å¤æ‚æ¨¡å¼ ===")
        await execute_commander_workflow("å¸®æˆ‘å†™ä¸€ä¸ª Python è„šæœ¬æ¥æŠ“å–è‚¡ç¥¨ä»·æ ¼ã€‚")
    
    asyncio.run(test())