"""
èŠå¤©è·¯ç”±æ¨¡å— - åŒ…å«ä¸»è¦èŠå¤©ç«¯ç‚¹å’Œçº¿ç¨‹ç®¡ç†
v3.0: å¤æ‚æ¨¡å¼ä½¿ç”¨æ–°çš„äº‹ä»¶åè®®ï¼ˆplan.created, task.started, task.completed, artifact.generated, message.deltaï¼‰
"""
import os
import json
import re
from datetime import datetime
from typing import List, Optional, AsyncGenerator
from uuid import uuid4

from fastapi import APIRouter, Depends, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from sqlmodel import Session, select
from sqlalchemy.orm import selectinload
from langchain_core.messages import HumanMessage, AIMessage

from database import get_session, engine
from dependencies import get_current_user, get_current_user_with_auth
from utils.thinking_parser import parse_thinking
from models import (
    User, Thread, Message, CustomAgent, TaskSession, SubTask
)
from crud.task_session import (
    create_task_session,
    get_task_session_by_thread,
    update_task_session_status,
    create_subtask,
    get_subtasks_by_session,
    update_subtask_status,
    create_artifacts_batch
)
from constants import (
    normalize_agent_id,
    SYSTEM_AGENT_ORCHESTRATOR,
    SYSTEM_AGENT_DEFAULT_CHAT
)
from utils.llm_factory import get_llm_instance
from agents.graph import commander_graph
from utils.exceptions import AppError, NotFoundError, AuthorizationError


router = APIRouter(prefix="/api", tags=["chat"])

DEBUG = os.getenv("DEBUG", "false").lower() == "true"


# ============================================================================
# è¯·æ±‚æ¨¡å‹
# ============================================================================

class ChatMessageDTO(BaseModel):
    role: str
    content: str
    id: Optional[str] = None
    timestamp: Optional[str] = None


class ChatRequest(BaseModel):
    message: str
    history: List[ChatMessageDTO]
    conversationId: Optional[str] = None
    agentId: Optional[str] = "assistant"
    stream: Optional[bool] = True
    message_id: Optional[str] = None  # v3.0: å‰ç«¯ä¼ é€’çš„åŠ©æ‰‹æ¶ˆæ¯ ID


# ============================================================================
# çº¿ç¨‹ç®¡ç† API
# ============================================================================

@router.get("/threads", response_model=List[dict])
async def get_threads(
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """è·å–å½“å‰ç”¨æˆ·çš„æ‰€æœ‰çº¿ç¨‹åˆ—è¡¨"""
    statement = (
        select(Thread)
        .where(Thread.user_id == current_user.id)
        .options(selectinload(Thread.messages))
        .order_by(Thread.updated_at.desc())
    )
    threads = session.exec(statement).all()
    
    result = []
    for thread in threads:
        result.append({
            "id": thread.id,
            "title": thread.title,
            "agent_id": thread.agent_id,
            "agent_type": thread.agent_type,
            "thread_mode": thread.thread_mode,
            "user_id": thread.user_id,
            "task_session_id": thread.task_session_id,
            "created_at": thread.created_at.isoformat() if thread.created_at else None,
            "updated_at": thread.updated_at.isoformat() if thread.updated_at else None,
            "messages": [
                {
                    "id": msg.id,
                    "role": msg.role,
                    "content": msg.content,
                    "timestamp": msg.timestamp.isoformat() if msg.timestamp else None
                }
                for msg in thread.messages
            ]
        })
    return result


@router.get("/threads/{thread_id}")
async def get_thread(
    thread_id: str,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """è·å–å•ä¸ªçº¿ç¨‹è¯¦æƒ…"""
    statement = (
        select(Thread)
        .where(Thread.id == thread_id)
        .options(selectinload(Thread.messages))
    )
    thread = session.exec(statement).first()

    if not thread or thread.user_id != current_user.id:
        raise NotFoundError(resource="ä¼šè¯")

    # å¦‚æœæ˜¯AIåŠ©æ‰‹çº¿ç¨‹ï¼ˆå¤æ‚æ¨¡å¼ï¼‰ï¼ŒåŠ è½½TaskSessionå’ŒSubTask
    if thread.agent_type == "ai" and thread.task_session_id:
        task_session = session.get(TaskSession, thread.task_session_id)
        if task_session:
            # v3.0: ä½¿ç”¨ selectinload é¢„åŠ è½½ artifacts å…³ç³»ï¼Œé¿å… N+1 æŸ¥è¯¢
            statement = (
                select(SubTask)
                .where(SubTask.task_session_id == task_session.session_id)
                .options(selectinload(SubTask.artifacts))
                .order_by(SubTask.sort_order)
            )
            sub_tasks = session.exec(statement).all()

            return {
                "id": thread.id,
                "title": thread.title,
                "agent_id": thread.agent_id,
                "agent_type": thread.agent_type,
                "user_id": thread.user_id,
                "task_session_id": thread.task_session_id,
                "created_at": thread.created_at.isoformat() if thread.created_at else None,
                "updated_at": thread.updated_at.isoformat() if thread.updated_at else None,
                "messages": [
                    {
                        "id": msg.id,
                        "role": msg.role,
                        "content": msg.content,
                        "timestamp": msg.timestamp.isoformat() if msg.timestamp else None,
                        "extra_data": msg.extra_data
                    }
                    for msg in thread.messages
                ],
                "task_session": {
                    "id": task_session.session_id,  # âœ… å‰ç«¯å…¼å®¹æ€§ï¼šåŒæ—¶æä¾› id å’Œ session_id
                    "session_id": task_session.session_id,
                    "user_query": task_session.user_query,
                    "final_response": task_session.final_response,
                    "status": task_session.status,
                    "sub_tasks": [
                        {
                            "id": st.id,
                            "task_session_id": st.task_session_id,
                            "expert_type": st.expert_type,
                            "task_description": st.task_description,
                            "status": st.status,
                            "output_result": st.output_result,
                            "error_message": st.error_message,
                            "artifacts": [
                                {
                                    "id": art.id,
                                    "type": art.type,
                                    "title": art.title,
                                    "content": art.content,
                                    "language": art.language,
                                    "sort_order": art.sort_order,
                                    "created_at": art.created_at.isoformat() if art.created_at else None
                                }
                                for art in (st.artifacts or [])
                            ],
                            "duration_ms": st.duration_ms,
                            "created_at": st.created_at.isoformat() if st.created_at else None
                        }
                        for st in sub_tasks
                    ]
                }
            }

    return {
        "id": thread.id,
        "title": thread.title,
        "agent_id": thread.agent_id,
        "agent_type": thread.agent_type,
        "user_id": thread.user_id,
        "task_session_id": thread.task_session_id,
        "created_at": thread.created_at.isoformat() if thread.created_at else None,
        "updated_at": thread.updated_at.isoformat() if thread.updated_at else None,
        "messages": [
            {
                "id": msg.id,
                "role": msg.role,
                "content": msg.content,
                "timestamp": msg.timestamp.isoformat() if msg.timestamp else None,
                "extra_data": msg.extra_data
            }
            for msg in thread.messages
        ]
    }


@router.delete("/threads/{thread_id}")
async def delete_thread(
    thread_id: str,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """åˆ é™¤çº¿ç¨‹"""
    thread = session.get(Thread, thread_id)
    if not thread or thread.user_id != current_user.id:
        raise NotFoundError(resource="ä¼šè¯")
    session.delete(thread)
    session.commit()
    return {"ok": True}


# ============================================================================
# ä¸»è¦èŠå¤©ç«¯ç‚¹
# ============================================================================

@router.post("/chat")
async def chat_endpoint(
    request: ChatRequest,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    ç»Ÿä¸€èŠå¤©ç«¯ç‚¹ï¼ˆç®€å•æ¨¡å¼ + å¤æ‚æ¨¡å¼ï¼‰
    v3.0: å¤æ‚æ¨¡å¼ä½¿ç”¨æ–°çš„äº‹ä»¶åè®®
    """
    # 1. ç¡®å®š Thread ID
    thread_id = request.conversationId
    thread = None

    if thread_id:
        thread = session.get(Thread, thread_id)
        if thread and thread.user_id != current_user.id:
            raise AuthorizationError("æ²¡æœ‰æƒé™è®¿é—®æ­¤ä¼šè¯")

    if not thread:
        if not thread_id:
            thread_id = str(uuid4())

        # å…œåº•é€»è¾‘ï¼šå¦‚æœ agentId ä¸º Noneã€null æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œå¼ºåˆ¶èµ‹å€¼ä¸ºç³»ç»Ÿé»˜è®¤åŠ©æ‰‹
        if not request.agentId or request.agentId.strip() == "":
            frontend_agent_id = SYSTEM_AGENT_DEFAULT_CHAT
        else:
            frontend_agent_id = normalize_agent_id(request.agentId)

        # sys-task-orchestrator æ˜¯å†…éƒ¨å®ç°ï¼Œä¸åº”åœ¨ URL ä¸­æš´éœ²
        if frontend_agent_id == SYSTEM_AGENT_ORCHESTRATOR:
            frontend_agent_id = SYSTEM_AGENT_DEFAULT_CHAT

        # æ ¹æ® agentId ç¡®å®š agent_type
        custom_agent_check = session.get(CustomAgent, frontend_agent_id)
        if custom_agent_check and custom_agent_check.user_id == current_user.id:
            agent_type = "custom"
            final_agent_id = frontend_agent_id
        else:
            agent_type = "default"
            final_agent_id = SYSTEM_AGENT_DEFAULT_CHAT

        # åˆå§‹ thread_mode ä¸º simpleï¼ŒRouter ä¼šåœ¨å¤„ç†æ—¶æ›´æ–°å®ƒ
        thread = Thread(
            id=thread_id,
            title=request.message[:30] + "..." if len(request.message) > 30 else request.message,
            agent_id=final_agent_id,
            agent_type=agent_type,
            thread_mode="simple",
            user_id=current_user.id,
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        session.add(thread)
        session.commit()
        session.refresh(thread)

    # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
    user_msg_db = Message(
        thread_id=thread_id,
        role="user",
        content=request.message,
        timestamp=datetime.now()
    )
    session.add(user_msg_db)
    session.commit()

    # 3. å‡†å¤‡ LangGraph ä¸Šä¸‹æ–‡
    statement = select(Message).where(Message.thread_id == thread_id).order_by(Message.timestamp)
    db_messages = session.exec(statement).all()

    langchain_messages = []
    for msg in db_messages:
        if msg.role == "user":
            langchain_messages.append(HumanMessage(content=msg.content))
        elif msg.role == "assistant":
            langchain_messages.append(AIMessage(content=msg.content))

    # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªå®šä¹‰æ™ºèƒ½ä½“
    custom_agent = None
    normalized_agent_id = normalize_agent_id(request.agentId)

    if normalized_agent_id == SYSTEM_AGENT_ORCHESTRATOR:
        normalized_agent_id = SYSTEM_AGENT_DEFAULT_CHAT

    is_system_default = False

    if normalized_agent_id == SYSTEM_AGENT_DEFAULT_CHAT:
        is_system_default = True
        custom_agent = None
        print(f"[CHAT] ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹æ¨¡å¼ - å°†ä½¿ç”¨ LangGraph Router å†³å®šæ‰§è¡Œè·¯å¾„")
    else:
        custom_agent = session.get(CustomAgent, normalized_agent_id)

        if custom_agent and custom_agent.user_id == current_user.id:
            custom_agent.conversation_count += 1
            session.add(custom_agent)
            session.commit()
            print(f"[CHAT] è‡ªå®šä¹‰æ™ºèƒ½ä½“æ¨¡å¼ - ç›´æ¥è°ƒç”¨ LLM: {custom_agent.name}")
        else:
            is_system_default = True
            custom_agent = None
            print(f"[CHAT] æœªæ‰¾åˆ°è‡ªå®šä¹‰æ™ºèƒ½ä½“ï¼Œå›é€€åˆ°ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹æ¨¡å¼")

    # å¦‚æœæ˜¯è‡ªå®šä¹‰æ™ºèƒ½ä½“ï¼Œä½¿ç”¨ç›´æ¥ LLM è°ƒç”¨æ¨¡å¼
    if custom_agent:
        if request.stream:
            return await _handle_custom_agent_stream(
                custom_agent, langchain_messages, thread_id, thread, request.message_id
            )
        else:
            return await _handle_custom_agent_sync(
                custom_agent, langchain_messages, thread_id, thread, session
            )

    # ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹æ¨¡å¼ï¼šé€šè¿‡ LangGraph å¤„ç†
    print(f"[CHAT] è¿›å…¥ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹æ¨¡å¼ï¼Œä½¿ç”¨ LangGraph å¤„ç†")

    initial_state = {
        "messages": langchain_messages,
        "current_agent": "router",
        "task_list": [],
        "current_task_index": 0,
        "strategy": "",
        "expert_results": [],
        "final_response": "",
        "context": {},
        "router_decision": ""
    }

    if request.stream:
        return await _handle_langgraph_stream(
            initial_state, thread_id, thread, request.message, session, request.message_id
        )
    else:
        return await _handle_langgraph_sync(
            initial_state, thread_id, thread, request.message, session
        )


# ============================================================================
# è‡ªå®šä¹‰æ™ºèƒ½ä½“å¤„ç†å‡½æ•°
# ============================================================================

async def _handle_custom_agent_stream(
    custom_agent: CustomAgent,
    langchain_messages: list,
    thread_id: str,
    thread: Thread,
    message_id: Optional[str] = None  # v3.0: å‰ç«¯ä¼ é€’çš„åŠ©æ‰‹æ¶ˆæ¯ ID
) -> StreamingResponse:
    """å¤„ç†è‡ªå®šä¹‰æ™ºèƒ½ä½“æµå¼å“åº” (v3.0 æ–°åè®®)"""
    async def event_generator():
        full_response = ""
        # v3.0: ç¡®ä¿ä½¿ç”¨ä¸€è‡´çš„ message_id
        actual_message_id = message_id or str(uuid4())
        try:
            # ä½¿ç”¨æ–°çš„é…ç½®ç³»ç»Ÿè·å–æ¨¡å‹
            from providers_config import get_model_config, get_provider_config, get_provider_api_key
            
            model_id = custom_agent.model_id or "deepseek-chat"
            model_config = get_model_config(model_id)
            
            if model_config:
                # ä»é…ç½®æ–‡ä»¶è·å–æä¾›å•†å’Œå®é™…æ¨¡å‹å
                provider = model_config.get('provider')
                actual_model = model_config.get('model', model_id)
                provider_config = get_provider_config(provider)
                
                if not provider_config:
                    raise ValueError(f"æä¾›å•† {provider} æœªé…ç½®")
                
                if not get_provider_api_key(provider):
                    raise ValueError(f"æä¾›å•† {provider} çš„ API Key æœªè®¾ç½®ï¼Œè¯·åœ¨ .env ä¸­é…ç½® {provider_config.get('env_key')}")

                # ä»æ¨¡å‹é…ç½®è¯»å– temperatureï¼ˆå…è®¸æ¨¡å‹çº§åˆ«è¦†ç›–ï¼‰
                model_config = get_model_config(model_id)
                temperature = model_config.get('temperature', 0.7) if model_config else 0.7

                print(f"[CUSTOM AGENT] ä½¿ç”¨æ¨¡å‹: {model_id} ({actual_model} via {provider}), temperature={temperature}ï¼Œæ¶ˆæ¯ID: {actual_message_id}")

                # ä½¿ç”¨æ–°çš„ llm_factoryï¼ˆä¼šè‡ªåŠ¨ä»é…ç½®æ–‡ä»¶è¯»å– base_urlï¼‰
                llm = get_llm_instance(
                    provider=provider,
                    model=actual_model,
                    streaming=True,
                    temperature=temperature
                )
            else:
                # Fallback: æ—§ç‰ˆå…¼å®¹ï¼ˆç›´æ¥ä¼ é€’æ¨¡å‹åï¼‰
                # å°è¯•ä»æ¨¡å‹é…ç½®è¯»å– temperature
                model_config = get_model_config(model_id)
                temperature = model_config.get('temperature', 0.7) if model_config else 0.7

                print(f"[CUSTOM AGENT] æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ï¼Œä½¿ç”¨ fallback: {model_id}, temperature={temperature}")
                llm = get_llm_instance(streaming=True, model=model_id, temperature=temperature)

            messages_with_system = [("system", custom_agent.system_prompt)]
            messages_with_system.extend(langchain_messages)

            async for chunk in llm.astream(messages_with_system):
                content = chunk.content
                if content:
                    full_response += content
                    # v3.0: ä½¿ç”¨ message.delta äº‹ä»¶ï¼ˆæ–°åè®®ï¼‰
                    from event_types.events import EventType, MessageDeltaData, build_sse_event
                    delta_event = build_sse_event(
                        EventType.MESSAGE_DELTA,
                        MessageDeltaData(
                            message_id=actual_message_id,
                            content=content
                        ),
                        str(uuid4())
                    )
                    from utils.event_generator import sse_event_to_string
                    yield sse_event_to_string(delta_event)

        except Exception as e:
            import traceback
            traceback.print_exc()
            # v3.0: å‘é€ error äº‹ä»¶
            from event_types.events import EventType, ErrorData, build_sse_event
            from utils.event_generator import sse_event_to_string
            error_event = build_sse_event(
                EventType.ERROR,
                ErrorData(code="STREAM_ERROR", message=str(e)),
                str(uuid4())
            )
            yield sse_event_to_string(error_event)

        # è§£æ thinking æ ‡ç­¾ï¼ˆç±»ä¼¼ DeepSeek Chat çš„æ€è€ƒè¿‡ç¨‹ï¼‰
        clean_content, thinking_data = parse_thinking(full_response)

        # v3.0: å‘é€ message.done äº‹ä»¶ï¼ˆæ–°åè®®ï¼‰
        # ä½¿ç”¨ä¸ delta äº‹ä»¶ç›¸åŒçš„ actual_message_id
        from event_types.events import EventType, MessageDoneData, build_sse_event
        done_event = build_sse_event(
            EventType.MESSAGE_DONE,
            MessageDoneData(
                message_id=actual_message_id,
                full_content=clean_content,  # ä½¿ç”¨æ¸…ç†åçš„å†…å®¹
                thinking=thinking_data  # åŒ…å« thinking æ•°æ®
            ),
            str(uuid4())
        )
        from utils.event_generator import sse_event_to_string
        yield sse_event_to_string(done_event)

        yield "data: [DONE]\n\n"
        print(f"[CUSTOM AGENT] æµå¼å“åº”å®Œæˆï¼Œæ¶ˆæ¯ID: {actual_message_id}")

        # ä¿å­˜ AI å›å¤åˆ°æ•°æ®åº“
        if full_response:
            ai_msg_db = Message(
                thread_id=thread_id,
                role="assistant",
                content=clean_content,  # ä¿å­˜æ¸…ç†åçš„å†…å®¹ï¼ˆç§»é™¤ thought æ ‡ç­¾ï¼‰
                extra_data={'thinking': thinking_data} if thinking_data else None,
                timestamp=datetime.now()
            )
            with Session(engine) as inner_session:
                inner_session.add(ai_msg_db)
                thread_obj = inner_session.get(Thread, thread_id)
                if thread_obj:
                    thread_obj.updated_at = datetime.now()
                    inner_session.add(thread_obj)
                inner_session.commit()
        
        yield "data: [DONE]\n\n"
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


async def _handle_custom_agent_sync(
    custom_agent: CustomAgent,
    langchain_messages: list,
    thread_id: str,
    thread: Thread,
    session: Session
) -> dict:
    """å¤„ç†è‡ªå®šä¹‰æ™ºèƒ½ä½“éæµå¼å“åº”"""
    # ä½¿ç”¨æ–°çš„é…ç½®ç³»ç»Ÿè·å–æ¨¡å‹
    from providers_config import get_model_config, get_provider_config, get_provider_api_key
    
    model_id = custom_agent.model_id or "deepseek-chat"
    model_config = get_model_config(model_id)
    
    if model_config:
        provider = model_config.get('provider')
        actual_model = model_config.get('model', model_id)
        provider_config = get_provider_config(provider)
        
        if not provider_config:
            raise ValueError(f"æä¾›å•† {provider} æœªé…ç½®")
        
        if not get_provider_api_key(provider):
            raise ValueError(f"æä¾›å•† {provider} çš„ API Key æœªè®¾ç½®")
        
        print(f"[CUSTOM AGENT] ä½¿ç”¨æ¨¡å‹: {model_id} ({actual_model} via {provider})")
        
        llm = get_llm_instance(
            provider=provider,
            model=actual_model,
            streaming=False,
            temperature=0.7
        )
    else:
        print(f"[CUSTOM AGENT] æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ï¼Œä½¿ç”¨ fallback: {model_id}")
        llm = get_llm_instance(streaming=False, model=model_id, temperature=0.7)
    
    messages_with_system = [("system", custom_agent.system_prompt)]
    messages_with_system.extend(langchain_messages)
    
    result = await llm.ainvoke(messages_with_system)
    full_response = result.content

    # ä¿å­˜ AI å›å¤
    # è§£æ thinking æ ‡ç­¾
    clean_content, thinking_data = parse_thinking(full_response)
    ai_msg_db = Message(
        thread_id=thread_id,
        role="assistant",
        content=clean_content,  # ä¿å­˜æ¸…ç†åçš„å†…å®¹
        extra_data={'thinking': thinking_data} if thinking_data else None,
        timestamp=datetime.now()
    )
    session.add(ai_msg_db)
    thread.updated_at = datetime.now()
    session.add(thread)
    session.commit()

    return {
        "role": "assistant",
        "content": full_response,
        "conversationId": thread_id
    }


# ============================================================================
# LangGraph å¤„ç†å‡½æ•° - v3.0 æ–°åè®®
# ============================================================================

async def _handle_langgraph_stream(
    initial_state: dict,
    thread_id: str,
    thread: Thread,
    user_message: str,
    session: Session,
    message_id: Optional[str] = None  # v3.0: å‰ç«¯ä¼ é€’çš„åŠ©æ‰‹æ¶ˆæ¯ ID
) -> StreamingResponse:
    """
    å¤„ç† LangGraph æµå¼å“åº” (v3.0)
    åªå‘é€æ–°åè®®äº‹ä»¶ï¼šplan.created, task.started, task.completed, artifact.generated, message.delta, message.done
    """
    async def event_generator():
        full_response = ""
        event_count = 0
        router_mode = ""
        task_session_id = None  # v3.0: è·Ÿè¸ª TaskSession ID
        
        # v3.0: æ”¶é›†ä»»åŠ¡åˆ—è¡¨å’Œäº§ç‰©ï¼ˆç”¨äºæœ€ç»ˆä¿å­˜ï¼‰
        collected_task_list = []
        expert_artifacts = {}
        
        # v3.0: åœ¨ initial_state ä¸­æ³¨å…¥æ•°æ®åº“ä¼šè¯å’Œ thread_id
        initial_state["db_session"] = session
        initial_state["thread_id"] = thread_id
        initial_state["event_queue"] = []
        initial_state["message_id"] = message_id  # v3.0: æ³¨å…¥å‰ç«¯ä¼ é€’çš„åŠ©æ‰‹æ¶ˆæ¯ ID

        try:
            async for event in commander_graph.astream_events(
                initial_state,
                version="v2"
            ):
                event_count += 1
                kind = event["event"]
                name = event.get("name", "")
                
                if event_count % 10 == 0:
                    print(f"[STREAM] å·²å¤„ç† {event_count} ä¸ªäº‹ä»¶ï¼Œå½“å‰: {kind} - {name}")

                # v3.0: å¤„ç†èŠ‚ç‚¹è¿”å›çš„ event_queueï¼ˆæ–°åè®®äº‹ä»¶ï¼‰
                if kind == "on_chain_end":
                    raw_output = event["data"].get("output", {})
                    # âœ… ç¡®ä¿ output_data æ˜¯å­—å…¸ç±»å‹ï¼ˆLangGraph æœ‰æ—¶ä¼šè¿”å›å­—ç¬¦ä¸²ï¼‰
                    output_data = raw_output if isinstance(raw_output, dict) else {}
                    # âœ… è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰ on_chain_end äº‹ä»¶
                    if isinstance(raw_output, dict):
                        print(f"[STREAM DEBUG] on_chain_end: name={name}, has_task_list={bool(output_data.get('task_list'))}, has_expert_info={bool(output_data.get('__expert_info'))}")
                    
                    if isinstance(output_data, dict):
                        event_queue = output_data.get("event_queue", [])
                        
                        # æ”¶é›†ä»»åŠ¡åˆ—è¡¨ï¼ˆä»ä»»ä½•è¿”å› task_list çš„èŠ‚ç‚¹ï¼‰
                        # âœ… é‡è¦ï¼šæ¯æ¬¡éƒ½æ›´æ–°ï¼Œå› ä¸º Generic Worker ä¼šæ›´æ–°ä»»åŠ¡çŠ¶æ€
                        if output_data.get("task_list"):
                            collected_task_list = output_data["task_list"]
                            # è°ƒè¯•æ—¥å¿—ï¼šæŸ¥çœ‹ä»»åŠ¡çŠ¶æ€å˜åŒ–
                            if DEBUG:
                                for task in collected_task_list:
                                    print(f"[STREAM] Task {task.get('expert_type')}: status={task.get('status')}, id={task.get('id')}")
                            
                        # æ”¶é›†äº§ç‰©ï¼ˆä» generic worker èŠ‚ç‚¹ï¼‰
                        if output_data.get("__expert_info"):
                            expert_info = output_data["__expert_info"]
                            task_id = expert_info.get("task_id")
                            expert_type = expert_info.get("expert_type")
                            artifact_data = output_data.get("artifact")
                            print(f"[STREAM DEBUG] expert_info found: task_id={task_id}, expert_type={expert_type}, has_artifact={bool(artifact_data)}")
                            if task_id and artifact_data:
                                # ä½¿ç”¨ task_id ä½œä¸º keyï¼Œç¡®ä¿æ¯ä¸ªä»»åŠ¡çš„ artifact éƒ½è¢«ä¿å­˜
                                if task_id not in expert_artifacts:
                                    expert_artifacts[task_id] = []
                                expert_artifacts[task_id].append(artifact_data)
                                print(f"[STREAM] âœ… æ”¶é›†åˆ° artifact: task_id={task_id}, type={artifact_data.get('type')}, title={artifact_data.get('title')}")
                            elif task_id:
                                print(f"[STREAM] âš ï¸ æœ‰ expert_info ä½†æ²¡æœ‰ artifact: task_id={task_id}, expert_type={expert_type}")
                            else:
                                print(f"[STREAM] âš ï¸ æœ‰ expert_info ä½†æ²¡æœ‰ task_id: expert_type={expert_type}")
                    else:
                        event_queue = []
                    
                    # å‘é€ event_queue ä¸­çš„æ‰€æœ‰äº‹ä»¶ï¼ˆæ–°åè®®ï¼‰
                    for queued_event in event_queue:
                        if queued_event.get("type") == "sse":
                            yield queued_event["event"]
                            
                            # è§£æ message.delta äº‹ä»¶ä»¥ç´¯ç§¯å†…å®¹
                            try:
                                event_lines = queued_event["event"].strip().split('\n')
                                event_data_str = ""
                                for line in event_lines:
                                    if line.startswith('data: '):
                                        event_data_str = line[6:]
                                        break
                                
                                if event_data_str:
                                    event_data = json.loads(event_data_str)
                                    if event_data.get('type') == 'message.delta':
                                        full_response += event_data.get('data', {}).get('content', '')
                            except Exception as e:
                                if DEBUG:
                                    print(f"[STREAM] è§£æäº‹ä»¶å¤±è´¥: {e}")

                # v3.0: æ•è· Router èŠ‚ç‚¹æ‰§è¡Œç»“æŸ
                if kind == "on_chain_end" and name == "router":
                    output_data = event["data"]["output"]
                    router_decision = output_data.get("router_decision", "")

                    if router_decision:
                        print(f"[STREAM] Router å†³ç­–: {router_decision}")
                        router_mode = router_decision
                        
                        # v3.0: å¦‚æœæ˜¯å¤æ‚æ¨¡å¼ï¼Œç«‹å³åˆ›å»º TaskSession å¹¶æ›´æ–° thread
                        if router_decision == "complex":
                            with Session(engine) as update_session:
                                thread_obj = update_session.get(Thread, thread_id)
                                if thread_obj:
                                    # ç«‹å³è®¾ç½® agent_type ä¸º ai
                                    if thread_obj.agent_type != "ai":
                                        thread_obj.agent_type = "ai"
                                    thread_obj.thread_mode = "complex"
                                    
                                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ TaskSessionï¼ˆé¿å…é‡å¤åˆ›å»ºï¼‰
                                    existing_ts = get_task_session_by_thread(update_session, thread_id)
                                    if existing_ts:
                                        task_session_id = existing_ts.session_id
                                        print(f"[STREAM] ä½¿ç”¨ç°æœ‰ TaskSession: {task_session_id}")
                                    else:
                                        # åˆ›å»ºæ–°çš„ TaskSession
                                        task_session = create_task_session(
                                            db=update_session,
                                            thread_id=thread_id,
                                            user_query=user_message
                                        )
                                        task_session_id = task_session.session_id
                                        thread_obj.task_session_id = task_session_id
                                        print(f"[STREAM] åˆ›å»ºæ–° TaskSession: {task_session_id}")
                                    
                                    update_session.add(thread_obj)
                                    update_session.commit()
                                    print(f"[STREAM] å·²æ›´æ–° thread ä¸º complex æ¨¡å¼")
                        
                        # v3.0: å‘é€ router.decision äº‹ä»¶ï¼ˆæ–°åè®®ï¼‰
                        from event_types.events import EventType, RouterDecisionData, build_sse_event
                        router_event = build_sse_event(
                            EventType.ROUTER_DECISION,
                            RouterDecisionData(decision=router_decision),
                            str(uuid4())
                        )
                        from utils.event_generator import sse_event_to_string
                        yield sse_event_to_string(router_event)

                # æ•è· direct_reply èŠ‚ç‚¹æ‰§è¡Œç»“æŸï¼ˆSimple æ¨¡å¼ï¼‰
                if kind == "on_chain_end" and name == "direct_reply":
                    # v3.0: Simple æ¨¡å¼ä½¿ç”¨ message.done äº‹ä»¶
                    from event_types.events import EventType, MessageDoneData, build_sse_event
                    done_event = build_sse_event(
                        EventType.MESSAGE_DONE,
                        MessageDoneData(message_id=message_id or str(uuid4()), full_content=full_response),
                        str(uuid4())
                    )
                    from utils.event_generator import sse_event_to_string
                    yield sse_event_to_string(done_event)
                    print(f"[STREAM] Direct Reply èŠ‚ç‚¹å®Œæˆ")

                # æ•è· LLM æµå¼è¾“å‡ºï¼ˆSimple æ¨¡å¼ï¼‰
                if kind == "on_chat_model_stream" and router_mode == "simple":
                    content = event["data"]["chunk"].content
                    if content:
                        full_response += content
                        # v3.0: Simple æ¨¡å¼ä¹Ÿä½¿ç”¨ message.delta äº‹ä»¶
                        from event_types.events import EventType, MessageDeltaData, build_sse_event
                        delta_event = build_sse_event(
                            EventType.MESSAGE_DELTA,
                            MessageDeltaData(message_id=message_id or str(uuid4()), content=content),
                            str(uuid4())
                        )
                        from utils.event_generator import sse_event_to_string
                        yield sse_event_to_string(delta_event)

            print(f"[STREAM] æµå¼å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {event_count} ä¸ªäº‹ä»¶")

        except Exception as e:
            print(f"[STREAM] é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            # v3.0: å‘é€ error äº‹ä»¶
            from event_types.events import EventType, ErrorData, build_sse_event
            from utils.event_generator import sse_event_to_string
            error_event = build_sse_event(
                EventType.ERROR,
                ErrorData(code="STREAM_ERROR", message=str(e)),
                str(uuid4())
            )
            yield sse_event_to_string(error_event)

        # ä¿å­˜ AI å›å¤å’Œ Artifacts åˆ°æ•°æ®åº“
        if full_response:
            with Session(engine) as save_session:
                # è§£æ thinking æ ‡ç­¾
                clean_content, thinking_data = parse_thinking(full_response)
                ai_msg_db = Message(
                    thread_id=thread_id,
                    role="assistant",
                    content=clean_content,  # ä¿å­˜æ¸…ç†åçš„å†…å®¹
                    extra_data={'thinking': thinking_data} if thinking_data else None,
                    timestamp=datetime.now()
                )
                save_session.add(ai_msg_db)

                thread_obj = save_session.get(Thread, thread_id)
                if thread_obj:
                    thread_obj.updated_at = datetime.now()

                    if router_mode:
                        thread_obj.thread_mode = router_mode
                        print(f"[STREAM] æ›´æ–° thread_mode ä¸º: {router_mode}")

                    # å¤æ‚æ¨¡å¼ï¼šæ›´æ–° TaskSession å’Œä¿å­˜ SubTask
                    print(f"[STREAM] ğŸ” è¯Šæ–­: router_mode={router_mode}, task_session_id={task_session_id}, len(collected_task_list)={len(collected_task_list)}")
                    
                    if router_mode == "complex" and task_session_id:
                        print(f"[STREAM] æ›´æ–°å¤æ‚æ¨¡å¼æ•°æ®: {len(collected_task_list)} ä¸ªä»»åŠ¡, session={task_session_id}")
                        
                        # æ›´æ–° TaskSession çŠ¶æ€ä¸ºå®Œæˆ
                        update_task_session_status(
                            save_session, 
                            task_session_id, 
                            "completed", 
                            final_response=full_response
                        )
                        
                        # è·å–å·²å­˜åœ¨çš„ SubTasksï¼ˆé¿å…é‡å¤åˆ›å»ºï¼‰
                        print(f"[STREAM] ğŸ” è¯Šæ–­: æŸ¥è¯¢ existing_subtasks, task_session_id={task_session_id}")
                        existing_subtasks = get_subtasks_by_session(save_session, task_session_id)
                        print(f"[STREAM] ğŸ” è¯Šæ–­: æŸ¥è¯¢åˆ° {len(existing_subtasks)} ä¸ª existing_subtasks")
                        existing_subtask_ids = {st.id for st in existing_subtasks}
                        print(f"[STREAM] ğŸ” è¯Šæ–­: existing_subtask_ids={existing_subtask_ids}")
                        
                        # ä¿å­˜/æ›´æ–° SubTasks
                        print(f"[STREAM] ğŸ” è¯Šæ–­: å‡†å¤‡éå† collected_task_list, æ•°é‡={len(collected_task_list)}")
                        if not collected_task_list:
                            print(f"[STREAM] ğŸ” è¯Šæ–­: collected_task_list ä¸ºç©ºï¼")
                        else:
                            for idx, task in enumerate(collected_task_list):
                                print(f"[STREAM] ğŸ” è¯Šæ–­: å¼€å§‹å¤„ç†ç¬¬ {idx} ä¸ª task")
                                task_id = task.get("id")
                                print(f"[STREAM] ğŸ” è¯Šæ–­:   task_id={task_id}")
                                print(f"[STREAM] ğŸ” è¯Šæ–­:   task_id in existing_subtask_ids? {task_id in existing_subtask_ids}")
                                
                                expert_type = task.get("expert_type", "")
                            task_id = task.get("id")
                                # âœ… ä½¿ç”¨ task_id è·å– artifactsï¼ˆä¸æ”¶é›†æ—¶ä¸€è‡´ï¼‰
                                artifacts_for_task = expert_artifacts.get(task_id, [])

                                print(f"[STREAM] ğŸ” è°ƒè¯•: å¤„ç† task_id={task_id}, expert_type={expert_type}")
                                print(f"[STREAM] ğŸ” è°ƒè¯•:   - task.get('status')={task.get('status')}")
                                print(f"[STREAM] ğŸ” è°ƒè¯•:   - task.get('output_result') type={type(task.get('output_result'))}")
                                print(f"[STREAM] ğŸ” è°ƒè¯•:   - artifacts_for_task count={len(artifacts_for_task)}")
                            
                            if task_id and task_id in existing_subtask_ids:
                                # æ›´æ–°ç°æœ‰ SubTask
                                # âœ… ä¿®å¤ï¼šoutput_result å·²ç»æ˜¯ {"content": "..."} æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                                output_value = task.get("output_result", {"content": ""})
                                # å…¼å®¹å¤„ç†ï¼šå¦‚æœå·²ç»æ˜¯å­—å…¸æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™åŒ…è£…
                                if isinstance(output_value, dict):
                                    output_result = output_value
                                else:
                                    output_result = {"content": str(output_value)}
                                
                                print(f"[STREAM] ğŸ” è°ƒè¯•: è°ƒç”¨ update_subtask_status")
                                print(f"[STREAM] ğŸ” è°ƒè¯•:   - status={task.get('status', 'completed')}")
                                print(f"[STREAM] ğŸ” è°ƒè¯•:   - output_result type={type(output_result)}")
                                
                                update_subtask_status(
                                    save_session,
                                    task_id,
                                    status=task.get("status", "completed"),
                                    output_result=output_result,
                                    duration_ms=task.get("duration_ms")  # âœ… æ·»åŠ  duration_ms
                                )
                                print(f"[STREAM] âœ… SubTask çŠ¶æ€å·²æ›´æ–°")
                                
                                # ä¿å­˜ artifacts
                                if artifacts_for_task:
                                    print(f"[STREAM] å‡†å¤‡ä¿å­˜ artifacts: task_id={task_id}, count={len(artifacts_for_task)}")
                                    for art in artifacts_for_task:
                                        print(f"[STREAM]   - artifact: type={art.get('type')}, title={art.get('title')[:30]}...")
                                    try:
                                        created = create_artifacts_batch(save_session, task_id, artifacts_for_task)
                                        print(f"[STREAM] âœ… æˆåŠŸä¿å­˜ {len(created)} ä¸ª artifacts åˆ° SubTask: {task_id}")
                                    except Exception as art_err:
                                        print(f"[STREAM] âŒ ä¿å­˜ artifacts å¤±è´¥: {art_err}")
                                        import traceback
                                        traceback.print_exc()
                                print(f"[STREAM] æ›´æ–° SubTask: {expert_type}")
                            else:
                                # åˆ›å»ºæ–° SubTask
                                create_subtask(
                                    save_session,
                                    task_session_id=task_session_id,
                                    expert_type=expert_type,
                                    task_description=task.get("description", ""),
                                    sort_order=task.get("sort_order", 0),
                                    input_data=task.get("input_data", {})
                                )
                                print(f"[STREAM] ğŸ” è¯Šæ–­: åˆ›å»ºæ–° SubTask, task_id={task_id}, expert_type={expert_type}")

                    print(f"[STREAM] ğŸ” è¯Šæ–­: for å¾ªç¯å®Œæˆï¼Œå‡†å¤‡æäº¤")
                    save_session.add(thread_obj)
                save_session.commit()
                print(f"[STREAM] ğŸ” è¯Šæ–­: æ•°æ®åº“å·²æäº¤")

        yield "data: [DONE]\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


async def _handle_langgraph_sync(
    initial_state: dict,
    thread_id: str,
    thread: Thread,
    user_message: str,
    session: Session
) -> dict:
    """å¤„ç† LangGraph éæµå¼å“åº”"""
    result = await commander_graph.ainvoke(initial_state)
    last_message = result["messages"][-1]

    # è·å– Router å†³ç­–å¹¶æ›´æ–° thread_mode
    router_decision = result.get("router_decision", "simple")
    thread.thread_mode = router_decision
    
    # v3.0: å°½æ—©è®¾ç½® agent_typeï¼Œè¿™æ ·å³ä½¿ä»»åŠ¡è¿›è¡Œä¸­åˆ·æ–°ä¹Ÿèƒ½æ­£ç¡®æ¢å¤çŠ¶æ€
    if router_decision == "complex":
        thread.agent_type = "ai"
        session.add(thread)
        session.flush()

        # åˆ›å»º TaskSession
        task_session = TaskSession(
            session_id=str(uuid4()),
            thread_id=thread_id,
            user_query=user_message,
            status="completed",
            final_response=last_message.content,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            completed_at=datetime.now()
        )
        session.add(task_session)
        session.flush()

        # æ›´æ–° thread çš„ task_session_id
        thread.task_session_id = task_session.session_id

        # ä¿å­˜ SubTaskï¼ˆåŒ…æ‹¬ artifactsï¼‰
        for subtask in result["task_list"]:
            artifacts = subtask.get("artifact")
            if artifacts:
                artifacts = [artifacts] if isinstance(artifacts, dict) else artifacts

            db_subtask = SubTask(
                id=subtask["id"],
                expert_type=subtask["expert_type"],
                task_description=subtask["description"],
                input_data=subtask["input_data"],
                status=subtask["status"],
                output_result=subtask["output_result"],
                artifacts=artifacts,
                started_at=subtask.get("started_at"),
                completed_at=subtask.get("completed_at"),
                created_at=subtask.get("created_at"),
                updated_at=subtask.get("updated_at"),
                task_session_id=task_session.session_id
            )
            session.add(db_subtask)

    # ä¿å­˜ AI å›å¤
    # è§£æ thinking æ ‡ç­¾
    clean_content, thinking_data = parse_thinking(last_message.content)
    ai_msg_db = Message(
        thread_id=thread_id,
        role="assistant",
        content=clean_content,  # ä¿å­˜æ¸…ç†åçš„å†…å®¹
        extra_data={'thinking': thinking_data} if thinking_data else None,
        timestamp=datetime.now()
    )
    session.add(ai_msg_db)
    thread.updated_at = datetime.now()
    session.add(thread)
    session.commit()

    return {
        "role": "assistant",
        "content": last_message.content,
        "conversationId": thread_id,
        "threadMode": router_decision
    }
