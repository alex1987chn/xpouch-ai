import pathlib
from dotenv import load_dotenv
import os
import sys

# >>> RELOADED main.py: Starting initialization...

# Load .env from the same directory as this file
env_path = pathlib.Path(__file__).parent / ".env"
load_dotenv(dotenv_path=env_path, override=True)

from fastapi import FastAPI, Request, Response, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, AsyncGenerator
from types import SimpleNamespace
import json
import re
import uvicorn
import os
from langchain_core.messages import HumanMessage, AIMessage
from sqlmodel import Session, select
from sqlalchemy.orm import selectinload # Import selectinload
from contextlib import asynccontextmanager
from datetime import datetime
import uuid
import io

from agents.graph import commander_graph
from agents.dynamic_experts import DYNAMIC_EXPERT_FUNCTIONS, initialize_expert_cache
from models import (
    Thread, Message, User, TaskSession, SubTask,
    CustomAgent, CustomAgentCreate, CustomAgentUpdate, CustomAgentResponse,
    ThreadResponse, MessageResponse
)
from database import create_db_and_tables, get_session, engine
from config import init_langchain_tracing, validate_config
from constants import (
    normalize_agent_id,
    is_system_agent,
    SYSTEM_AGENT_ORCHESTRATOR,
    SYSTEM_AGENT_DEFAULT_CHAT
)
from utils.artifacts import parse_artifacts_from_response, generate_artifact_event
from utils.exceptions import (
    AppError,
    ValidationError,
    AuthenticationError,
    AuthorizationError,
    NotFoundError,
    LLMError,
    DatabaseError,
    ExternalServiceError,
    RateLimitError,
    handle_error
)
from auth import router as auth_router
from api.admin import router as admin_router
from utils.llm_factory import get_llm_instance


# ============================================================================
# æµå¼è¾“å‡ºè¿‡æ»¤å‡½æ•°
# ============================================================================

def should_stream_event(event_tags: list, router_mode: str, name: str = "") -> tuple[bool, str]:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥å°†å½“å‰äº‹ä»¶æµå¼è¾“å‡ºåˆ°å‰ç«¯
    
    Args:
        event_tags: äº‹ä»¶æ ‡ç­¾åˆ—è¡¨
        router_mode: å½“å‰è·¯ç”±æ¨¡å¼ ("", "simple", "complex")
        name: äº‹ä»¶åç§°ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    
    Returns:
        tuple[bool, str]: (æ˜¯å¦åº”è¾“å‡º, è·³è¿‡åŸå› )
    
    è¿‡æ»¤è§„åˆ™ï¼š
    - Router æ¨¡å¼æœªçŸ¥æ—¶: è·³è¿‡æ‰€æœ‰å†…éƒ¨èŠ‚ç‚¹ (router/planner/expert)
    - Simple æ¨¡å¼: åªå…è®¸ direct_reply èŠ‚ç‚¹
    - Complex æ¨¡å¼: è·³è¿‡å†…éƒ¨èŠ‚ç‚¹ï¼Œä¿ç•™ Aggregator è¾“å‡º
    """
    tags_str = str(event_tags).lower()
    
    # Router å†³ç­–æœªçŸ¥æ—¶ï¼Œè·³è¿‡æ‰€æœ‰å†…éƒ¨èŠ‚ç‚¹
    if router_mode == "":
        if any(tag in tags_str for tag in ["router", "commander", "planner", "expert"]):
            return False, f"Router å†³ç­–æœªçŸ¥ï¼Œè·³è¿‡å†…éƒ¨èŠ‚ç‚¹: {tags_str}"
    
    # Simple æ¨¡å¼ï¼šåªå…è®¸ direct_reply èŠ‚ç‚¹
    elif router_mode == "simple":
        if "direct_reply" not in tags_str:
            return False, f"Simple æ¨¡å¼ï¼šè·³è¿‡é direct_reply: {tags_str}"
    
    # Complex æ¨¡å¼ï¼šè·³è¿‡å†…éƒ¨è§„åˆ’èŠ‚ç‚¹å’Œä¸“å®¶
    else:  # router_mode == "complex"
        if any(tag in tags_str for tag in ["router", "commander", "planner", "expert"]):
            return False, f"Complex æ¨¡å¼ï¼šè·³è¿‡å†…éƒ¨èŠ‚ç‚¹: {tags_str}"
    
    return True, "é€šè¿‡è¿‡æ»¤"


def is_task_plan_content(content: str) -> bool:
    """
    æ£€æŸ¥å†…å®¹æ˜¯å¦æ˜¯ä»»åŠ¡è®¡åˆ’ JSON
    
    ç”¨äºè¿‡æ»¤æ‰ä¸åº”å±•ç¤ºç»™ç”¨æˆ·çš„å†…éƒ¨ä»»åŠ¡è®¡åˆ’æ•°æ®
    """
    if not content:
        return False
    
    content_stripped = content.strip()
    
    # ç§»é™¤ Markdown ä»£ç å—æ ‡è®°
    import re
    code_block_match = re.match(r'^```(?:json)?\s*([\s\S]*?)\s*```$', content_stripped)
    if code_block_match:
        content_stripped = code_block_match.group(1).strip()
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ JSON æ ¼å¼çš„ä»»åŠ¡è®¡åˆ’
    if content_stripped.startswith('{'):
        content_lower = content_stripped.lower()
        if (('"tasks"' in content_lower and '"strategy"' in content_lower) or
            ('"tasks"' in content_lower and '"expert_type"' in content_lower) or
            ('"estimated_steps"' in content_lower)):
            return True
    
    return False


# ============================================================================
# å…±äº«çš„å¤§æ¨¡å‹è°ƒç”¨å‡½æ•°
# ============================================================================

async def stream_llm_response(
    messages: list,
    system_prompt: str,
    model: str = None,
    thread_id: str = None
) -> AsyncGenerator[str, None]:
    """
    å…±äº«çš„å¤§æ¨¡å‹æµå¼å“åº”å‡½æ•°

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨ï¼ˆLangChain æ ¼å¼ï¼‰
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        thread_id: çº¿ç¨‹ IDï¼ˆå¯é€‰ï¼‰

    Yields:
        SSE æ ¼å¼çš„æ•°æ®å—
    """
    # ä½¿ç”¨å·¥å‚å‡½æ•°è·å– LLM å®ä¾‹
    llm = get_llm_instance(streaming=True, model=model, temperature=0.7)

    # æ·»åŠ  System Prompt
    messages_with_system = []
    messages_with_system.append(("system", system_prompt))
    messages_with_system.extend(messages)

    async for chunk in llm.astream(messages_with_system):
        content = chunk.content
        if content:
            # SSE æ ¼å¼ï¼šdata: {...}\n\n
            event_data = {'content': content}
            if thread_id:
                event_data['conversationId'] = thread_id
            yield f"data: {json.dumps(event_data)}\n\n"


async def invoke_llm_response(
    messages: list,
    system_prompt: str,
    model: str = None
) -> str:
    """
    å…±äº«çš„å¤§æ¨¡å‹éæµå¼å“åº”å‡½æ•°

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨ï¼ˆLangChain æ ¼å¼ï¼‰
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰

    Returns:
        å®Œæ•´çš„å“åº”æ–‡æœ¬
    """
    # ä½¿ç”¨å·¥å‚å‡½æ•°è·å– LLM å®ä¾‹ï¼ˆéæµå¼ï¼‰
    llm = get_llm_instance(streaming=False, model=model, temperature=0.7)

    # æ·»åŠ  System Prompt
    messages_with_system = []
    messages_with_system.append(("system", system_prompt))
    messages_with_system.extend(messages)

    result = await llm.ainvoke(messages_with_system)
    return result.content



@asynccontextmanager
async def lifespan(app: FastAPI):
    # åˆå§‹åŒ– LangSmith è¿½è¸ª
    init_langchain_tracing()
    # éªŒè¯é…ç½®
    validate_config()
    # åˆ›å»ºæ•°æ®åº“è¡¨
    create_db_and_tables()
    # åˆå§‹åŒ–ç³»ç»Ÿä¸“å®¶æ•°æ®
    from models import SystemExpert
    from scripts.init_experts import EXPERT_DEFAULTS

    with Session(engine) as session:
        existing_experts = session.exec(select(SystemExpert)).all()
        existing_keys = {e.expert_key for e in existing_experts}

        if not existing_experts:
            print("[Lifespan] No experts found, initializing default experts...")
            for expert_config in EXPERT_DEFAULTS:
                expert = SystemExpert(**expert_config)
                session.add(expert)
            session.commit()
            print(f"[Lifespan] Initialized {len(EXPERT_DEFAULTS)} experts")
        else:
            print(f"[Lifespan] Found {len(existing_experts)} experts in database")

    # æ¸…ç©ºä¸“å®¶ç¼“å­˜ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„å…œåº•æœºåˆ¶é‡æ–°åŠ è½½
    from agents.expert_loader import force_refresh_all
    force_refresh_all()
    print("[Lifespan] Expert cache cleared for fresh start")

    print("[Lifespan] Startup complete, yielding control to Uvicorn...")
    yield
    print("[Lifespan] Shutdown started...")

app = FastAPI(lifespan=lifespan)

# æ³¨å†Œè·¯ç”±
app.include_router(auth_router)
app.include_router(admin_router)  # ç®¡ç†å‘˜ API

# æ·»åŠ è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
@app.middleware("http")
async def log_requests(request: Request, call_next) -> Response:
    print(f"[REQUEST] {request.method} {request.url.path}")
    try:
        response = await call_next(request)
        print(f"[RESPONSE] {response.status_code} {request.url.path}")
        return response
    except Exception as e:
        print(f"[ERROR] Exception in {request.method} {request.url.path}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError) -> JSONResponse:
    return JSONResponse(
        status_code=422,
        content={"detail": exc.errors(), "body": exc.body},
    )

@app.exception_handler(AppError)
async def app_error_handler(request: Request, exc: AppError) -> JSONResponse:
    """å¤„ç†è‡ªå®šä¹‰åº”ç”¨å¼‚å¸¸"""
    print(f"[APP ERROR] {exc.code}: {exc.message}")
    if exc.original_error:
        import traceback
        traceback.print_exception(type(exc.original_error), exc.original_error, exc.original_error.__traceback__)
    return JSONResponse(
        status_code=exc.status_code,
        content=exc.to_dict(),
    )


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException) -> JSONResponse:
    """å¤„ç† FastAPI HTTP å¼‚å¸¸"""
    print(f"[HTTP ERROR] {exc.status_code}: {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": {
                "code": "HTTP_ERROR",
                "message": str(exc.detail),
                "details": {}
            }
        },
    )


@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception) -> JSONResponse:
    """å¤„ç†æœªæ•è·çš„å¼‚å¸¸"""
    import traceback
    print("=" * 80)
    print("[UNHANDLED ERROR] Global exception caught:")
    print(f"[UNHANDLED ERROR] Request path: {request.url.path}")
    print(f"[UNHANDLED ERROR] Exception type: {type(exc).__name__}")
    print(f"[UNHANDLED ERROR] Exception message: {str(exc)}")
    print("[UNHANDLED ERROR] Stack trace:")
    traceback.print_exc()
    print("=" * 80)
    
    # è½¬æ¢ä¸º AppError
    app_error = handle_error(exc)
    return JSONResponse(
        status_code=app_error.status_code,
        content=app_error.to_dict(),
    )

# é…ç½® CORS
def get_cors_origins():
    """ä»ç¯å¢ƒå˜é‡ CORS_ORIGINS è¯»å–å…è®¸çš„æ¥æºï¼Œæ”¯æŒé€—å·åˆ†éš”çš„å¤šä¸ªåŸŸå"""
    cors_origins_str = os.getenv("CORS_ORIGINS", "").strip()
    if cors_origins_str:
        # æŒ‰é€—å·åˆ†å‰²ï¼Œå»é™¤ç©ºç™½å­—ç¬¦
        origins = [origin.strip() for origin in cors_origins_str.split(",")]
        print(f"[CORS] å…è®¸çš„æ¥æº: {origins}")
        return origins
    
    # æœªè®¾ç½® CORS_ORIGINSï¼Œæ ¹æ®ç¯å¢ƒå˜é‡å†³å®šé»˜è®¤å€¼
    environment = os.getenv("ENVIRONMENT", "development").lower()
    if environment == "production":
        print("[WARN] ç”Ÿäº§ç¯å¢ƒæœªè®¾ç½® CORS_ORIGINSï¼ŒCORS å°†æ‹’ç»æ‰€æœ‰è·¨åŸŸè¯·æ±‚")
        return []
    else:
        # å¼€å‘ç¯å¢ƒé»˜è®¤å…è®¸æœ¬åœ°å‰ç«¯
        default_origin = "http://localhost:5173"
        print(f"[CORS] å¼€å‘ç¯å¢ƒé»˜è®¤å…è®¸æ¥æº: {default_origin}")
        return [default_origin]

app.add_middleware(
    CORSMiddleware,
    allow_origins=get_cors_origins(),
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["Authorization", "Content-Type", "X-User-ID", "X-Request-ID"],
)

# æ·»åŠ è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
@app.middleware("http")
async def log_requests(request: Request, call_next):
    print(f"[Main] æ”¶åˆ°è¯·æ±‚: {request.method} {request.url}")
    print(f"[Main] Headers: {dict(request.headers)}")
    response = await call_next(request)
    print(f"[Main] å“åº”çŠ¶æ€: {response.status_code}")
    return response

# æ·»åŠ å®‰å…¨å¤´ä¿¡æ¯ä¸­é—´ä»¶
@app.middleware("http")
async def add_security_headers(request: Request, call_next):
    response = await call_next(request)
    # å®‰å…¨å¤´ä¿¡æ¯
    response.headers["X-Frame-Options"] = "DENY"
    response.headers["X-Content-Type-Options"] = "nosniff"
    response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
    # åŸºæœ¬ CSP - å…è®¸è‡ªèº«å’Œ inline æ ·å¼/è„šæœ¬ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    csp_policy = "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline';"
    response.headers["Content-Security-Policy"] = csp_policy
    # æƒé™ç­–ç•¥
    response.headers["Permissions-Policy"] = "camera=(), microphone=(), geolocation=()"
    return response

class ChatMessageDTO(BaseModel):
    role: str
    content: str
    id: Optional[str] = None
    timestamp: Optional[str] = None

class ChatRequest(BaseModel):
    message: str
    history: List[ChatMessageDTO]
    conversationId: Optional[str] = None
    agentId: Optional[str] = "assistant"
    stream: Optional[bool] = True


class ChatInvokeRequest(BaseModel):
    """åŒæ¨¡è·¯ç”±è¯·æ±‚æ¨¡å‹"""
    message: str
    mode: str = "auto"  # "auto" æˆ– "direct"
    agent_id: Optional[str] = None  # direct æ¨¡å¼ä¸‹å¿…å¡«
    thread_id: Optional[str] = None  # LangSmith çº¿ç¨‹ ID

class UpdateUserRequest(BaseModel):
    username: Optional[str] = None
    avatar: Optional[str] = None
    plan: Optional[str] = None

# --- Dependency: Current User ---
async def get_current_user(
    request: Request,
    session: Session = Depends(get_session),
    require_auth: bool = False  # æ˜¯å¦å¼ºåˆ¶è¦æ±‚JWTè®¤è¯
) -> User:
    """
    è·å–å½“å‰ç”¨æˆ·ï¼ˆä¼˜å…ˆJWTï¼Œå›é€€X-User-IDï¼‰

    ç­–ç•¥ï¼š
    1. é¦–å…ˆæ£€æŸ¥Authorizationå¤´ï¼ˆJWT tokenï¼‰
    2. å¦‚æœJWTæœ‰æ•ˆï¼Œä½¿ç”¨JWTä¸­çš„user_id
    3. å¦‚æœæ²¡æœ‰JWTï¼Œå›é€€åˆ°X-User-IDå¤´ï¼ˆå‘åå…¼å®¹ï¼‰
    4. å¦‚æœrequire_auth=Trueä¸”éƒ½æ²¡æœ‰è®¤è¯ï¼ŒæŠ›å‡º401é”™è¯¯

    Args:
        request: FastAPIè¯·æ±‚å¯¹è±¡
        session: æ•°æ®åº“ä¼šè¯
        require_auth: æ˜¯å¦å¼ºåˆ¶è¦æ±‚è®¤è¯ï¼ˆé»˜è®¤Falseï¼Œå‘åå…¼å®¹ï¼‰

    Returns:
        ç”¨æˆ·å¯¹è±¡
    """
    from utils.jwt_handler import verify_token, AuthenticationError as JWTAuthError

    # ç­–ç•¥1: å°è¯•ä»Authorizationå¤´è·å–JWT token
    auth_header = request.headers.get("Authorization")
    if auth_header and auth_header.startswith("Bearer "):
        token = auth_header.split(" ")[1]
        try:
            payload = verify_token(token, token_type="access")
            user_id = payload["sub"]
            
            user = session.get(User, user_id)
            if user:
                return user
        except JWTAuthError:
            # JWTæ— æ•ˆï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹å¼
            pass

    # ç­–ç•¥2: å›é€€åˆ°X-User-IDå¤´ï¼ˆå‘åå…¼å®¹ï¼‰ - ä»…åœ¨éä¸¥æ ¼è®¤è¯æ¨¡å¼ä¸‹ä½¿ç”¨
    if not require_auth:
        user_id = request.headers.get("X-User-ID")
        if user_id:
            user = session.get(User, user_id)
            if user:
                return user
            else:
                # æœªå¯ç”¨ä¸¥æ ¼è®¤è¯æ—¶ï¼Œè‡ªåŠ¨æ³¨å†Œæ–°ç”¨æˆ·ï¼ˆå‘åå…¼å®¹ï¼‰
                user = User(id=user_id, username=f"User-{user_id[:4]}")
                session.add(user)
                session.commit()
                session.refresh(user)
                return user

    # ç­–ç•¥3: æ²¡æœ‰ä»»ä½•è®¤è¯ä¿¡æ¯ - ä»…åœ¨éä¸¥æ ¼è®¤è¯æ¨¡å¼ä¸‹ä½¿ç”¨
    if not require_auth:
        # æœªå¯ç”¨ä¸¥æ ¼è®¤è¯æ—¶ï¼Œä½¿ç”¨é»˜è®¤ç”¨æˆ·ï¼ˆå‘åå…¼å®¹ï¼‰
        user = session.get(User, "default-user")
        if user:
            return user
        else:
            user = User(id="default-user", username="Default User")
            session.add(user)
            session.commit()
            session.refresh(user)
            return user

    # ä¸¥æ ¼è®¤è¯æ¨¡å¼ï¼šæŠ›å‡º401é”™è¯¯
    raise HTTPException(
        status_code=401,
        detail="Unauthorized. Please login first."
    )

# --- Helper: Require Authentication ---
async def get_current_user_with_auth(
    request: Request,
    session: Session = Depends(get_session)
) -> User:
    """è¦æ±‚å¼ºåˆ¶JWTè®¤è¯çš„ä¾èµ–ï¼ˆåŒ…è£… get_current_userï¼‰"""
    return await get_current_user(request, session, require_auth=True)

# --- API Endpoints ---

@app.get("/")
async def root():
    return {"status": "ok", "message": "XPouch AI Backend (Python + SQLModel) is running"}

# ç”¨æˆ·ä¿¡æ¯æ¥å£
@app.get("/api/user/me")
async def get_user_me(current_user: User = Depends(get_current_user_with_auth)):
    return current_user

@app.put("/api/user/me")
async def update_user_me(request: UpdateUserRequest, session: Session = Depends(get_session), current_user: User = Depends(get_current_user_with_auth)):
    import sys
    from datetime import datetime
    print(f"[API] æ”¶åˆ°æ›´æ–°ç”¨æˆ·ä¿¡æ¯è¯·æ±‚ï¼Œç”¨æˆ·ID: {current_user.id}", file=sys.stderr)
    print(f"[API] è¯·æ±‚å†…å®¹: username={request.username}, avatar={'æœ‰' if request.avatar else 'å¦'}, plan={request.plan}", file=sys.stderr)

    # è®°å½•æ›´æ–°æ—¶é—´æˆ³
    current_user.updated_at = datetime.now()
    
    if request.username is not None:
        current_user.username = request.username
        print(f"[API] æ›´æ–°ç”¨æˆ·åä¸º: {request.username}", file=sys.stderr)
    if request.avatar is not None:
        current_user.avatar = request.avatar
        print(f"[API] æ›´æ–°å¤´åƒ: {'æ˜¯' if request.avatar else 'å¦'}", file=sys.stderr)
    if request.plan is not None:
        current_user.plan = request.plan
        print(f"[API] æ›´æ–°å¥—é¤: {request.plan}", file=sys.stderr)

    session.add(current_user)
    session.commit()
    session.refresh(current_user)

    print(f"[API] ç”¨æˆ·ä¿¡æ¯æ›´æ–°æˆåŠŸ: {current_user.username} (æ›´æ–°æ—¶é—´: {current_user.updated_at})", file=sys.stderr)
    return current_user


# ============================================================================
# è°ƒè¯•æ¥å£ - ä¸´æ—¶ç”¨äºæ’æŸ¥ç”¨æˆ·é—®é¢˜
# ============================================================================

@app.get("/api/debug/users")
async def debug_list_users(session: Session = Depends(get_session)):
    """åˆ—å‡ºæ‰€æœ‰ç”¨æˆ·ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰"""
    users = session.exec(select(User).order_by(User.created_at.desc())).all()
    return {
        "count": len(users),
        "users": [
            {
                "id": u.id,
                "username": u.username,
                "phone_number": u.phone_number,
                "auth_provider": u.auth_provider,
                "created_at": u.created_at.isoformat() if u.created_at else None
            }
            for u in users
        ]
    }

@app.get("/api/debug/verify-token")
async def debug_verify_token(request: Request, session: Session = Depends(get_session)):
    """éªŒè¯JWT tokenå¹¶è¿”å›ç”¨æˆ·ä¿¡æ¯ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰"""
    auth_header = request.headers.get("Authorization")
    if not auth_header or not auth_header.startswith("Bearer "):
        return {"error": "No Authorization header"}

    from utils.jwt_handler import verify_token, AuthenticationError as JWTAuthError

    token = auth_header.split(" ")[1]
    try:
        payload = verify_token(token, token_type="access")
        user_id = payload["sub"]
        user = session.get(User, user_id)

        if user:
            return {
                "token_user_id": user_id,
                "user_found": True,
                "user": {
                    "id": user.id,
                    "username": user.username,
                    "phone_number": user.phone_number,
                    "auth_provider": user.auth_provider
                }
            }
        else:
            return {
                "token_user_id": user_id,
                "user_found": False,
                "error": "User not found in database"
            }
    except JWTAuthError as e:
        return {
            "error": "Invalid token",
            "detail": str(e)
        }

@app.delete("/api/debug/cleanup-users")
async def debug_cleanup_users():
    """æ¸…ç†æ²¡æœ‰æ‰‹æœºå·çš„åƒåœ¾ç”¨æˆ·ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰"""
    from database import engine
    from sqlalchemy.orm import Session
    import sys
    
    # åˆ›å»ºæ–°çš„sessionï¼Œä¸ç»è¿‡get_current_userä¾èµ–
    with Session(engine) as session:
        # æŸ¥æ‰¾æ‰€æœ‰æ²¡æœ‰æ‰‹æœºå·çš„ç”¨æˆ·
        users_to_delete = session.exec(
            select(User).where(User.phone_number.is_(None))
        ).all()

        count = len(users_to_delete)

        for user in users_to_delete:
            # 1. å…ˆåˆ é™¤è¯¥ç”¨æˆ·çš„æ‰€æœ‰çº¿ç¨‹ï¼ˆä¼šçº§è”åˆ é™¤messagesï¼‰
            threads = session.exec(
                select(Thread).where(Thread.user_id == user.id)
            ).all()
            for conv in threads:
                session.delete(conv)

            # 2. åˆ é™¤è¯¥ç”¨æˆ·çš„æ‰€æœ‰è‡ªå®šä¹‰æ™ºèƒ½ä½“
            custom_agents = session.exec(
                select(CustomAgent).where(CustomAgent.user_id == user.id)
            ).all()
            for agent in custom_agents:
                session.delete(agent)
            
            # 3. æœ€ååˆ é™¤ç”¨æˆ·
            session.delete(user)

        session.commit()

        return {
            "deleted_count": count,
            "deleted_users": [{"id": u.id, "username": u.username} for u in users_to_delete]
        }

# ============================================================================
# è‡ªå®šä¹‰æ™ºèƒ½ä½“ APIï¼ˆç®€å•å¯¹è¯æ¨¡å¼ï¼‰
# ============================================================================

@app.post("/api/agents")
async def create_custom_agent(
    agent_data: CustomAgentCreate,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    åˆ›å»ºè‡ªå®šä¹‰æ™ºèƒ½ä½“
    
    ç”¨æˆ·åˆ›å»ºçš„æ™ºèƒ½ä½“ç”¨äºç®€å•çš„å¯¹è¯åœºæ™¯ï¼Œç›´æ¥ä½¿ç”¨è‡ªå®šä¹‰çš„ system_prompt
    è°ƒç”¨ LLMï¼Œä¸ç»è¿‡ LangGraph ä¸“å®¶å·¥ä½œæµã€‚
    """
    custom_agent = CustomAgent(
        user_id=current_user.id,
        name=agent_data.name,
        description=agent_data.description,
        system_prompt=agent_data.system_prompt,
        category=agent_data.category,
        model_id=agent_data.model_id
    )
    session.add(custom_agent)
    session.commit()
    session.refresh(custom_agent)
    return custom_agent


@app.get("/api/agents")
async def get_all_agents(
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    è·å–å½“å‰ç”¨æˆ·çš„æ‰€æœ‰è‡ªå®šä¹‰æ™ºèƒ½ä½“

    è¿”å›åˆ—è¡¨ï¼š
    - ç”¨æˆ·è‡ªå®šä¹‰æ™ºèƒ½ä½“ï¼ˆæŒ‰åˆ›å»ºæ—¶é—´é™åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰

    æ³¨æ„ï¼š
    - ç³»ç»Ÿä¸“å®¶ï¼ˆsearch, coder, researcherç­‰ï¼‰ä¸è¿”å›ï¼Œè™šæ‹Ÿä¸“å®¶ä¸æš´éœ²åˆ°å‰ç«¯
    - é»˜è®¤åŠ©æ‰‹ï¼ˆç®€å•æ¨¡å¼ï¼‰ç”±å‰ç«¯ç¡¬ç¼–ç ï¼Œä¸åœ¨æ­¤æ¥å£è¿”å›
    """
    try:
        # è·å–ç”¨æˆ·è‡ªå®šä¹‰æ™ºèƒ½ä½“ï¼ˆæŒ‰åˆ›å»ºæ—¶é—´é™åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
        statement = select(CustomAgent).where(
            CustomAgent.user_id == current_user.id,
            CustomAgent.is_default == False  # æ’é™¤é»˜è®¤åŠ©æ‰‹
        ).order_by(CustomAgent.created_at.desc())

        custom_agents = session.exec(statement).all()

        # æ„å»ºè¿”å›ç»“æœ
        result = []

        # æ·»åŠ è‡ªå®šä¹‰æ™ºèƒ½ä½“
        for agent in custom_agents:
            result.append({
                "id": str(agent.id),
                "name": agent.name,
                "description": agent.description or "",
                "system_prompt": agent.system_prompt,
                "category": agent.category,
                "model_id": agent.model_id,
                "conversation_count": agent.conversation_count,
                "is_public": agent.is_public,
                "is_default": False,
                "created_at": agent.created_at.isoformat() if agent.created_at else None,
                "updated_at": agent.updated_at.isoformat() if agent.updated_at else None,
                "is_builtin": False
            })


        return result

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise AppError(message=str(e), original_error=e)


@app.get("/api/agents/{agent_id}")
async def get_custom_agent(
    agent_id: str,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """è·å–å•ä¸ªè‡ªå®šä¹‰æ™ºèƒ½ä½“è¯¦æƒ…"""
    agent = session.get(CustomAgent, agent_id)
    if not agent or agent.user_id != current_user.id:
        raise NotFoundError(resource="æ™ºèƒ½ä½“")
    return agent


@app.delete("/api/agents/{agent_id}")
async def delete_custom_agent(
    agent_id: str,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    åˆ é™¤è‡ªå®šä¹‰æ™ºèƒ½ä½“

    æ³¨æ„ï¼š
    - ç¦æ­¢åˆ é™¤é»˜è®¤åŠ©æ‰‹ï¼ˆis_default=Trueï¼‰
    - åªèƒ½åˆ é™¤ç”¨æˆ·è‡ªå·±çš„æ™ºèƒ½ä½“
    """
    agent = session.get(CustomAgent, agent_id)
    if not agent or agent.user_id != current_user.id:
        raise NotFoundError(resource="æ™ºèƒ½ä½“")

    # ç¦æ­¢åˆ é™¤é»˜è®¤åŠ©æ‰‹
    if agent.is_default:
        raise AppError(message="ç¦æ­¢åˆ é™¤é»˜è®¤åŠ©æ‰‹")

    session.delete(agent)
    session.commit()
    return {"ok": True}


@app.put("/api/agents/{agent_id}")
async def update_custom_agent(
    agent_id: str,
    agent_data: CustomAgentUpdate,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """æ›´æ–°è‡ªå®šä¹‰æ™ºèƒ½ä½“"""
    agent = session.get(CustomAgent, agent_id)
    if not agent or agent.user_id != current_user.id:
        raise NotFoundError(resource="æ™ºèƒ½ä½“")
    
    if agent_data.name is not None:
        agent.name = agent_data.name
    if agent_data.description is not None:
        agent.description = agent_data.description
    if agent_data.system_prompt is not None:
        agent.system_prompt = agent_data.system_prompt
    if agent_data.category is not None:
        agent.category = agent_data.category
    if agent_data.model_id is not None:
        agent.model_id = agent_data.model_id
    
    agent.updated_at = datetime.now()
    session.add(agent)
    session.commit()
    session.refresh(agent)
    return agent


# è·å–æ‰€æœ‰çº¿ç¨‹åˆ—è¡¨ (Filtered by User)
@app.get("/api/threads", response_model=List[ThreadResponse])
async def get_threads(session: Session = Depends(get_session), current_user: User = Depends(get_current_user)):
    statement = select(Thread).where(Thread.user_id == current_user.id).options(selectinload(Thread.messages)).order_by(Thread.updated_at.desc())
    threads = session.exec(statement).all()
    return [ThreadResponse.model_validate(conv) for conv in threads]

# è·å–å•ä¸ªçº¿ç¨‹è¯¦æƒ… (Filtered by User)
@app.get("/api/threads/{thread_id}")
async def get_thread(thread_id: str, session: Session = Depends(get_session), current_user: User = Depends(get_current_user)):
    statement = select(Thread).where(Thread.id == thread_id).options(selectinload(Thread.messages))
    thread = session.exec(statement).first()

    if not thread or thread.user_id != current_user.id:
        raise NotFoundError(resource="ä¼šè¯")

    # å¦‚æœæ˜¯AIåŠ©æ‰‹çº¿ç¨‹ï¼ˆå¤æ‚æ¨¡å¼ï¼‰ï¼ŒåŠ è½½TaskSessionå’ŒSubTask
    if thread.agent_type == "ai" and thread.task_session_id:
        task_session = session.get(TaskSession, thread.task_session_id)
        if task_session:
            # åŠ è½½SubTasks
            statement = select(SubTask).where(SubTask.task_session_id == task_session.session_id)
            sub_tasks = session.exec(statement).all()

            # æ„å»ºå“åº”æ•°æ®ï¼ˆå­—å…¸å½¢å¼ï¼‰- æ˜ç¡®åŒ…å« agent_type å­—æ®µå’Œ messages
            return {
                "id": thread.id,
                "title": thread.title,
                "agent_id": thread.agent_id,
                "agent_type": thread.agent_type,
                "user_id": thread.user_id,
                "task_session_id": thread.task_session_id,
                "created_at": thread.created_at.isoformat() if thread.created_at else None,
                "updated_at": thread.updated_at.isoformat() if thread.updated_at else None,
                "messages": [
                    {
                        "id": msg.id,
                        "role": msg.role,
                        "content": msg.content,
                        "timestamp": msg.timestamp.isoformat() if msg.timestamp else None
                    }
                    for msg in thread.messages
                ],
                "task_session": {
                    "session_id": task_session.session_id,
                    "user_query": task_session.user_query,
                    "final_response": task_session.final_response,
                    "status": task_session.status,
                    "sub_tasks": [
                        {
                            "id": st.id,
                            "task_session_id": st.task_session_id,
                            "expert_type": st.expert_type,
                            "task_description": st.task_description,
                            "status": st.status,
                            "output": st.output,
                            "error": st.error,
                            "artifacts": st.artifacts,
                            "duration_ms": st.duration_ms,
                            "created_at": st.created_at.isoformat() if st.created_at else None
                        }
                        for st in sub_tasks
                    ]
                }
            }

    # å¯¹äºéAIçº¿ç¨‹ï¼Œæ‰‹åŠ¨æ„å»ºå“åº”ä»¥ç¡®ä¿ messages è¢«åºåˆ—åŒ–
    return {
        "id": thread.id,
        "title": thread.title,
        "agent_id": thread.agent_id,
        "agent_type": thread.agent_type,
        "user_id": thread.user_id,
        "task_session_id": thread.task_session_id,
        "created_at": thread.created_at.isoformat() if thread.created_at else None,
        "updated_at": thread.updated_at.isoformat() if thread.updated_at else None,
        "messages": [
            {
                "id": msg.id,
                "role": msg.role,
                "content": msg.content,
                "timestamp": msg.timestamp.isoformat() if msg.timestamp else None
            }
            for msg in thread.messages
        ]
    }

# åˆ é™¤çº¿ç¨‹ (Filtered by User)
@app.delete("/api/threads/{thread_id}")
async def delete_thread(thread_id: str, session: Session = Depends(get_session), current_user: User = Depends(get_current_user)):
    thread = session.get(Thread, thread_id)
    if not thread or thread.user_id != current_user.id:
        raise NotFoundError(resource="ä¼šè¯")
    session.delete(thread)
    session.commit()
    return {"ok": True}

# ============================================================================
# ç»Ÿä¸€èŠå¤©ç«¯ç‚¹ï¼ˆç®€å•æ¨¡å¼ + å¤æ‚æ¨¡å¼ï¼‰
# ============================================================================

@app.post("/api/chat")
async def chat_endpoint(request: ChatRequest, session: Session = Depends(get_session), current_user: User = Depends(get_current_user)):
    # 1. ç¡®å®š Thread ID
    thread_id = request.conversationId
    thread = None

    if thread_id:
        thread = session.get(Thread, thread_id)
        if thread and thread.user_id != current_user.id:
             raise AuthorizationError("æ²¡æœ‰æƒé™è®¿é—®æ­¤ä¼šè¯")

    if not thread:
        # å¦‚æœæ²¡æœ‰IDæˆ–æ‰¾ä¸åˆ°ï¼Œåˆ›å»ºæ–°çº¿ç¨‹
        # å¦‚æœå‰ç«¯æä¾›äº†conversationIdï¼ˆå³ä½¿æ˜¯æ–°çº¿ç¨‹ï¼‰ï¼Œç›´æ¥ä½¿ç”¨å‰ç«¯çš„IDï¼ˆå¹‚ç­‰æ€§ï¼‰
        # åªæœ‰å½“conversationIdä¸ºç©ºæ—¶ï¼Œæ‰ç”Ÿæˆæ–°çš„UUID
        if not thread_id:
            thread_id = str(uuid.uuid4())

        # å…œåº•é€»è¾‘ï¼šå¦‚æœ agentId ä¸º Noneã€null æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œå¼ºåˆ¶èµ‹å€¼ä¸ºç³»ç»Ÿé»˜è®¤åŠ©æ‰‹
        if not request.agentId or request.agentId.strip() == "":
            frontend_agent_id = SYSTEM_AGENT_DEFAULT_CHAT
        else:
            # è§„èŒƒåŒ–æ™ºèƒ½ä½“ IDï¼ˆå…¼å®¹æ—§ IDï¼‰
            frontend_agent_id = normalize_agent_id(request.agentId)

        # ğŸ‘ˆ é‡è¦ï¼šsys-task-orchestrator æ˜¯å†…éƒ¨å®ç°ï¼Œä¸åº”åœ¨ URL ä¸­æš´éœ²
        # å¦‚æœå‰ç«¯ä¼ äº† orchestrator IDï¼Œå°†å…¶è§†ä¸ºé»˜è®¤åŠ©æ‰‹ï¼ˆç”±åç«¯ Router å†³å®šå®é™…æ¨¡å¼ï¼‰
        if frontend_agent_id == SYSTEM_AGENT_ORCHESTRATOR:
            frontend_agent_id = SYSTEM_AGENT_DEFAULT_CHAT

        # æ ¹æ® agentId ç¡®å®š agent_type
        # å°è¯•ä½œä¸ºè‡ªå®šä¹‰æ™ºèƒ½ä½“UUIDåŠ è½½
        custom_agent_check = session.get(CustomAgent, frontend_agent_id)
        if custom_agent_check and custom_agent_check.user_id == current_user.id:
            agent_type = "custom"
            # è‡ªå®šä¹‰æ™ºèƒ½ä½“ä¿æŒå…¶åŸå§‹ ID
            final_agent_id = frontend_agent_id
        else:
            # ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹
            agent_type = "default"
            # å§‹ç»ˆä½¿ç”¨ sys-default-chat ä½œä¸ºç³»ç»ŸåŠ©æ‰‹çš„ ID
            final_agent_id = SYSTEM_AGENT_DEFAULT_CHAT

        # åˆå§‹ thread_mode ä¸º simpleï¼ŒRouter ä¼šåœ¨å¤„ç†æ—¶æ›´æ–°å®ƒ
        thread = Thread(
            id=thread_id,
            title=request.message[:30] + "..." if len(request.message) > 30 else request.message,
            agent_id=final_agent_id,  # ğŸ‘ˆ ç³»ç»ŸåŠ©æ‰‹å§‹ç»ˆä½¿ç”¨ sys-default-chat
            agent_type=agent_type,  # æ­£ç¡®è®¾ç½® agent_type
            thread_mode="simple",  # åˆå§‹ä¸º simpleï¼Œåç»­ç”± Router æ›´æ–°
            user_id=current_user.id, # ç»‘å®šå½“å‰ç”¨æˆ·
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        session.add(thread)
        session.commit()
        session.refresh(thread)

    # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
    user_msg_db = Message(
        thread_id=thread_id,
        role="user",
        content=request.message,
        timestamp=datetime.now()
    )
    session.add(user_msg_db)
    session.commit()

    # 3. å‡†å¤‡ LangGraph ä¸Šä¸‹æ–‡
    statement = select(Message).where(Message.thread_id == thread_id).order_by(Message.timestamp)
    db_messages = session.exec(statement).all()

    langchain_messages = []
    for msg in db_messages:
        if msg.role == "user":
            langchain_messages.append(HumanMessage(content=msg.content))
        elif msg.role == "assistant":
            langchain_messages.append(AIMessage(content=msg.content))

    # æ„å»ºçŠ¶æ€

    # ğŸ‘ˆ æ–°æ¶æ„ï¼šæ‰€æœ‰å¯¹è¯éƒ½é€šè¿‡ sys-default-chat å…¥å£
    # å¤æ‚æ¨¡å¼ (Complex Mode) æ˜¯ Thread çš„å†…éƒ¨çŠ¶æ€ï¼Œä¸æ˜¯ç‹¬ç«‹çš„ Agent ID
    # Router ä¼šæ ¹æ®æŸ¥è¯¢å¤æ‚åº¦è‡ªåŠ¨å†³å®šæ˜¯ç®€å•æ¨¡å¼è¿˜æ˜¯å¤æ‚æ¨¡å¼

    # æ£€æŸ¥æ˜¯å¦æ˜¯è‡ªå®šä¹‰æ™ºèƒ½ä½“
    custom_agent = None

    # è§„èŒƒåŒ–æ™ºèƒ½ä½“ IDï¼ˆå…¼å®¹æ—§ IDï¼‰
    normalized_agent_id = normalize_agent_id(request.agentId)

    # ğŸ‘ˆ å°† orchestrator ID ä¹Ÿè§†ä¸ºé»˜è®¤åŠ©æ‰‹ï¼ˆä¸å†ä½œä¸º URL ä¸­çš„ç‹¬ç«‹æ¨¡å¼ï¼‰
    if normalized_agent_id == SYSTEM_AGENT_ORCHESTRATOR:
        normalized_agent_id = SYSTEM_AGENT_DEFAULT_CHAT

    # åˆ¤æ–­æ™ºèƒ½ä½“ç±»å‹ï¼š
    # 1. è‡ªå®šä¹‰æ™ºèƒ½ä½“UUID â†’ ç›´æ¥è°ƒç”¨ LLMï¼ˆä¸ç»è¿‡ LangGraphï¼‰
    # 2. sys-default-chat æˆ–é»˜è®¤æƒ…å†µ â†’ ç”± Router å†³å®šç®€å•/å¤æ‚æ¨¡å¼

    # ğŸ‘ˆ ä¿®å¤ï¼šä½¿ç”¨æ ‡å¿—ä½åŒºåˆ†ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹å’Œè‡ªå®šä¹‰æ™ºèƒ½ä½“
    is_system_default = False

    if normalized_agent_id == SYSTEM_AGENT_DEFAULT_CHAT:
        # ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹ï¼šç”± Router å†³å®šæ¨¡å¼
        # - ç®€å•æŸ¥è¯¢ -> ç›´æ¥è°ƒç”¨ LLM -> thread_mode='simple'
        # - å¤æ‚ä»»åŠ¡ -> LangGraph ä¸“å®¶åä½œ -> thread_mode='complex'
        is_system_default = True
        custom_agent = None  # ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹ä¸è®¾ç½® custom_agentï¼Œè®©å®ƒèµ° LangGraph
        print(f"[MAIN] ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹æ¨¡å¼ - å°†ä½¿ç”¨ LangGraph Router å†³å®šæ‰§è¡Œè·¯å¾„")
    else:
        # å°è¯•ä½œä¸ºè‡ªå®šä¹‰æ™ºèƒ½ä½“UUIDåŠ è½½
        custom_agent = session.get(CustomAgent, normalized_agent_id)

        if custom_agent and custom_agent.user_id == current_user.id:
            # æ›´æ–°ä½¿ç”¨æ¬¡æ•°
            custom_agent.conversation_count += 1
            session.add(custom_agent)
            session.commit()
            print(f"[MAIN] è‡ªå®šä¹‰æ™ºèƒ½ä½“æ¨¡å¼ - ç›´æ¥è°ƒç”¨ LLM: {custom_agent.name}")
        else:
            # æœªæ‰¾åˆ°è‡ªå®šä¹‰æ™ºèƒ½ä½“ï¼Œå›é€€åˆ°ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹
            is_system_default = True
            custom_agent = None
            print(f"[MAIN] æœªæ‰¾åˆ°è‡ªå®šä¹‰æ™ºèƒ½ä½“ï¼Œå›é€€åˆ°ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹æ¨¡å¼")

    # å¦‚æœæ˜¯è‡ªå®šä¹‰æ™ºèƒ½ä½“ï¼Œä½¿ç”¨ç›´æ¥ LLM è°ƒç”¨æ¨¡å¼ï¼ˆä¸ç»è¿‡ LangGraphï¼‰
    if custom_agent:
        # 4. æµå¼å“åº”å¤„ç†ï¼ˆè‡ªå®šä¹‰æ™ºèƒ½ä½“ç›´æ¥è°ƒç”¨ LLMï¼‰
        if request.stream:
            async def event_generator():
                full_response = ""
                try:
                    # ç¡®å®šæ¨¡å‹åç§°ï¼ˆå¸¦è‡ªåŠ¨ä¿®æ­£é€»è¾‘ï¼‰
                    model_name = custom_agent.model_id or os.getenv("MODEL_NAME", "deepseek-chat")
                    base_url = os.getenv("OPENAI_BASE_URL") or os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
                    
                    # è‡ªåŠ¨ä¿®æ­£ï¼šå¦‚æœä½¿ç”¨ DeepSeek API ä½† model_id æ˜¯ OpenAI æ¨¡å‹ï¼Œåˆ‡æ¢ä¸º deepseek-chat
                    if "deepseek.com" in base_url and model_name.startswith("gpt-"):
                        print(f"[CUSTOM AGENT] æ£€æµ‹åˆ°ä¸å…¼å®¹æ¨¡å‹ {model_name}ï¼Œè‡ªåŠ¨åˆ‡æ¢ä¸º deepseek-chat")
                        model_name = "deepseek-chat"

                    print(f"[CUSTOM AGENT] ä½¿ç”¨æ¨¡å‹: {model_name}")
                    print(f"[CUSTOM AGENT] ä½¿ç”¨ Base URL: {base_url}")
                    
                    # ä½¿ç”¨å·¥å‚å‡½æ•°è·å– LLM å®ä¾‹
                    llm = get_llm_instance(streaming=True, model=model_name, temperature=0.7)

                    # æ·»åŠ  System Prompt
                    messages_with_system = []
                    messages_with_system.append(("system", custom_agent.system_prompt))
                    messages_with_system.extend(langchain_messages)

                    async for chunk in llm.astream(messages_with_system):
                        content = chunk.content
                        if content:
                            full_response += content
                            yield f"data: {json.dumps({'content': content, 'conversationId': thread_id})}\n\n"

                except Exception as e:
                    import traceback
                    traceback.print_exc()
                    error_msg = json.dumps({"error": str(e)})
                    yield f"data: {error_msg}\n\n"

                # 5. ä¿å­˜ AI å›å¤åˆ°æ•°æ®åº“
                if full_response:
                    ai_msg_db = Message(
                        thread_id=thread_id,
                        role="assistant",
                        content=full_response,
                        timestamp=datetime.now()
                    )
                    from database import engine
                    with Session(engine) as inner_session:
                        inner_session.add(ai_msg_db)
                        # æ›´æ–°çº¿ç¨‹æ—¶é—´
                        thread = inner_session.get(Thread, thread_id)
                        if thread:
                            thread.updated_at = datetime.now()
                            inner_session.add(thread)
                        inner_session.commit()
                
                yield "data: [DONE]\n\n"
            
            return StreamingResponse(
                event_generator(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                    "X-Accel-Buffering": "no"
                }
            )
        else:
            # éæµå¼
            # ç¡®å®šæ¨¡å‹åç§°ï¼ˆå¸¦è‡ªåŠ¨ä¿®æ­£é€»è¾‘ï¼‰
            model_name = custom_agent.model_id or os.getenv("MODEL_NAME", "deepseek-chat")
            base_url = os.getenv("OPENAI_BASE_URL") or os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")

            # è‡ªåŠ¨ä¿®æ­£ï¼šå¦‚æœä½¿ç”¨ DeepSeek API ä½† model_id æ˜¯ OpenAI æ¨¡å‹ï¼Œåˆ‡æ¢ä¸º deepseek-chat
            if "deepseek.com" in base_url and model_name.startswith("gpt-"):
                model_name = "deepseek-chat"

            # ä½¿ç”¨å·¥å‚å‡½æ•°è·å– LLM å®ä¾‹
            llm = get_llm_instance(streaming=False, model=model_name, temperature=0.7)
            
            # æ·»åŠ  System Prompt
            messages_with_system = []
            messages_with_system.append(("system", custom_agent.system_prompt))
            messages_with_system.extend(langchain_messages)
            
            result = await llm.ainvoke(messages_with_system)
            full_response = result.content

            # ä¿å­˜ AI å›å¤
            ai_msg_db = Message(
                thread_id=thread_id,
                role="assistant",
                content=full_response,
                timestamp=datetime.now()
            )
            session.add(ai_msg_db)
            thread.updated_at = datetime.now()
            session.add(thread)
            session.commit()

            return {
                "role": "assistant",
                "content": full_response,
                "conversationId": thread_id
            }

    # ============================================================================
    # ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹æ¨¡å¼ï¼šé€šè¿‡ LangGraph (Router -> Planner -> Experts) å¤„ç†
    # ============================================================================
    # ğŸ‘ˆ æ³¨æ„ï¼šæ‰€æœ‰å¯¹è¯éƒ½é€šè¿‡ sys-default-chat å…¥å£
    # Router èŠ‚ç‚¹ä¼šå†³å®šæ˜¯ç®€å•æ¨¡å¼ (simple) è¿˜æ˜¯å¤æ‚æ¨¡å¼ (complex)
    # - simple: Router ç›´æ¥ç”Ÿæˆå›å¤ï¼Œä¸ç»è¿‡ Planner
    # - complex: ç»è¿‡ Planner æ‹†è§£ä»»åŠ¡ï¼Œå¤šä¸“å®¶åä½œæ‰§è¡Œ

    print(f"[MAIN] è¿›å…¥ç³»ç»Ÿé»˜è®¤åŠ©æ‰‹æ¨¡å¼ï¼Œä½¿ç”¨ LangGraph å¤„ç†")

    initial_state = {
        "messages": langchain_messages,
        "current_agent": "router",  # ğŸ‘ˆ ä» Router èŠ‚ç‚¹å¼€å§‹
        "task_list": [],
        "current_task_index": 0,
        "strategy": "",
        "expert_results": [],
        "final_response": "",
        "context": {},
        "router_decision": ""  # Router ä¼šå¡«å……æ­¤å­—æ®µ
    }

        # 4. æµå¼å“åº”å¤„ç†
    if request.stream:
        async def event_generator():
            nonlocal thread  # ğŸ‘ˆ å£°æ˜ thread æ˜¯å¤–å±‚å‡½æ•°çš„å˜é‡
            full_response = ""
            event_count = 0

            # ä¸ºæ¯ä¸ªä¸“å®¶ç»´æŠ¤ artifact åˆ—è¡¨ï¼ˆæ”¯æŒå¤šä¸ª artifact ç´¯ç§¯ï¼‰
            expert_artifacts = {}

            # æ”¶é›† task_list å’Œ expert_resultsï¼ˆç”¨äºæŒä¹…åŒ–ï¼‰
            collected_task_list = []
            collected_expert_results = []

            # è·Ÿè¸ªè·¯ç”±æ¨¡å¼ï¼ˆsimple/complexï¼‰
            router_mode = ""

            try:
                async for event in commander_graph.astream_events(
                    initial_state,
                    version="v2"
                ):
                    event_count += 1
                    kind = event["event"]
                    name = event.get("name", "")

                    # æ¯æ”¶åˆ°10ä¸ªäº‹ä»¶æ‰“å°ä¸€æ¬¡è¿›åº¦ï¼ˆè°ƒè¯•ç”¨ï¼‰
                    if event_count % 10 == 0:
                        print(f"[STREAM] å·²å¤„ç† {event_count} ä¸ªäº‹ä»¶ï¼Œå½“å‰: {kind} - {name}")

                    # ğŸ‘ˆ æ•è· Router èŠ‚ç‚¹æ‰§è¡Œç»“æŸï¼ˆè·å–è·¯ç”±å†³ç­–ï¼‰
                    if kind == "on_chain_end" and name == "router":
                        output_data = event["data"]["output"]
                        router_decision = output_data.get("router_decision", "")

                        if router_decision:
                            print(f"[STREAM] Router å†³ç­–: {router_decision}")
                            router_mode = router_decision  # è®°å½•è·¯ç”±æ¨¡å¼
                            # æ›´æ–° Thread çš„ thread_mode
                            thread.thread_mode = router_decision
                            session.add(thread)
                            session.commit()
                            # å‘å‰ç«¯å‘é€ routerDecision äº‹ä»¶
                            yield f"data: {json.dumps({'routerDecision': router_decision, 'conversationId': thread_id})}\n\n"

                    # ğŸ‘ˆ æ•è·è§„åˆ’èŠ‚ç‚¹æ‰§è¡Œç»“æŸï¼ˆæ”¶é›† task_listï¼‰
                    if kind == "on_chain_end" and name == "planner":
                        output_data = event["data"]["output"]
                        if "task_list" in output_data:
                            collected_task_list = output_data["task_list"]

                    # æ•è·è§„åˆ’èŠ‚ç‚¹æ‰§è¡Œç»“æŸï¼ˆè·å–ä»»åŠ¡è®¡åˆ’ï¼‰
                    if kind == "on_chain_end" and name == "planner":
                        output_data = event["data"]["output"]
                        print(f"[STREAM] Planner èŠ‚ç‚¹ç»“æŸï¼Œè¾“å‡ºé”®: {list(output_data.keys())}")

                        if "__task_plan" in output_data:
                            task_plan = output_data["__task_plan"]
                            print(f"[STREAM] å‘é€ taskPlan äº‹ä»¶: {task_plan.get('task_count', 0)} ä¸ªä»»åŠ¡")
                            # æ¨é€ä»»åŠ¡è®¡åˆ’äº‹ä»¶åˆ°å‰ç«¯
                            yield f"data: {json.dumps({'taskPlan': task_plan, 'conversationId': thread_id})}\n\n"

                    # æ•è· direct_reply èŠ‚ç‚¹æ‰§è¡Œç»“æŸï¼ˆSimple æ¨¡å¼æµå¼è¾“å‡ºå®Œæˆï¼‰
                    if kind == "on_chain_end" and name == "direct_reply":
                        # direct_reply èŠ‚ç‚¹çš„æµå¼è¾“å‡ºå·²ç»é€šè¿‡ on_chat_model_stream å¤„ç†å®Œæ¯•
                        # è¿™é‡Œåªéœ€è¦å‘é€æœ€ç»ˆæ ‡è®°
                        yield f"data: {json.dumps({'content': '', 'conversationId': thread_id, 'isFinal': True})}\n\n"
                        print(f"[STREAM] Direct Reply èŠ‚ç‚¹å®Œæˆï¼ŒSimple æ¨¡å¼æµå¼è¾“å‡ºç»“æŸ")

                    # æ•è·èšåˆå™¨èŠ‚ç‚¹æ‰§è¡Œç»“æŸï¼ˆè·å–æœ€ç»ˆå“åº”ï¼‰
                    if kind == "on_chain_end" and name == "aggregator":
                        output_data = event["data"]["output"]

                        if "final_response" in output_data:
                            final_response = output_data["final_response"]
                            # æ¨é€æœ€ç»ˆå“åº”åˆ°å‰ç«¯
                            yield f"data: {json.dumps({'content': final_response, 'conversationId': thread_id, 'isFinal': True})}\n\n"

                    # æ•è·ä¸“å®¶åˆ†å‘å™¨èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œï¼ˆæ¨é€ä»»åŠ¡å¼€å§‹ä¿¡æ¯ï¼‰
                    if kind == "on_chain_start" and name == "expert_dispatcher":
                        # ä»äº‹ä»¶è¾“å…¥ä¸­è·å– state
                        input_data = event.get("data", {}).get("input", {})
                        task_list = input_data.get("task_list", [])
                        current_task_index = input_data.get("current_task_index", 0)

                        if task_list and current_task_index < len(task_list):
                            current_task = task_list[current_task_index]
                            task_start_info = {
                                "task_index": current_task_index + 1,
                                "total_tasks": len(task_list),
                                "expert_type": current_task.get("expert_type", ""),
                                "description": current_task.get("description", "")
                            }
                            yield f"data: {json.dumps({'taskStart': task_start_info, 'conversationId': thread_id})}\n\n"

                    # æ•è·ä¸“å®¶åˆ†å‘å™¨èŠ‚ç‚¹æ‰§è¡Œï¼ˆé€šè¿‡ __expert_info å­—æ®µä¼ é€’ä¸“å®¶ä¿¡æ¯ï¼‰
                    if kind == "on_chain_end" and name == "expert_dispatcher":
                        output_data = event["data"]["output"]

                        # ç§»é™¤é‡å¤çš„ __task_start_info å¤„ç†ï¼ˆç°åœ¨åœ¨ on_chain_start æ—¶å¤„ç†ï¼‰
                        if "__expert_info" in output_data:
                            expert_info = output_data["__expert_info"]
                            expert_name = expert_info.get("expert_type")
                            expert_status = expert_info.get("status", "completed")
                            duration_ms = expert_info.get("duration_ms", 0)
                            output_result = expert_info.get("output", "")
                            expert_error = expert_info.get("error")

                            # åˆå§‹åŒ–è¯¥ä¸“å®¶çš„ artifact åˆ—è¡¨
                            if expert_name not in expert_artifacts:
                                expert_artifacts[expert_name] = []

                            # æ¨é€ä¸“å®¶æ¿€æ´»äº‹ä»¶ï¼ˆåœ¨ä¸“å®¶å¼€å§‹æ‰§è¡Œæ—¶ï¼‰
                            yield f"data: {json.dumps({'activeExpert': expert_name, 'conversationId': thread_id})}\n\n"

                            # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº† artifact
                            if "artifact" in output_data:
                                artifact = output_data["artifact"]
                                # æ·»åŠ åˆ°è¯¥ä¸“å®¶çš„ artifact åˆ—è¡¨
                                expert_artifacts[expert_name].append(artifact)

                                # æ¨é€ artifact_update äº‹ä»¶ï¼ˆåŒ…å«æ‰€æœ‰ artifactsï¼‰
                                yield f"data: {json.dumps({'artifact': artifact, 'conversationId': thread_id, 'allArtifacts': expert_artifacts[expert_name], 'activeExpert': expert_name})}\n\n"

                            # æ¨é€ä¸“å®¶å®Œæˆäº‹ä»¶ï¼ˆåŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
                            yield f"data: {json.dumps({
                                'expertCompleted': expert_name,
                                'description': expert_info.get('description', ''),
                                'conversationId': thread_id,
                                'duration_ms': duration_ms,
                                'status': expert_status,
                                'output': output_result,
                                'error': expert_error,
                                'allArtifacts': expert_artifacts.get(expert_name, [])
                            })}\n\n"

                    # æ•è· LLM æµå¼è¾“å‡º
                    # - Simple æ¨¡å¼ï¼šå…è®¸ direct_reply èŠ‚ç‚¹çš„æµå¼è¾“å‡º
                    # - Complex æ¨¡å¼ï¼šæ’é™¤å†…éƒ¨èŠ‚ç‚¹ï¼ˆRouterã€Planner/Commanderã€Expertï¼‰ï¼Œåªä¿ç•™ Aggregator çš„è¾“å‡º
                    # - Router å†³ç­–æœªçŸ¥ï¼šè·³è¿‡æ‰€æœ‰å†…éƒ¨èŠ‚ç‚¹çš„è¾“å‡ºï¼ˆé¿å…æå‰è¿‡æ»¤ï¼‰
                    if kind == "on_chat_model_stream":
                        event_tags = event.get("tags", [])
                        content = event["data"]["chunk"].content

                        # æ‰“å°è°ƒè¯•ä¿¡æ¯
                        print(f"[STREAM DEBUG] tags={event_tags}, name={name}, content[:30]={content[:30] if content else 'None'}")

                        # ä½¿ç”¨ç»Ÿä¸€çš„è¿‡æ»¤å‡½æ•°åˆ¤æ–­æ˜¯å¦åº”è¾“å‡º
                        should_yield, reason = should_stream_event(event_tags, router_mode, name)
                        if not should_yield:
                            print(f"[STREAM] {reason}")
                            continue

                        # é¢å¤–å®‰å…¨æ£€æŸ¥ï¼šè¿‡æ»¤æ‰ä»»åŠ¡è®¡åˆ’ JSON
                        if is_task_plan_content(content):
                            print(f"[STREAM] è·³è¿‡ä»»åŠ¡è®¡åˆ’JSONå†…å®¹: {content[:200]}...")
                            continue

                        if content:
                            print(f"[STREAM] é€šè¿‡è¿‡æ»¤çš„æµå¼è¾“å‡º: content[:50]={content[:50]}")
                            full_response += content
                            yield f"data: {json.dumps({'content': content, 'conversationId': thread_id})}\n\n"

                print(f"[STREAM] æµå¼å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {event_count} ä¸ªäº‹ä»¶")

            except Exception as e:
                print(f"[STREAM] é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                error_msg = json.dumps({"error": str(e)})
                yield f"data: {error_msg}\n\n"

            # 5. æµå¼ç»“æŸåï¼Œä¿å­˜ AI å›å¤å’Œ Artifacts åˆ°æ•°æ®åº“
            if full_response:
                ai_msg_db = Message(
                    thread_id=thread_id,
                    role="assistant",
                    content=full_response,
                    timestamp=datetime.now()
                )
                from database import engine
                with Session(engine) as inner_session:
                    inner_session.add(ai_msg_db)

                    # æ›´æ–°çº¿ç¨‹æ—¶é—´
                    thread = inner_session.get(Thread, thread_id)
                    if thread:
                        thread.updated_at = datetime.now()

                    # å¦‚æœæ˜¯å¤æ‚æ¨¡å¼ï¼Œä¿å­˜ TaskSession å’Œ SubTask
                    if thread.thread_mode == "complex" and collected_task_list:
                        print(f"[STREAM] ä¿å­˜å¤æ‚æ¨¡å¼æ•°æ®: {len(collected_task_list)} ä¸ªä»»åŠ¡")

                        # åˆ›å»º TaskSession
                        now = datetime.now()
                        task_session = TaskSession(
                            session_id=str(uuid.uuid4()),
                            thread_id=thread_id,
                            user_query=request.message,
                            status="completed",
                            final_response=full_response,
                            created_at=now,
                            updated_at=now,
                            completed_at=now
                        )
                        inner_session.add(task_session)
                        inner_session.flush()  # ç¡®ä¿ task_session æœ‰ ID

                        # æ›´æ–° thread çš„ task_session_id å’Œ agent_type
                        thread.task_session_id = task_session.session_id
                        thread.agent_type = "ai"
                        inner_session.add(thread)

                        # ä¿å­˜æ¯ä¸ª SubTask
                        for task in collected_task_list:
                            expert_type = task.get("expert_type", "")
                            # è·å–è¯¥ä¸“å®¶çš„ artifacts
                            artifacts_for_expert = expert_artifacts.get(expert_type, [])

                            subtask = SubTask(
                                id=task.get("id", str(uuid.uuid4())),
                                expert_type=expert_type,
                                task_description=task.get("description", ""),
                                input_data=task.get("input_data", {}),
                                status=task.get("status", "completed"),
                                output_result={"content": task.get("output_result", "")},
                                artifacts=artifacts_for_expert,  # ğŸ‘ˆ ä¿å­˜ artifacts
                                task_session_id=task_session.session_id,
                                started_at=task.get("started_at"),
                                completed_at=task.get("completed_at"),
                                created_at=task.get("created_at"),
                                updated_at=task.get("updated_at"),
                            )
                            inner_session.add(subtask)
                            print(f"[STREAM] ä¿å­˜ SubTask: {expert_type}, artifacts: {len(artifacts_for_expert)}")

                    inner_session.commit()

            yield "data: [DONE]\n\n"

        return StreamingResponse(
            event_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
    else:
        # éæµå¼
        result = await commander_graph.ainvoke(initial_state)
        last_message = result["messages"][-1]

        # ğŸ‘ˆ è·å– Router å†³ç­–å¹¶æ›´æ–° thread_mode
        router_decision = result.get("router_decision", "simple")
        thread.thread_mode = router_decision

        # å¦‚æœæ˜¯å¤æ‚æ¨¡å¼ï¼Œè®¾ç½® agent_type ä¸º "ai"
        if router_decision == "complex":
            thread.agent_type = "ai"

            # åˆ›å»º TaskSession
            task_session = TaskSession(
                session_id=str(uuid.uuid4()),
                thread_id=thread_id,
                user_query=request.message,
                status="completed",
                final_response=last_message.content,
                created_at=datetime.now(),
                updated_at=datetime.now(),
                completed_at=datetime.now()
            )
            session.add(task_session)
            session.flush()  # ç¡®ä¿ task_session æœ‰ ID

            # æ›´æ–° thread çš„ task_session_id
            thread.task_session_id = task_session.session_id

            # ä¿å­˜ SubTaskï¼ˆåŒ…æ‹¬ artifactsï¼‰
            for subtask in result["task_list"]:
                # æ£€æŸ¥æ˜¯å¦æœ‰ artifact å­—æ®µ
                artifacts = subtask.get("artifact")
                if artifacts:
                    # å°†å•ä¸ª artifact è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
                    artifacts = [artifacts] if isinstance(artifacts, dict) else artifacts

                db_subtask = SubTask(
                    id=subtask["id"],
                    expert_type=subtask["expert_type"],
                    task_description=subtask["description"],
                    input_data=subtask["input_data"],
                    status=subtask["status"],
                    output_result=subtask["output_result"],
                    artifacts=artifacts,
                    started_at=subtask.get("started_at"),
                    completed_at=subtask.get("completed_at"),
                    created_at=subtask.get("created_at"),
                    updated_at=subtask.get("updated_at"),
                    task_session_id=task_session.session_id
                )
                session.add(db_subtask)

        # ä¿å­˜ AI å›å¤
        ai_msg_db = Message(
            thread_id=thread_id,
            role="assistant",
            content=last_message.content,
            timestamp=datetime.now()
        )
        session.add(ai_msg_db)
        thread.updated_at = datetime.now()
        session.add(thread)
        session.commit()

        return {
            "role": "assistant",
            "content": last_message.content,
            "conversationId": thread_id,
            "threadMode": router_decision  # ğŸ‘ˆ è¿”å› thread_mode ç»™å‰ç«¯
        }


# ============================================================================
# åŒæ¨¡è·¯ç”±ï¼šAuto æ¨¡å¼ï¼ˆå®Œæ•´å·¥ä½œæµï¼‰vs Direct æ¨¡å¼ï¼ˆå•ä¸“å®¶æ‰§è¡Œï¼‰
# ============================================================================

@app.post("/api/v1/chat/invoke")
async def chat_invoke_endpoint(
    request: ChatInvokeRequest,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    åŒæ¨¡è·¯ç”±ç«¯ç‚¹ï¼šæ”¯æŒ Auto å’Œ Direct ä¸¤ç§æ‰§è¡Œæ¨¡å¼

    Auto æ¨¡å¼ï¼šå®Œæ•´çš„å¤šä¸“å®¶åä½œæµç¨‹ï¼ˆcommander_graphï¼‰
    - æŒ‡æŒ¥å®˜æ‹†è§£ä»»åŠ¡
    - å¤šä¸“å®¶é¡ºåºæ‰§è¡Œ
    - ç»“æœèšåˆ

    Direct æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨å•ä¸ªä¸“å®¶
    - è·³è¿‡æŒ‡æŒ¥å®˜å’Œèšåˆå™¨
    - ç›´æ¥æ‰§è¡ŒæŒ‡å®šä¸“å®¶
    - é€‚ç”¨äºç®€å•ä»»åŠ¡

    ä¸¤ç§æ¨¡å¼éƒ½ä¼šï¼š
    - ä¿å­˜ç»“æœåˆ° TaskSession æ•°æ®åº“
    - ç”Ÿæˆ thread_id ç”¨äº LangSmith è¿½è¸ª
    """
    print(f"[INVOKE] æ¨¡å¼: {request.mode}, Agent: {request.agent_id}")

    # 1. æ¨¡å¼éªŒè¯
    if request.mode not in ["auto", "direct"]:
        raise ValidationError(f"æ— æ•ˆçš„æ‰§è¡Œæ¨¡å¼: {request.mode}ï¼Œå¿…é¡»æ˜¯ 'auto' æˆ– 'direct'")

    # 2. Direct æ¨¡å¼éœ€è¦ agent_id
    if request.mode == "direct" and not request.agent_id:
        raise ValidationError("Direct æ¨¡å¼éœ€è¦æŒ‡å®š agent_id")

    # 3. éªŒè¯ agent_id æ˜¯å¦åœ¨ EXPERT_FUNCTIONS ä¸­
    if request.mode == "direct":
        if request.agent_id not in EXPERT_FUNCTIONS:
            raise ValidationError(f"æœªçŸ¥çš„ä¸“å®¶ç±»å‹: {request.agent_id}ï¼Œå¯ç”¨ä¸“å®¶: {list(EXPERT_FUNCTIONS.keys())}")

    # 4. åˆ›å»º TaskSession è®°å½•ï¼ˆç”¨äºæ•°æ®åº“æŒä¹…åŒ–ï¼‰
    thread_id = request.thread_id or str(uuid.uuid4())
    task_session = TaskSession(
        session_id=thread_id,
        user_query=request.message,
        status="running",
        created_at=datetime.now(),
        updated_at=datetime.now()
    )
    session.add(task_session)
    session.commit()
    session.refresh(task_session)

    # 5. å¯¼å…¥æ¶ˆæ¯ç±»å‹
    from langchain_core.messages import HumanMessage, AIMessage

    # ä½¿ç”¨å·¥å‚å‡½æ•°è·å– LLM å®ä¾‹
    llm = get_llm_instance(streaming=True, temperature=0.7)

    # 6. æ ¹æ®æ¨¡å¼æ‰§è¡Œ
    try:
        if request.mode == "auto":
            # ========================================================
            # Auto æ¨¡å¼ï¼šå®Œæ•´çš„å¤šä¸“å®¶åä½œæµç¨‹
            # ========================================================
            print("[AUTO MODE] å¯åŠ¨å®Œæ•´å·¥ä½œæµ")

            # æ„å»ºåˆå§‹çŠ¶æ€
            initial_state = {
                "messages": [HumanMessage(content=request.message)],
                "task_list": [],
                "current_task_index": 0,
                "strategy": "",
                "expert_results": [],
                "final_response": ""
            }

            # æ‰§è¡ŒæŒ‡æŒ¥å®˜å·¥ä½œæµ
            final_state = await commander_graph.ainvoke(
                initial_state,
                config={"configurable": {"thread_id": thread_id}}
            )

            # ä¿å­˜ SubTask åˆ°æ•°æ®åº“
            for subtask in final_state["task_list"]:
                # task_list ç°åœ¨æ˜¯å­—å…¸åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨å­—å…¸å­—æ®µ
                # æ£€æŸ¥æ˜¯å¦æœ‰ artifact å­—æ®µ
                artifacts = subtask.get("artifact")
                if artifacts:
                    # å°†å•ä¸ª artifact è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
                    artifacts = [artifacts] if isinstance(artifacts, dict) else artifacts

                db_subtask = SubTask(
                    id=subtask["id"],
                    expert_type=subtask["expert_type"],
                    task_description=subtask["description"],
                    input_data=subtask["input_data"],
                    status=subtask["status"],
                    output_result=subtask["output_result"],
                    artifacts=artifacts,  # ğŸ‘ˆ ä¿å­˜ artifacts
                    started_at=subtask.get("started_at"),
                    completed_at=subtask.get("completed_at"),
                    created_at=subtask["created_at"],
                    updated_at=subtask["updated_at"],
                    task_session_id=task_session.session_id
                )
                session.add(db_subtask)

            # æ›´æ–° TaskSession
            task_session.final_response = final_state["final_response"]
            task_session.status = "completed"
            task_session.completed_at = datetime.now()
            task_session.updated_at = datetime.now()

            session.commit()

            print(f"[AUTO MODE] å®Œæˆï¼Œæ‰§è¡Œäº† {len(final_state['expert_results'])} ä¸ªä¸“å®¶")

            return {
                "mode": "auto",
                "thread_id": thread_id,
                "session_id": task_session.session_id,
                "user_query": request.message,
                "strategy": final_state["strategy"],
                "final_response": final_state["final_response"],
                "expert_results": final_state["expert_results"],
                "sub_tasks_count": len(final_state["task_list"]),
                "status": "completed"
            }

        else:
            # ========================================================
            # Direct æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨å•ä¸ªä¸“å®¶
            # ========================================================
            print(f"[DIRECT MODE] ç›´æ¥è°ƒç”¨ä¸“å®¶: {request.agent_id}")

            # æ„å»ºçŠ¶æ€ï¼ˆæ¨¡æ‹Ÿå•ä¸ªä»»åŠ¡ï¼‰
            subtask_dict = {
                "id": str(uuid.uuid4()),
                "expert_type": request.agent_id,
                "description": request.message,
                "input_data": {},
                "status": "pending",
                "created_at": datetime.now(),
                "updated_at": datetime.now()
            }

            initial_state = {
                "messages": [HumanMessage(content=request.message)],
                "task_list": [subtask_dict],
                "current_task_index": 0,
                "strategy": f"ç›´æ¥æ¨¡å¼: {request.agent_id} ä¸“å®¶",
                "expert_results": [],
                "final_response": ""
            }

            # è°ƒç”¨åŸå­åŒ–ä¸“å®¶å‡½æ•°
            expert_func = EXPERT_FUNCTIONS[request.agent_id]
            result = await expert_func(initial_state, llm)

            # ä¿å­˜ SubTask åˆ°æ•°æ®åº“
            db_subtask = SubTask(
                id=subtask_dict["id"],
                expert_type=subtask_dict["expert_type"],
                task_description=subtask_dict["description"],
                input_data=subtask_dict["input_data"],
                status=result.get("status", "completed"),
                output_result={"content": result.get("output_result", "")},
                started_at=result.get("started_at"),
                completed_at=result.get("completed_at"),
                created_at=subtask_dict["created_at"],
                updated_at=subtask_dict["updated_at"],
                task_session_id=task_session.session_id
            )
            session.add(db_subtask)

            # æ„å»ºä¸“å®¶ç»“æœ
            expert_result = {
                "task_id": subtask_dict["id"],
                "expert_type": request.agent_id,
                "description": request.message,
                "output": result.get("output_result", ""),
                "status": result.get("status", "unknown"),
                "started_at": result.get("started_at"),
                "completed_at": result.get("completed_at"),
                "duration_ms": result.get("duration_ms", 0)
            }

            # æ›´æ–° TaskSession
            task_session.final_response = result.get("output_result", "")
            task_session.status = "completed"
            task_session.completed_at = datetime.now()
            task_session.updated_at = datetime.now()

            session.commit()

            print(f"[DIRECT MODE] å®Œæˆï¼Œä¸“å®¶: {request.agent_id}")

            return {
                "mode": "direct",
                "thread_id": thread_id,
                "session_id": task_session.session_id,
                "user_query": request.message,
                "expert_type": request.agent_id,
                "final_response": result.get("output_result", ""),
                "expert_results": [expert_result],
                "sub_tasks_count": 1,
                "status": "completed"
            }

    except Exception as e:
        # é”™è¯¯å¤„ç†ï¼šæ›´æ–° TaskSession çŠ¶æ€
        task_session.status = "failed"
        task_session.final_response = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
        task_session.updated_at = datetime.now()
        session.commit()

        print(f"[ERROR] æ‰§è¡Œå¤±è´¥: {e}")
        raise AppError(message=f"æ‰§è¡Œå¤±è´¥: {str(e)}", original_error=e)


if __name__ == "__main__":
    # Local dev defaults to 3002, Docker uses PORT env var (e.g. 3000)
    port = int(os.getenv("PORT", 3002))
    print(f"[STARTUP] Starting Uvicorn server on port {port}...")
    print(f"[STARTUP] Host: 0.0.0.0, Port: {port}")

    try:
        # å¯åŠ¨uvicornï¼ˆç¦ç”¨reloadé¿å…Windowsæ–‡ä»¶ç›‘æ§é—®é¢˜ï¼‰
        uvicorn.run("main:app", host="0.0.0.0", port=port, reload=False, log_level="info")
    except Exception as e:
        print(f"[STARTUP ERROR] {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        raise
