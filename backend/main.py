"""
XPouch AI Backend - å…¥å£æ–‡ä»¶

é‡æ„åï¼šä»…è´Ÿè´£ App åˆå§‹åŒ–ã€ä¸­é—´ä»¶ã€æ³¨å†Œè·¯ç”±
ä¸šåŠ¡é€»è¾‘å·²æ‹†åˆ†åˆ° routers/ ç›®å½•

ğŸ”¥ å¯åŠ¨æ–¹å¼ï¼š
- Windows: python run.py (å·²å¤„ç†äº‹ä»¶å¾ªç¯å…¼å®¹æ€§)
- Linux/Mac: python main.py æˆ– uvicorn main:app
"""
import pathlib
from dotenv import load_dotenv
import os

# Load .env from the same directory as this file
env_path = pathlib.Path(__file__).parent / ".env"
load_dotenv(dotenv_path=env_path, override=True)

from fastapi import FastAPI, Request, Response, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
from typing import List, Optional
import json
import uvicorn
from datetime import datetime
from uuid import uuid4

from sqlmodel import Session, select
from contextlib import asynccontextmanager

# å†…éƒ¨æ¨¡å—å¯¼å…¥
from database import create_db_and_tables, engine, get_session
from config import init_langchain_tracing, validate_config
from models import User, TaskSession, SubTask, SystemExpert
from constants import SYSTEM_AGENT_DEFAULT_CHAT
from agents.graph import commander_graph
from agents.nodes.generic import generic_worker_node
from agents.services.expert_manager import get_expert_config_cached
from utils.llm_factory import get_llm_instance
from utils.exceptions import (
    AppError, ValidationError, NotFoundError,
    handle_error
)

# è·¯ç”±å¯¼å…¥
from auth import router as auth_router
from api.admin import router as admin_router
from routers import chat, agents, system


# ============================================================================
# Lifespan - åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
# ============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    # åˆå§‹åŒ– LangSmith è¿½è¸ª
    init_langchain_tracing()
    # éªŒè¯é…ç½®
    validate_config()
    # åˆ›å»ºæ•°æ®åº“è¡¨
    create_db_and_tables()

    # ğŸ”¥ğŸ”¥ğŸ”¥ v3.5: åˆå§‹åŒ– LangGraph Checkpointer è¡¨ (HITL æ”¯æŒ)
    from utils.db import init_checkpointer_tables
    try:
        await init_checkpointer_tables()
        print("[Lifespan] Checkpointer tables initialized for HITL")
    except Exception as e:
        print(f"[Lifespan WARN] Failed to init checkpointer tables: {e}")
        # éè‡´å‘½é”™è¯¯ï¼Œç»§ç»­å¯åŠ¨

    # åˆå§‹åŒ–ç³»ç»Ÿä¸“å®¶æ•°æ®
    from expert_config import EXPERT_DEFAULTS

    with Session(engine) as session:
        existing_experts = session.exec(select(SystemExpert)).all()
        existing_keys = {e.expert_key for e in existing_experts}

        if not existing_experts:
            print("[Lifespan] No experts found, initializing default experts...")
            for expert_config in EXPERT_DEFAULTS:
                expert = SystemExpert(**expert_config)
                session.add(expert)
            session.commit()
            print(f"[Lifespan] Initialized {len(EXPERT_DEFAULTS)} experts")
        else:
            print(f"[Lifespan] Found {len(existing_experts)} experts in database")

    # æ¸…ç©ºä¸“å®¶ç¼“å­˜ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„å…œåº•æœºåˆ¶é‡æ–°åŠ è½½
    from agents.services.expert_manager import force_refresh_all
    force_refresh_all()
    print("[Lifespan] Expert cache cleared for fresh start")

    print("[Lifespan] Startup complete, yielding control to Uvicorn...")
    yield
    print("[Lifespan] Shutdown started...")
    
    # ğŸ”¥ å…³é—­è¿æ¥æ± 
    from utils.db import close_connection_pool
    try:
        await close_connection_pool()
        print("[Lifespan] Connection pool closed")
    except Exception as e:
        print(f"[Lifespan WARN] Failed to close connection pool: {e}")


# ============================================================================
# FastAPI åº”ç”¨å®ä¾‹
# ============================================================================

app = FastAPI(
    title="XPouch AI Backend",
    description="Python + SQLModel + LangGraph backend",
    version="2.0.0",
    lifespan=lifespan
)

# æ³¨å†Œè·¯ç”±
app.include_router(auth_router)
app.include_router(admin_router)
app.include_router(chat.router)
app.include_router(agents.router)
app.include_router(system.router)


# ============================================================================
# ä¸­é—´ä»¶
# ============================================================================

@app.middleware("http")
async def log_requests(request: Request, call_next) -> Response:
    """è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶"""
    print(f"[REQUEST] {request.method} {request.url.path}")
    try:
        response = await call_next(request)
        print(f"[RESPONSE] {response.status_code} {request.url.path}")
        return response
    except Exception as e:
        print(f"[ERROR] Exception in {request.method} {request.url.path}: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


@app.middleware("http")
async def add_security_headers(request: Request, call_next):
    """å®‰å…¨å¤´ä¿¡æ¯ä¸­é—´ä»¶"""
    response = await call_next(request)
    response.headers["X-Frame-Options"] = "DENY"
    response.headers["X-Content-Type-Options"] = "nosniff"
    response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
    csp_policy = "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline';"
    response.headers["Content-Security-Policy"] = csp_policy
    response.headers["Permissions-Policy"] = "camera=(), microphone=(), geolocation=()"
    return response


# ============================================================================
# CORS é…ç½®
# ============================================================================

def get_cors_origins():
    """ä»ç¯å¢ƒå˜é‡ CORS_ORIGINS è¯»å–å…è®¸çš„æ¥æº"""
    cors_origins_str = os.getenv("CORS_ORIGINS", "").strip()
    if cors_origins_str:
        origins = [origin.strip() for origin in cors_origins_str.split(",")]
        print(f"[CORS] å…è®¸çš„æ¥æº: {origins}")
        return origins
    
    environment = os.getenv("ENVIRONMENT", "development").lower()
    if environment == "production":
        print("[WARN] ç”Ÿäº§ç¯å¢ƒæœªè®¾ç½® CORS_ORIGINSï¼ŒCORS å°†æ‹’ç»æ‰€æœ‰è·¨åŸŸè¯·æ±‚")
        return []
    else:
        default_origin = "http://localhost:5173"
        print(f"[CORS] å¼€å‘ç¯å¢ƒé»˜è®¤å…è®¸æ¥æº: {default_origin}")
        return [default_origin]


app.add_middleware(
    CORSMiddleware,
    allow_origins=get_cors_origins(),
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["Authorization", "Content-Type", "X-User-ID", "X-Request-ID"],
)


# ============================================================================
# å¼‚å¸¸å¤„ç†å™¨
# ============================================================================

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError) -> JSONResponse:
    return JSONResponse(
        status_code=422,
        content={"detail": exc.errors(), "body": exc.body},
    )


@app.exception_handler(AppError)
async def app_error_handler(request: Request, exc: AppError) -> JSONResponse:
    """å¤„ç†è‡ªå®šä¹‰åº”ç”¨å¼‚å¸¸"""
    print(f"[APP ERROR] {exc.code}: {exc.message}")
    if exc.original_error:
        import traceback
        traceback.print_exception(type(exc.original_error), exc.original_error, exc.original_error.__traceback__)
    return JSONResponse(
        status_code=exc.status_code,
        content=exc.to_dict(),
    )


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException) -> JSONResponse:
    """å¤„ç† FastAPI HTTP å¼‚å¸¸"""
    print(f"[HTTP ERROR] {exc.status_code}: {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": {
                "code": "HTTP_ERROR",
                "message": str(exc.detail),
                "details": {}
            }
        },
    )


@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception) -> JSONResponse:
    """å¤„ç†æœªæ•è·çš„å¼‚å¸¸"""
    import traceback
    print("=" * 80)
    print("[UNHANDLED ERROR] Global exception caught:")
    print(f"[UNHANDLED ERROR] Request path: {request.url.path}")
    print(f"[UNHANDLED ERROR] Exception type: {type(exc).__name__}")
    print(f"[UNHANDLED ERROR] Exception message: {str(exc)}")
    print("[UNHANDLED ERROR] Stack trace:")
    traceback.print_exc()
    print("=" * 80)
    
    app_error = handle_error(exc)
    return JSONResponse(
        status_code=app_error.status_code,
        content=app_error.to_dict(),
    )


# ============================================================================
# åŒæ¨¡è·¯ç”±ï¼šä¿ç•™åœ¨ main.pyï¼ˆæ–°å¼€å‘çš„åŠŸèƒ½ï¼Œç¨³å®šåå†è¿ç§»ï¼‰
# ============================================================================

class ChatInvokeRequest(BaseModel):
    """åŒæ¨¡è·¯ç”±è¯·æ±‚æ¨¡å‹"""
    message: str
    mode: str = "auto"  # "auto" æˆ– "direct"
    agent_id: Optional[str] = None  # direct æ¨¡å¼ä¸‹å¿…å¡«
    thread_id: Optional[str] = None  # LangSmith çº¿ç¨‹ ID


from dependencies import get_current_user


@app.post("/api/v1/chat/invoke")
async def chat_invoke_endpoint(
    request: ChatInvokeRequest,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    åŒæ¨¡è·¯ç”±ç«¯ç‚¹ï¼šæ”¯æŒ Auto å’Œ Direct ä¸¤ç§æ‰§è¡Œæ¨¡å¼

    Auto æ¨¡å¼ï¼šå®Œæ•´çš„å¤šä¸“å®¶åä½œæµç¨‹ï¼ˆcommander_graphï¼‰
    Direct æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨å•ä¸ªä¸“å®¶
    """
    print(f"[INVOKE] æ¨¡å¼: {request.mode}, Agent: {request.agent_id}")

    # 1. æ¨¡å¼éªŒè¯
    if request.mode not in ["auto", "direct"]:
        raise ValidationError(f"æ— æ•ˆçš„æ‰§è¡Œæ¨¡å¼: {request.mode}ï¼Œå¿…é¡»æ˜¯ 'auto' æˆ– 'direct'")

    # 2. Direct æ¨¡å¼éœ€è¦ agent_id
    if request.mode == "direct" and not request.agent_id:
        raise ValidationError("Direct æ¨¡å¼éœ€è¦æŒ‡å®š agent_id")

    # 3. éªŒè¯ agent_id æ˜¯å¦å­˜åœ¨ï¼ˆä½¿ç”¨ expert_loaderï¼‰
    if request.mode == "direct":
        expert_config = get_expert_config_cached(request.agent_id)
        if not expert_config:
            raise ValidationError(f"æœªçŸ¥çš„ä¸“å®¶ç±»å‹: {request.agent_id}")

    # 4. åˆ›å»º TaskSession è®°å½•
    from langchain_core.messages import HumanMessage
    
    thread_id = request.thread_id or str(uuid4())
    task_session = TaskSession(
        session_id=thread_id,
        user_query=request.message,
        status="running",
        created_at=datetime.now(),
        updated_at=datetime.now()
    )
    session.add(task_session)
    session.commit()
    session.refresh(task_session)

    # ä½¿ç”¨å·¥å‚å‡½æ•°è·å– LLM å®ä¾‹
    llm = get_llm_instance(streaming=True, temperature=0.7)

    # 5. æ ¹æ®æ¨¡å¼æ‰§è¡Œ
    try:
        if request.mode == "auto":
            # Auto æ¨¡å¼ï¼šå®Œæ•´çš„å¤šä¸“å®¶åä½œæµç¨‹
            print("[AUTO MODE] å¯åŠ¨å®Œæ•´å·¥ä½œæµ")

            initial_state = {
                "messages": [HumanMessage(content=request.message)],
                "task_list": [],
                "current_task_index": 0,
                "strategy": "",
                "expert_results": [],
                "final_response": ""
            }

            final_state = await commander_graph.ainvoke(
                initial_state,
                config={
                    "recursion_limit": 100,  # ğŸ”¥ è®¾ç½®é€’å½’é™åˆ¶ï¼ˆæ”¾åœ¨é¡¶å±‚ï¼ï¼‰
                    "configurable": {
                        "thread_id": thread_id
                    }
                }
            )

            # ä¿å­˜ SubTask åˆ°æ•°æ®åº“
            for subtask in final_state["task_list"]:
                artifacts = subtask.get("artifact")
                if artifacts:
                    artifacts = [artifacts] if isinstance(artifacts, dict) else artifacts

                db_subtask = SubTask(
                    id=subtask["id"],
                    expert_type=subtask["expert_type"],
                    task_description=subtask["description"],
                    input_data=subtask["input_data"],
                    status=subtask["status"],
                    output_result=subtask["output_result"],
                    artifacts=artifacts,
                    started_at=subtask.get("started_at"),
                    completed_at=subtask.get("completed_at"),
                    created_at=subtask.get("created_at"),
                    updated_at=subtask.get("updated_at"),
                    task_session_id=task_session.session_id
                )
                session.add(db_subtask)

            # æ›´æ–° TaskSession
            task_session.final_response = final_state["final_response"]
            task_session.status = "completed"
            task_session.completed_at = datetime.now()
            task_session.updated_at = datetime.now()
            session.commit()

            print(f"[AUTO MODE] å®Œæˆï¼Œæ‰§è¡Œäº† {len(final_state['expert_results'])} ä¸ªä¸“å®¶")

            return {
                "mode": "auto",
                "thread_id": thread_id,
                "session_id": task_session.session_id,
                "user_query": request.message,
                "strategy": final_state["strategy"],
                "final_response": final_state["final_response"],
                "expert_results": final_state["expert_results"],
                "sub_tasks_count": len(final_state["task_list"]),
                "status": "completed"
            }

        else:
            # Direct æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨å•ä¸ªä¸“å®¶
            print(f"[DIRECT MODE] ç›´æ¥è°ƒç”¨ä¸“å®¶: {request.agent_id}")

            subtask_dict = {
                "id": str(uuid4()),
                "expert_type": request.agent_id,
                "description": request.message,
                "input_data": {},
                "status": "pending",
                "created_at": datetime.now(),
                "updated_at": datetime.now()
            }

            initial_state = {
                "messages": [HumanMessage(content=request.message)],
                "task_list": [subtask_dict],
                "current_task_index": 0,
                "strategy": f"ç›´æ¥æ¨¡å¼: {request.agent_id} ä¸“å®¶",
                "expert_results": [],
                "final_response": ""
            }

            # ä½¿ç”¨ generic_worker_node ç»Ÿä¸€æ‰§è¡Œä¸“å®¶
            result = await generic_worker_node(initial_state)

            # ä¿å­˜ SubTask åˆ°æ•°æ®åº“
            db_subtask = SubTask(
                id=subtask_dict["id"],
                expert_type=subtask_dict["expert_type"],
                task_description=subtask_dict["description"],
                input_data=subtask_dict["input_data"],
                status=result.get("status", "completed"),
                output_result={"content": result.get("output_result", "")},
                started_at=result.get("started_at"),
                completed_at=result.get("completed_at"),
                created_at=subtask_dict["created_at"],
                updated_at=subtask_dict["updated_at"],
                task_session_id=task_session.session_id
            )
            session.add(db_subtask)

            expert_result = {
                "task_id": subtask_dict["id"],
                "expert_type": request.agent_id,
                "description": request.message,
                "output": result.get("output_result", ""),
                "status": result.get("status", "unknown"),
                "started_at": result.get("started_at"),
                "completed_at": result.get("completed_at"),
                "duration_ms": result.get("duration_ms", 0)
            }

            # æ›´æ–° TaskSession
            task_session.final_response = result.get("output_result", "")
            task_session.status = "completed"
            task_session.completed_at = datetime.now()
            task_session.updated_at = datetime.now()
            session.commit()

            print(f"[DIRECT MODE] å®Œæˆï¼Œä¸“å®¶: {request.agent_id}")

            return {
                "mode": "direct",
                "thread_id": thread_id,
                "session_id": task_session.session_id,
                "user_query": request.message,
                "expert_type": request.agent_id,
                "final_response": result.get("output_result", ""),
                "expert_results": [expert_result],
                "sub_tasks_count": 1,
                "status": "completed"
            }

    except Exception as e:
        # é”™è¯¯å¤„ç†
        task_session.status = "failed"
        task_session.final_response = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
        task_session.updated_at = datetime.now()
        session.commit()

        print(f"[ERROR] æ‰§è¡Œå¤±è´¥: {e}")
        raise AppError(message=f"æ‰§è¡Œå¤±è´¥: {str(e)}", original_error=e)


# ============================================================================
# å¯åŠ¨å…¥å£
# ============================================================================

if __name__ == "__main__":
    port = int(os.getenv("PORT", 3002))
    print(f"[STARTUP] Starting Uvicorn server on port {port}...")
    print(f"[STARTUP] Host: 0.0.0.0, Port: {port}")

    try:
        uvicorn.run("main:app", host="0.0.0.0", port=port, reload=False, log_level="info")
    except Exception as e:
        print(f"[STARTUP ERROR] {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        raise
